# spi_bus


## 0 修订记录
| 修订说明 | 日期 | 作者 | 额外说明 |
| --- |
| 初版 | 2018/04/10 | 员清观 |  |

## 0 语音处理算法等

**db计算**
  https://blog.csdn.net/weixin_30514745/article/details/95182926
    对于功率：dB = 10*lg(A/B) 对于电压或电流：dB = 20*lg(A/B)。
**python的webrtc库实现语音端点检测，识别声音的开始和结束**<br>
  https://blog.csdn.net/u012123989/article/details/72771667
**语音识别中唤醒技术调研**<br>
  https://www.cnblogs.com/talkaudiodev/p/10919725.html

**声学回声消除(Acoustic Echo Cancellation)原理与实现**<br>
  https://www.cnblogs.com/LXP-Never/p/11703440.html
  https://www.cnblogs.com/ldjrl2013/p/3687938.html
**靠“喂喂喂”来测试实时语音质量靠谱吗？**<br>
  https://blog.csdn.net/agora_cloud/article/details/53007099
**音频软件开发中的debug方法和工具**<br>
  https://www.cnblogs.com/talkaudiodev/p/7400252.html
**音频混音算法的实现**<br>
  https://blog.csdn.net/hczhiyue/article/details/23618591?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.control


## 1 麦克风阵列
### 1.1 开发板
当前成熟的麦克风阵列的主要包括：科大讯飞的2麦方案、4麦阵列和6麦阵列方案，思必驰的6+1麦阵列方案，云知声的2麦方案，以及声智科技的单麦、2麦阵列、4（+1）麦阵列、6（+1）麦阵列和8（+1）麦阵列方案，其他家也有麦克风阵列的硬件方案，但是缺乏前端算法和云端识别的优化。由于各家算法原理的不同，有些阵列方案可以由用户自主选用中间的麦克风，这样更利于用户进行ID设计。其中，2个以上的麦克风阵列，又分为线形和环形两种主流结构，而2麦的阵列则又有Broadside和Endfire两种结构。

**其他参考**<br>
  http://www.360doc.com/content/18/0212/13/36367108_729552426.shtml

### 1.2　基本功能
1、语音增强：解决噪声环境下的识别
噪声环境是影响语音识别的一个重要因素，普通家居环境下的噪音有混响、回声、背景噪音、人声干扰等多种类型。不同步的语音相互叠加产生音素的交叠掩蔽效应，严重影响语音识别的效果。解决该问题需要从抑制噪声和语音增强两方面入手。
2、声源定位：辅助多功能联动
对麦克风拾音来讲，声源的位置的不确定性为语音交互带来了阻碍。声源定位功能不限制说话人运动，不需要移位操作，这增强了产品设计的灵活性和功能的多样性，可有效地实现对产品的多功能辅助作用。
3、远场交互：打破远距离沟通障碍
语音会随着传播距离衰减，传播距离越远，背景噪声和干扰所占比例就越大，同时混响也越严重，这对语音的远场识别及交互提出了较高要求。麦克风阵列在前端充分利用其空域滤波特性，抑制拾音波束外的回声、混响等噪声，进行语音增强处理，辅之以语音识别引擎的二次处理，实现优质的远场识别交互。
4、打断纠错：针对错误识别的解决办法
语音系统的认知能力是智能语音不容回避的问题，用户需求决定了要识别错误、纠正打断，认知型语音技术成为语音交互的必然趋势。麦克风阵列融入了自适应、理解纠错、智能反馈等认知技术，重新提取大数据因素，并进行二次计算，实现智能纠正打断，能够适应更多的应用环境，具有进化调整功能，从而在人机交互的过程中，使机器更“听话”。
5、多轮对话：应对用户的复杂需求指令
复杂任务的处理要求人机能够进行多轮对话，要求机器能够基于上下文的任务关系，进行任务切换和指代消减。基于对话逻辑，允许人机进行多轮语音互动，让机器理解用户的深层意图并提供反馈。而机器可以通过深度学习，可以根据上下文语境准确追踪用户意图，并随着数据的积累而越发灵活精准。深谙语音交互之道的多轮对话，使人机交互更自然流畅。
6、后端服务：实际场景下的功能需求
语音技术的应用场景、功能设计千差万别，保证用户体验的首要标准是满足用户的功能需求。当前智能硬件更多的是在生活场景中的应用，需要提供周边、资讯、音乐、订餐、订票、导航等生活服务，自然语言仅是人机交互的入口，而后端的内容和服务才是真正的交互对象。目前麦克风阵列解决方案能整合高德地图、网易云音乐、虾米音乐、喜马拉雅电台、考拉电台、大众点评等生活服务方面的诸多关键资源，致力将智能语音服务整合成一体化产品，打造体验闭环，形成完整的生态链。

## 2 回声抑制和消除
回声抑制算法是较早的一种回声控制算法。回声抑制是一acoustic echo suppression种非线性的回声消除。它通过简单的比较器将准备由扬声器播放的声音与当前话筒拾取的声音的电平进行比较，如果前者高于某个阈值，那么就允许传至扬声器，而且话筒被关闭，以阻止它拾取扬声器播放的声音而引起远端回声。如果话筒拾取的声音电平高于某个阈值，扬声器被禁止，以达到消除回声的目的。由于回声抑制是一种非线性的回声控制方法，会引起扬声器播放的不连续，影响回声消除的效果，随着高性能的回声消除器的出现，回声抑制已经很少有人使用了。

### 2.0 speex与webrtc回声消除小结
回声消除AEC包含：   延时估计对齐+线性自适应滤波器+NLP(双讲检测、处理)+舒适噪声CNG.

WebRtc：实现了基于网页的视频会议，标准是WHATWG 协议，目的是通过浏览器提供简单的javascript就可以达到实时通讯（Real-Time Communications (RTC)）能力。
Speex：实现了高质量和低比特率的编码，目的是提供一个可以替代高性能语音编解码来降低语音应用输入门槛。

两者比较： 都提供了信号处理的前端基本方案，如AEC，NS等
WebRtc：
  回声消除有吃音现象，模块相对复杂； 自动增益实现了对大信号的压缩，中间响度信号的增益，但是小信号没有压缩；
  噪声抑制效果较好； VAD检测效果良好，较好于Speex；
Speex：
  回声消除效果良好，但对于非线性，回声消除效果很差；自动增益不稳定，会出现忽大忽小的背景噪声的情况；噪声抑制效果不明显;VAD检测效果较差，即使是单纯的背景噪声，也可能将其检测为语音；
总的来说：Speex的AEC和NS较好于WebRtc，且Speex中的AEC支持立体声去回声以及2路以上的去回声；而WebRtc的AGC和VAD较好于Speex；

一、speex aec
  1、没有NLP 2、只考虑实时DSP系统，即是没有延时对齐等 3、自适应滤波（MDF）使用双滤波器结构，自适应滤波器因子自动更新
二、webrtc aec
  1、双讲检测没有，双讲时远端的声音会消没了 2、PBFDAF，固定自适应因子 0.6
  3、抑制是使用相关性技术，近端误差，近端远端，由低频段相关性参数求出gain值
对于aec，webrtc主要依赖NLP，speex主要是自适应滤波器（双滤波器）
三、实际效果对比
  如果样本非线性不严重，两者的效果都不错；对于非线性speex效果就很差了，webrtc的效果好；双讲时，webrtc出来的音质就很差，有吃音现象。至于webrtc的aecm音质差，单讲会有吱吱声。
四、优化点：
  对webrtc的aec加入双讲检测，双讲处理。
五、由于mic与扬声器对非线性影响比较大，自已硬件产品可以考虑使用比较好的mci与扬声器，极大减少nlp的抑制程度。对于dsp而言，实时性比较好，延时估计对齐可以不要。最后推荐使用webrtc aec。

### 2.1 speex算法
Speex的AEC是以NLMS(Normalized Least Mean Square)为基础，用MDF(multidelay block frequency domain)频域实现，最终推导出最优步长估计：残余回声与误差之比。最优步长等于残余回声方差与误差信号方差之比。 只有改与泄露系数相关部分的代码，才是对效果影响最大的地方，因为根据泄露系数，最终会估计出滤波器的最优步长。

**优缺点：**<br>
  1 AEC的线性算法处理不了Non-linear distortion(非线性失真)
  2 在其它预处理前 先调用AEC
  3 speex的aec并不是很适合音响系统里，音响中要慎用。耳机中效果还挺好。
  4 实验用的音频数据就不放到这里了，有谁需要可以留言邮箱，我发个你。


### 2.2 MC34118软件模拟
MC34118用在普通模拟电话机内消除侧音的一块芯片，能够比较满意的禁止麦克风录到本机喇叭播放的声音。它比较放音和录音的电平，谁小就禁止谁。晕哦，好好的全双工通信变成了半双工的。不过通话时一般感觉不到，并且软件实现起来很简单。
MC34118的工作原理看看datasheet就清楚了。它内部有点复杂，有4个电平比较器，两个背景噪音监视器，一个AGC，一个拨号音检测器，两个衰减器，一个控制衰减器的控制模块，还有一些放大。其实我们只需知道通过开关麦克风和喇叭的方法可以有效的避免回声就可以了。
参考文档：  http://www.icdemi.com/viewManual.aspx?p=manual%2fMC34118L.pdf

语音的电平也就是能量的大小可以计算采样的平方和得到。为了计算简单，采用计算采样的绝对值和得到。-- 原文如此，但我觉得应该换算成dB比较好衡量．
```cpp
static int check_val(const short * pdata,int len)　//以一个帧为单位，还是1s呢？
{
 int tmp = len;
 int all = 0;
 short val;
 while(tmp--)
 {
  val = *pdata++;
   if(val < 0)
      val  = -val;
   all += val
 }
 return all/len;
} //由于信号的不稳定，可能播放和录音的计算结果虽然相差不大，但大小频繁交叉，从而频繁开关麦克风和喇叭。所以将计算出来的平方和划分到8个等级中。
  if(check < 15)         r_level = 0;
  else if(check < 40)    r_level = 1;
  else if(check < 90)    r_level = 2;
  else if(check < 150)   r_level = 3;
  else if(check < 240)   r_level = 4;
  else if(check < 350)   r_level = 5;
  else if(check < 480)   r_level = 6;
  else  r_level = 7;
```
### 2.3 回声抑制（echo suppress）

为了优化aec测试过程中声音文件的时间同步问题处理，引入自动测试过程：
１．sudo minicom，启动板子，确认进入命令行
２．断开minicom链接(ctrl+a, 然后按q键)
３．执行脚本开始测试：pc开始播放音源，然后通过执行minicom脚本发送放音和录音命令到EVB板.(测试开始之前应该先启动加载totem进程，以减少PC播放延迟)
    totem ./tools/origion.wav &
    sudo minicom -S ./aectest.run
    sleep 30
    killall totem

    附aectest.run脚本内容：
    send "mount -t vfat /dev/mmcblk0p1 /mnt"
    send "abctrl play -w 32 -s 16000 -n 2 -d /mnt/pcm_16khz_ch2_32b.wav -y 55 -z 76 &"
    send "abctrl record --enable-aec -w 32 -s 16000 -n 2 -t 20 -o /mnt/record.wav"
    exit
４．20秒后录音结束，pesq比较record.wav和origion.wav.

断开uart链接
actl+a, q

git branch -a
qsdk_mainline_2.5.0

找到所有的.o文件并且按照大小排序：
    find . -type f -name "*.o" -size +10k | xargs ls -l | sort -rn -k 5
显示当前所有子目录大小，加上排序：
    du -sh *
    du -s * | sort -nr

ls -i　显示所有的inode, 和lz4中打印比较，看是否一次读取整个文件．


err = snd_pcm_open_conf(pcmp, name, root, pcm_conf, stream, mode);
      _snd_pcm_empty_open
        _snd_pcm_plug_open
          _snd_pcm_hw_open
            snd_pcm_hw_open
    SNDRV_PCM_IOCTL_XRUN
    snd_pcm_linear_open
    snd_pcm_write_areas


1. 能否通过struct device *dev找到对应的aecv2. aecv2最好是链表管理,可以通过dev寻找,或者通过cardid来找到.
    aecv2_set_soc_card 函数中,申请一个新的,根据cardid申请,
    通过 struct device *device 找到, 同时, 文件目录名称和cardid有关;生成之后,dev不会改变,所以无需销毁

static int imapx_pcm_new(struct snd_soc_pcm_runtime *rtd)
    aecv2_set_soc_card
int imapx_pcm_hw_params(struct snd_pcm_substream *substream,
    aecv2_register_substream
int imapx_pcm_close(struct snd_pcm_substream *substream)
    aecv2_unregister_substream
int imapx_pcm_trigger(struct snd_pcm_substream *substream, int cmd)
    aecv2_reset_substream
    几个数据buffer注意填充0的时机

## 3 aec运算命令
gcc -o pesq dsp.c pesqdsp.c pesqio.c pesqmain.c pesqmod.c -lm
gcc -o pesq dsp.c pesqdsp.c pesqio.c pesqmain.c pesqmod.c -lm;./pesq +16000 ~/eric_share/double_talk_music/voice_origion.wav ~/eric_share/double_talk_music/voice_aec.wav 10000 200000 1088

./pesq +16000 ~/eric_share/double_talk_music/voice_origion.wav ~/eric_share/double_talk_music/voice_aec.wav 20000 200000 1088
./pesq +8000 ~/eric_share/double_talk_voice/voice_origion.wav ~/eric_share/double_talk_voice/voice_aec.wav

cp ~/eric_share/double_talk_music/capture0.wav .;

./audioproc 3 80;~/work/pesq/pesq +8000 ~/eric_share/double_talk_voice/voice_origion.wav ~/work/audio_process/out.wav 8000 90000 -6720

cp ~/eric_share/
cp ~/eric_share/double_talk_music/capture0.wav .;./audioproc 5 80; ~/work/pesq/pesq +8000 ~/eric_share/double_talk_music/voice_origion.wav ~/work/audio_process/out.wav | grep Prediction
cp ~/eric_share/double_talk_voice/capture0.wav .;./audioproc 5 80; ~/work/pesq/pesq +8000 ~/eric_share/double_talk_voice/voice_origion.wav ~/work/audio_process/out.wav | grep Prediction

./audioproc 5 80 ~/eric_share/unittest_same_voice/capture0.wav
./webrtc_aec ~/eric_share/double_talk_test/test0_cap 160 3
./testecho ~/eric_share/capture/capture0.wav
./testecho ~/eric_share/double_talk_music/capture0.wav

./testecho ~/eric_share/aecin0_cap

gcc -o pesq dsp.c pesqdsp.c pesqio.c pesqmain.c pesqmod.c -lm;./pesq +16000 ~/eric_share/double_talk_voice/voice_origion.wav ~/eric_share/double_talk_voice/voice_aec.wav


### 3.1 最初pesq测试时使用的命令
./out +16000 origion1.aiff origion1.aiff |grep "Prediction : PESQ_MOS"
./out +16000 record1.aiff record1.aiff |grep "Prediction : PESQ_MOS"
./out +16000 origion.aiff record1.aiff |grep "Prediction : PESQ_MOS"

## 4 语音质量评估

目前国内研究语音相关的团队主要包括科研院所、语音技术公司以及互联网公司三部分：1. 科研院所主要包括高校和科学院，比如科学院里有声学所、自动化所，高校里面研究比较多的清华、北大、西工大、科大、上海交大等，这些都是在语音圈里占有较高位置的老牌队伍。2.语音技术公司包括我们比较熟悉的科大讯飞、云知声、思必驰、极限元等。3. 互联网公司包括BAT、搜狗等拥有强大的语音技术团队来支撑着其本身的很多业务

将会尝试采用主观语音质量评估标准：PESQ算法来量化回声消除效果．PESQ算法可以比较原始和结果两个wav音频文件，比较完毕之后给出对音频质量变化的主观评分．
ITU-T P.862提供了PESQ文档和C代码下载，网上也有基于matlab的实现下载，这种方式应该可行．
因为之前不熟悉aec部分，花了几天时间浏览了alango公司几个文档/G.165/G.168等，没有发现特别合适的算法；中间误以为THD+N(失真率)可以用来量化音效测试，查询了相关音频分析设备和软件，最后发现这个参数应该只是为了测试耳机或功放这种设备的线性度而定的，用来量化aec结果完全不行；后来考虑到高压缩率的编码算法也有失真，和回声消除的性质有几分相似，查询之后发现评估编码和通信质量的PESQ算法比较适合我们的需求．

### 4.1 评分标准
**相关的几个标准**<br>
重点关注P.831和基于P.862的4个文档：
ITU–T Recommendation G.165 Echo cancellers.
  介绍回声消除的基本原理，测试音源等．
ITU–T Recommendation G.168 Digital network echo cancellers.
  介绍回声消除的基本原理，测试音源等．
ITU–T Recommendation　P.800　Methods for subjective determination of transmission quality
  通用语音主观测试环境和测试方法
ITU–T Recommendation P.830 Subjective performance assessment of telephone-band and wideband digital codecs *
  语音主观测试环境，条件和方法的一些介绍
*ITU–T Recommendation P.831 Subjective performance evaluation of network echo cancellers
  介绍回声消除建立测试环境，各种测试条件，测试方法．但都是基于人工测试，主观评分．
ITU–T Recommendation P.56 　Objective measurement of active speech level.
  语音客观测试的音量/频率响应等指标的测量
ITU–T Recommendation P.862　Perceptual evaluation of speech quality
  主观语音质量评估
ITU–T Recommendation P.862.1 Mapping function for transforming P.862 raw result scores to MOS-LQO
ITU–T Recommendation P.862.2 Wideband extension to Recommendation P.862 for the assessment of wideband telephone networks and speech codecs
ITU–T Recommendation P.862.3 Application guide for objective quality measurement based on Recommendations P.862, P.862.1 and P.862.2
ITU–T Recommendation P.863 Perceptual objective listening quality assessment

**主观评估方法**<br>
主动方式需要发送一个语音参考信号通过电话网络，在网络的另一端采用数字信号处理的方式比较样本信号和接收到的信号，进而估算出网络的语音质量。（注：这里的比较算法基于心理声学（psychoacoustical），而不是简单的信号波形比较。具体算法太复杂，特别强大的同事可以参考ITU的标准文档。）

现在许多客观的测量方法已经出现并被应用，诸如，PSQM (Perceptual Speech Quality Measure定义于ITU-T P.861)/PSQM+感知通话质量测量，PESQ (Perceptual Evaluation of Speech Quality定义于ITU-T P.862)感知评估通话质量测量，PAMS（Perceptual Analysis Measurement System英国电信）感知分析测量等。

PESQ结合了PSQM和 PAMS的优势，针对VoIP和混合的端到端应用作了改进，并针对MOS和MOS-LQ计算方法做了修改。
最开始这些方法被用于测量编码算法，后来也逐渐 应用到VoIP网络系统的测量中，著名的测量仪器生产厂商Agilent的语音质量测量仪器VQT即是代表。
著名的VoIP测试厂商Empirix在G5中也使用了PESQ和PSQM。另外，根据本人瞎猜，XMS-Active也利用了这种方式。


### aec计算采样长度的公式
```cpp
//find a proper sample num.
int aec_lib_set_sampling_num(int sample_size, int base_size)
{
	int divv = 1, saved_divv = 1;

	while ((sample_size/divv) >= base_size) {
		if (sample_size%divv) {
			divv++;
			continue;
		} else {
			saved_divv = divv;
			divv++;
		}
	}
	aec_sample_num = sample_size/saved_divv;
	aec_sample_size = aec_sample_num * (AEC_UNIFIED_BITWIDTH>>3);

	return 0;
}
```

## 4 客户 FAQ
当客户现场出现问题时,应该有一个标准的流程:
1. audiobox_service.c中，增加'#define CAPTURE_FILE'，以获取原始alsa录音音频流
2. 确认下面打印是否存在：
    ^^^^^^^ aecv2 dma synced, sampling_rate:%d echo_path:(%dus,%dbytes) substream_offset:%d reserve_num:%d ^^^^^^^
3.

关于ctrl+c终止rtspserver程序时audiobox crash的问题, 能否启用gdb跟踪audiobox以定位crash具体位置? 这应该可以通过下面方式完成:1. rtspserver后台延时启动,保证在gdb启动audiobox之后即可 2.工作若干时间之后, 后台主动 "killall rtspserver" 3. 如果这个模拟场景能否浮现问题, bt命令查看一下crash时调用栈即可.
我这边平台上无法重现这个crash的问题,需要贵司提供协助,多谢.

编写和验证参考脚本, 使用gdb audiobox 调试程序
