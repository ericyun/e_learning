## 进程与调度管理

###  修订记录
| 修订说明 | 日期 | 作者 | 额外说明 |
| --- |
| 初版 | 2018/04/26 | 员清观 |  |

**参考索引**<br>
https://blog.csdn.net/npy_lp/article/category/1209083
**wowo**<br>
http://www.wowotech.net/sort/process_management/page/2

**进程调优**
https://blog.csdn.net/ljianhui/article/details/46718835

## 1 task_struct 定义

`task_struct`结构体内容不会全部在这个小节中描述，成员变量和功能定义在单独的小节中绑定
https://blog.csdn.net/gatieme/article/details/51872618
https://blog.csdn.net/sailor_8318/article/details/2460177


```cpp
//进程0 只有这个进程是静态分配的, 通过INIT_TASK宏初始化init_task结构体，通过INIT_THREAD_INFO宏初始化thread_info结构体
struct task_struct init_task = INIT_TASK(init_task);
union thread_union init_thread_union __init_task_data =	{ INIT_THREAD_INFO(init_task) };

struct task_struct {
	volatile long state;	/* -1 unrunnable, 0 runnable, >0 stopped */
	int exit_state; 	//#define EXIT_DEAD 16		//#define EXIT_ZOMBIE 32
	pid_t pid, tgid; //在CONFIG_BASE_SMALL配置为0的情况下，PID的取值范围是0到32767，即系统中的进程数最大为32768个
	int exit_code, exit_signal;
	void *stack;
	atomic_t usage;
	unsigned int flags;	/* per process flags, defined below */
	unsigned int ptrace;
	...
	char comm[TASK_COMM_LEN]; //程序名称
	/* file system info */
	int link_count, total_link_count;
/* filesystem information */
	struct fs_struct *fs;    //fs用来表示进程与文件系统的联系，包括当前目录和根目录
	struct files_struct *files; //opened file information
	...
	struct list_head tasks;
};

```
**state状态定义**

state域能够取5个互为排斥的值（通俗一点就是这五个值任意两个不能一起使用，只能单独使用）。系统中的每个进程都必然处于以上所列进程状态中的一种。

| 状态 | 描述 |
| --- |
| TASK_RUNNING | 表示进程要么正在执行，要么正要准备执行（已经就绪），正在等待cpu时间片的调度 |
| TASK_INTERRUPTIBLE | 进程因为等待一些条件而被挂起（阻塞）而所处的状态。这些条件主要包括：硬中断、资源、一些信号……，一旦等待的条件成立，进程就会从该状态（阻塞）迅速转化成为就绪状态TASK_RUNNING |
| TASK_UNINTERRUPTIBLE | 意义与TASK_INTERRUPTIBLE类似，除了不能通过接受一个信号来唤醒以外，对于处于TASK_UNINTERRUPIBLE状态的进程，哪怕我们传递一个信号或者有一个外部中断都不能唤醒他们。只有它所等待的资源可用的时候，他才会被唤醒。这个标志很少用，但是并不代表没有任何用处，其实他的作用非常大，特别是对于驱动刺探相关的硬件过程很重要，这个刺探过程不能被一些其他的东西给中断，否则就会让进城进入不可预测的状态 |
| TASK_STOPPED | 进程被停止执行，当进程接收到SIGSTOP、SIGTTIN、SIGTSTP或者SIGTTOU信号之后就会进入该状态 |
| TASK_TRACED | 表示进程被debugger等进程监视，进程执行被调试程序所停止，当一个进程被另外的进程所监视，每一个信号都会让进城进入该状态 |

Linux 内核提供了两种方法将进程置为睡眠状态。将进程置为睡眠状态的普通方法是将进程状态设置为 TASK_INTERRUPTIBLE 或 TASK_UNINTERRUPTIBLE 并调用调度程序的 schedule() 函数。这样会将进程从 CPU 运行队列中移除。如果进程处于可中断模式的睡眠状态（通过将其状态设置为 TASK_INTERRUPTIBLE），那么可以通过显式的唤醒呼叫（wakeup_process()）或需要处理的信号来唤醒它。当处于可中断睡眠模式的任务接收到信号时，它需要处理该信号（除非它已被屏弊），离开之前正在处理的任务（此处需要清除代码），并将 -EINTR 返回给用户空间。再一次，检查这些返回代码和采取适当操作的工作将由程序员完成。

虽然引入了TASK_UNINTERRUPTIBLE/TASK_WAKEKILL(接收到致命信号时唤醒进程)/TASK_KILLABLE 这几个状态，但qsdk驱动中很少使用，可以忽略。只需要关心TASK_RUNNING/TASK_INTERRUPTIBLE/TASK_STOPPED这三个状态就可以了

**exit_state状态定义**

| 状态 | 描述 |
| --- |
| EXIT_ZOMBIE | 进程的执行被终止，但是其父进程还没有使用wait()等系统调用来获知它的终止信息，此时进程成为僵尸进程 |
| EXIT_DEAD | 进程的最终状态 |

```cpp
//在Linux系统中，一个线程组中的所有线程使用和该线程组的领头线程（该组中的第一个轻量级进程）相同的PID，并被存放在tgid成员中。只有线程组的领头线程的pid成员才会被设置为与tgid相同的值。注意，getpid()系统调用返回的是当前进程的tgid值而不是pid值。

//获取当前主线程(内核中管理的id):
pid_t getpid(void); //获取当前进程的tgid值
//获取当前线程(内核中管理的id):
pid_t gettid(void); //获取当前线程的pid值
//获取当前posix线程id(posix中管理的id):获取的id实际上是主线程分配给子线程的线程描述符的地址而已，只是在当前进程空间中是唯一的
pthread_t pthread_self(void);
```
## 2 进程加载和退出
### 2.1 进程加载
```cpp
//常用的可执行文件格式为ELF格式以及使用#!机制的脚本格式。每一种格式都使用struct linux_binfmt结构体来表示
struct linux_binfmt {
	struct list_head lh; //用于formats构建链表
	struct module *module;
	int (*load_binary)(struct linux_binprm *, struct  pt_regs * regs);  //用于执行普通程序
	int (*load_shlib)(struct file *);   //用于加载共享库
	int (*core_dump)(struct coredump_params *cprm);  //用于程序出错时输出内存转储
	unsigned long min_coredump;	/* minimal dump size */
};
//ELF格式的linux_binfmt实例定义在fs/binfmt_elf.c文件中, 其中，load_elf_binary就是用来执行ELF格式可执行文件的函数
static struct linux_binfmt elf_format = {
	.module		= THIS_MODULE,
	.load_binary	= load_elf_binary,
	.load_shlib	= load_elf_library,
	.core_dump	= elf_core_dump,
	.min_coredump	= ELF_EXEC_PAGESIZE,
};
struct linux_binprm {
	char buf[BINPRM_BUF_SIZE];
	struct vm_area_struct *vma;
	unsigned long vma_pages;
	struct mm_struct *mm;
	unsigned long p; /* current top of mem */
	unsigned int
		cred_prepared:1,/* true if creds already prepared (multiple
				 * preps happen for interpreters) */
		cap_effective:1;/* true if has elevated effective capabilities,
				 * false if not; except for init which inherits
				 * its parent's caps anyway */
	unsigned int recursion_depth;
	struct file * file;
	struct cred *cred;	/* new credentials */
	int unsafe;		/* how unsafe this exec is (mask of LSM_UNSAFE_*) */
	unsigned int per_clear;	/* bits to clear in current->personality */
	int argc, envc;
	const char * filename;	/* Name of binary as seen by procps */
	const char * interp;	/* Name of the binary really executed. Most
				   of the time same as filename, but could be different for binfmt_{misc,script} */
	unsigned interp_flags, interp_data;
	unsigned long loader, exec;
	char tcomm[TASK_COMM_LEN];
};
```
```cpp
long do_fork(unsigned long clone_flags,　unsigned long stack_start,　unsigned long stack_size,　int __user *parent_tidptr,　int __user *child_tidptr)//好像很少用，下一步可以重点关注 copy_thread()源代码
	|--> p = copy_process(clone_flags, stack_start, stack_size, child_tidptr, NULL, trace);
		|--> struct task_struct *p = dup_task_struct(current);
			int node = tsk_fork_get_node(orig); 			tsk = alloc_task_struct_node(node);
			ti = alloc_thread_info_node(tsk, node);		 //内核栈申请
			err = arch_dup_task_struct(tsk, orig);
			tsk->stack = ti;  setup_thread_stack(tsk, orig); //互相索引
			return tsk;
		sched_fork(p); p->pid = pid_nr(pid); p->tgid = p->pid; //以及其他乱七八糟的初始化
	wake_up_new_task(p); return nr = task_pid_vnr(p);

pid_t kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)//这个函数最重要的用处就是初始化过程中rest_init()函数中创建两个内核线程： //kernel_thread(kernel_init, NULL, CLONE_FS | CLONE_SIGHAND); //pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);
  return do_fork(flags|CLONE_VM|CLONE_UNTRACED, (unsigned long)fn,(unsigned long)arg, NULL, NULL);

int load_elf_binary(struct linux_binprm *bprm)
  struct {	struct elfhdr elf_ex;	struct elfhdr interp_elf_ex; } *loc;
  loc = kmalloc(sizeof(*loc), GFP_KERNEL); loc->elf_ex = *((struct elfhdr *)bprm->buf);
  size = loc->elf_ex.e_phnum * sizeof(struct elf_phdr);   elf_phdata = kmalloc(size, GFP_KERNEL);
  retval = kernel_read(bprm->file, loc->elf_ex.e_phoff, (char *)elf_phdata, size); elf_ppnt = elf_phdata;
  //解析依赖库，全部读取到一个buffer中。
  for (i = 0; i < loc->elf_ex.e_phnum; i++) {
    if (elf_ppnt->p_type == PT_INTERP)   {
      elf_interpreter = kmalloc(elf_ppnt->p_filesz, GFP_KERNEL);
      retval = kernel_read(bprm->file, elf_ppnt->p_offset, elf_interpreter, elf_ppnt->p_filesz);
      interpreter = open_exec(elf_interpreter);  retval = kernel_read(interpreter, 0, bprm->buf, BINPRM_BUF_SIZE);
      loc->interp_elf_ex = *((struct elfhdr *)bprm->buf);
    }
    elf_ppnt++;
  }
  retval = flush_old_exec(bprm);  current->mm->def_flags = def_flags;
  SET_PERSONALITY(loc->elf_ex);

static int do_execve_common(const char *filename, struct user_arg_ptr argv, struct user_arg_ptr envp)
	struct linux_binprm *bprm = kzalloc(sizeof(*bprm), GFP_KERNEL); //用于维护程序执行过程中所使用的各种数据
	prepare_bprm_creds(bprm); check_unsafe_exec(bprm); current->in_execve = 1;
  file = open_exec(filename); sched_exec();//确定最小负载CPU以执行新程序，并把当前进程转移过去
	bprm->file = file; 	bprm->filename = filename; 	bprm->interp = filename;
  |--> retval = bprm_mm_init(bprm);//创建并且初始化mm_struct, 分配新的进程地址空间
		struct mm_struct *mm = NULL; bprm->mm = mm = mm_alloc();
		init_new_context(current, mm);
		|--> __bprm_mm_init(bprm); //int __bprm_mm_init(struct linux_binprm *bprm)
			struct vm_area_struct *vma = NULL; 	struct mm_struct *mm = bprm->mm;
			bprm->vma = vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
			down_write(&mm->mmap_sem);
			vma->vm_mm = mm; vma->vm_end = STACK_TOP_MAX;	vma->vm_start = vma->vm_end - PAGE_SIZE;
			vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;
			vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
			INIT_LIST_HEAD(&vma->anon_vma_chain); insert_vm_struct(mm, vma); mm->stack_vm = mm->total_vm = 1;
			up_write(&mm->mmap_sem);
			bprm->p = vma->vm_end - sizeof(void *);
  retval = prepare_binprm(bprm); //return kernel_read(bprm->file, 0, bprm->buf, BINPRM_BUF_SIZE); 填充linux_binprm结构体变量*bprm的某些字段
  |--> retval = search_binary_handler(bprm); //扫描formats链表（当前Linux系统支持的所有可执行文件格式的链表），并不断地尝试调用找到的每种可执行文件格式的load_binary函数（先只是比较魔数而已，不匹配则返回），直到找到匹配的格式为止;如果都未找到匹配的可执行文件格式，则返回错误码-ENOEXEC，表示当前的Linux系统不能执行此种格式的程序
    int (*fn)(struct linux_binprm *) = fmt->load_binary;  retval = fn(bprm);//load_binary:: load_elf_binary()
  current->fs->in_exec = current->in_execve = 0;
	acct_update_integrals(current);  free_bprm(bprm);

int do_execve(const char *filename,	const char __user *const __user *__argv, const char __user *const __user *__envp)
  struct user_arg_ptr argv = { .ptr.native = __argv };
	struct user_arg_ptr envp = { .ptr.native = __envp };
  return do_execve_common(filename, argv, envp);

SYSCALL_DEFINE3(execve, const char __user *, filename, const char __user *const __user *, argv,	const char __user *const __user *, envp)
	struct filename *path = getname(filename);
	int error = PTR_ERR(path);
	if (!IS_ERR(path)) { 		error = do_execve(path->name, argv, envp); 		putname(path); 	}

int run_init_process(const char *init_filename)//内核态创建的用户进程
  argv_init[0] = init_filename;
  return do_execve(init_filename,(const char __user *const __user *)argv_init,(const char __user *const __user *)envp_init);

```
### 2.2 进程退出
```cpp
//例如 pr_detect.c中调用 profile_event_register(PROFILE_TASK_EXIT, &my_task_exit_nb); 注册了一个cb到进程退出处理流程
void do_exit(long code)
	struct task_struct *tsk = current;
	profile_task_exit(tsk); //-->blocking_notifier_call_chain(&task_exit_notifier, 0, task); --> notifier_call_chain(&nh->head, val, v, nr_to_call, nr_calls); 处理之前注册的退出cb
	set_fs(USER_DS); //设定进程可以使用的虚拟地址的上限（用户空间）
	exit_sem(tsk); 	exit_shm(tsk); 	exit_files(tsk); 	exit_fs(tsk); 	exit_task_namespaces(tsk);
	exit_task_work(tsk); 	check_stack_usage(); 	exit_thread();
	disassociate_ctty(1); //脱离控制终端
	exit_notify(tsk, group_dead); //通知所有子进程的父进程
	tsk->state = TASK_DEAD; tsk->flags |= PF_NOFREEZE;  schedule();
```
### 2.3 内核线程的创建
内核线程kthreadd用来创建其它的内核线程.kthreadd函数通过死循环不断地检查kthread_create_list链表是否为空，如果不为空，则调用`create_kthread`函数来创建新的内核线程。
```cpp
void create_kthread(struct kthread_create_info *create)
	pid = kernel_thread(kthread, create, CLONE_FS | CLONE_FILES | SIGCHLD); //do_fork

int kthreadd(void *unused)
{
	struct task_struct *tsk = current;
	/* Setup a clean context for our children to inherit. */
	set_task_comm(tsk, "kthreadd");
	ignore_signals(tsk);
	set_cpus_allowed_ptr(tsk, cpu_all_mask);
	set_mems_allowed(node_states[N_MEMORY]);
	current->flags |= PF_NOFREEZE;
	for (;;) {
		set_current_state(TASK_INTERRUPTIBLE);
		if (list_empty(&kthread_create_list))
			schedule();
		__set_current_state(TASK_RUNNING);

		spin_lock(&kthread_create_lock);
		while (!list_empty(&kthread_create_list)) {
			struct kthread_create_info *create;

			create = list_entry(kthread_create_list.next,
					    struct kthread_create_info, list);
			list_del_init(&create->list);
			spin_unlock(&kthread_create_lock);

			create_kthread(create);

			spin_lock(&kthread_create_lock);
		}
		spin_unlock(&kthread_create_lock);
	}

	return 0;
}
```

## 3 进程优先级和调度
实时优先级范围是0到MAX_RT_PRIO-1（即99），而普通进程的静态优先级范围是从MAX_RT_PRIO到MAX_PRIO-1（即100到139）。值越大静态优先级越低
```cpp
//#define MAX_USER_RT_PRIO	100
//#define MAX_RT_PRIO				MAX_USER_RT_PRIO
//#define MAX_PRIO					(MAX_RT_PRIO + 40)
//#define DEFAULT_PRIO			(MAX_RT_PRIO + 20)

struct task_struct {
	...
	int prio; //用于保存动态优先级
	int static_prio; //用于保存静态优先级，可以通过nice系统调用来进行修改
	int normal_prio; //他的值取决于静态优先级和调度策略
	unsigned int rt_priority; //用于保存实时优先级
	const struct sched_class *sched_class;
	//se和rt都是调用实体，一个用于普通进程，一个用于实时进程，每个进程都有其中之一的实体。
	struct sched_entity se;
	struct sched_rt_entity rt;
	...
	unsigned int policy;
	int nr_cpus_allowed;
	cpumask_t cpus_allowed; //用于控制进程可以在哪些处理器上运行
};

/* policy			表示进程的调度策略，目前主要有以下五种: */
//#define SCHED_NORMAL	0 //用于普通进程，通过CFS调度器实现
//#define SCHED_FIFO		1 //实时调度策略
//#define SCHED_RR			2 //实时调度策略
//#define SCHED_BATCH		3 //用于非交互的处理器消耗型进程
//#define SCHED_IDLE		5 //在系统负载很低时使用

static const struct sched_class fair_sched_class;/* linux-2.6.38.8/kernel/sched_fair.c */
static const struct sched_class rt_sched_class;/* linux-2.6.38.8/kernel/sched_rt.c */
static const struct sched_class idle_sched_class;/* linux-2.6.38.8/kernel/sched_idletask.c */
static const struct sched_class stop_sched_class;/* linux-2.6.38.8/kernel/sched_stoptask.c */
```

## 4
### 4.1 进程栈 线程栈 中断栈 内核栈
	https://blog.csdn.net/yangkuanqaz85988/article/details/52403726

```cpp
/* 虚拟内存管理的操作函数 - 对VMA做打开、关闭和
 * 取消映射操作, (需要保持文件在磁盘上的同步更新等),
 * 当一个缺页或交换页异常发生时，这些函数指针指向实际的函数调用。 */
struct vm_operations_struct {
    void (*open)(struct vm_area_struct * area);
   /* 被内核调用以实现 VMA 的子系统来初始化一个VMA.当对 VMA 产生一个新的引用时( 如fork进程时)，则调用这个方法
    * 唯一的例外是当该 VMA 第一次被 mmap 创建时;在这个情况下, 则需要调用驱动的 mmap 方法.  */

    void (*close)(struct vm_area_struct * area);
   /* 当一个VMA被销毁时, 内核调用此操作.注意：由于没有相应的 VMA使用计数; VMA只被每个使用它的进程打开和关闭一次. */

    int (*fault)(struct vm_area_struct *vma, struct vm_fault *vmf);
   /* 重要的函数调用，当一个进程试图存取使用一个有效的、但当前不在内存中 VMA 的页,自动触发的缺页异常处理程序就调用该方法。
    * 将对应的数据读取到一个映射在用户地址空间的物理内存页中（替代原有的nopage）*/


    /* 通知一个之前只读的页将要变为可写，如果返回错误，将会引发SIGBUS（总线错误） */
    int (*page_mkwrite)(struct vm_area_struct *vma, struct vm_fault *vmf);

    /* 当get_user_pages() 失败，被access_process_vm调用，一般用于特殊的VMA（可以在硬件和内存间交换的VMA）*/
    int (*access)(struct vm_area_struct *vma, unsigned long addr, void *buf, int len, int write);
		/* called by sys_remap_file_pages() to populate non-linear mapping */
		int (*remap_pages)(struct vm_area_struct *vma, unsigned long addr,
	   		 unsigned long size, pgoff_t pgoff);
};

struct vm_area_struct {
	 struct mm_struct * vm_mm;/* 所属的进程虚拟地址空间的结构体指针，就是我们上面看到的结构体 */
	 /* 被该VMA 覆盖的虚拟地址范围. 也就是在 /proc/*/maps中出现的头 2 个字段 */
   unsigned long vm_start;        /* vm_mm内的起始地址 */
   unsigned long vm_end;          /* 在vm_mm内的结束地址之后的第一个字节的地址 */
   struct vm_area_struct *vm_next, *vm_prev;		/* 用来链接进程的VMA结构体的指针, 按地址排序 */
	 struct rb_node vm_rb; 	 unsigned long rb_subtree_gap;
	 struct mm_struct *vm_mm;	/* The address space we belong to. */
	 pgprot_t vm_page_prot;		/* Access permissions of this VMA. */
	 unsigned long vm_flags;		/* Flags, see mm.h. */
	 union {
		 struct {
			 struct list_head list;
			 void *parent;
			 struct vm_area_struct *head;
		 } vm_set;
		 struct raw_prio_tree_node prio_tree_node;
	 } shared;
	 //上面union shared 则与文件映射页面使用的优先级搜索树相关；union shared 中的 prio_tree_node 结构用于表示优先级搜索树的一个节点；在某些情况下，比如不同的进程的内存区域可能映射到了同一个文件的相同部分，也就是说这些内存区域具有相同的 （radix,size,heap）值，这个时候 Linux 就会在树上相应的节点（树上原来那个具有相同 （radix,size,heap） 值的内存区域）上接一个双向链表用来存放这些内存区域，这个链表用 vm_set.list 来表示；树上那个节点指向的链表中的第一个节点是表头，用 vm_set.head 表示；vm_set.parent 用于表示是否是树结点
	 //与 匿名页面的双向链表相关的字段是 anon_vma_node 和 anon_vma；字段 anon_vma 指向 anon_vma 表；字段 anon_vma_node 将映射该页面的所有虚拟内存区域链接起来
	 struct list_head anon_vma_node;
	 struct anon_vma *anon_vma;
	 const struct vm_operations_struct *vm_ops;//ops回调函数
	 unsigned long vm_pgoff;
	 struct file * vm_file;		/* File we map to (can be NULL). */
	 void * vm_private_data;		/* was vm_pte (shared mem) */
 };

struct mm_struct {
	struct vm_area_struct *mmap; /* 内存区域链表 */
	struct rb_root mm_rb; 			 /* VMA 形成的红黑树 */
	struct vm_area_struct * mmap_cache;    /* 指向最近找到的虚拟区间 */
	unsigned long (*get_unmapped_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags);
  void (*unmap_area) (struct mm_struct *mm, unsigned long addr);
	unsigned long mmap_base;        /* mmap区域的基地址 */
  unsigned long task_size;        /* 进程虚拟地址空间的大小 */
	unsigned long cached_hole_size;     /* if non-zero, the largest hole below free_area_cache */
	unsigned long free_area_cache;        /* first hole of size cached_hole_size or larger */
	pgd_t * pgd;                   /* 指向进程的页目录 */
	atomic_t mm_users;             /* 用户空间中的有多少用户? */
	atomic_t mm_count;             /* 本数据结构的引用计数 (users count as 1) */
	int map_count;                 /* 虚拟内存区（VMA）的计数 */

	spinlock_t page_table_lock;        /* 页表和计数器的保护自旋锁 */
	struct rw_semaphore mmap_sem;
	struct list_head mmlist; 		 /* 所有 mm_struct 形成的链表 */
	...
	unsigned long total_vm; 		 /* 全部页面数目 */
	unsigned long locked_vm; 		 /* 上锁的页面数据 */
	unsigned long pinned_vm; 		 /* Refcount permanently increased */
	unsigned long shared_vm; 	 	 /* 共享页面数目 Shared pages (files) */
	unsigned long exec_vm; 			 /* 可执行页面数目 VM_EXEC & ~VM_WRITE */
	unsigned long stack_vm; 		 /* 栈区页面数目 VM_GROWSUP/DOWN */
	unsigned long def_flags;
	unsigned long start_code, end_code, start_data, end_data; /* 代码段、数据段 起始地址和结束地址 */
	unsigned long start_brk, brk, start_stack; /* 栈区 的起始地址，堆区 起始地址和结束地址 */
	unsigned long arg_start, arg_end, env_start, env_end; /* 命令行参数 和 环境变量的 起始地址和结束地址 */
	... /* Architecture-specific MM context */
	mm_context_t context; 		   /* 体系结构特殊数据 */
	/* Must use atomic bitops to access the bits */
	unsigned long flags; 				 /* 状态标志位 */
	...
	/* Coredumping and NUMA and HugePage 相关结构体 */
};

struct thread_info {
    unsigned long        flags;        /* low level flags */
    int            preempt_count;    /* 0 => preemptable, <0 => bug */
    mm_segment_t        addr_limit;    /* address limit */
    struct task_struct    *task;        /* main task structure */
    struct exec_domain    *exec_domain;    /* execution domain */
    __u32            cpu;        /* cpu */
    __u32            cpu_domain;    /* cpu domain */
    struct cpu_context_save    cpu_context;    /* cpu context */
    __u32            syscall;    /* syscall number */
    __u8            used_cp[16];    /* thread used copro */
    unsigned long        tp_value;
    struct crunch_state    crunchstate;
    union fp_state        fpstate __attribute__((aligned(8)));
    union vfp_state        vfpstate;
    unsigned long        thumbee_state;    /* ThumbEE Handler Base register */
    struct restart_block    restart_block;
};

//#define THREAD_SIZE		8192
union thread_union {
    struct thread_info thread_info;
    unsigned long stack[THREAD_SIZE/sizeof(long)];
};
//内核栈被放在特殊的段中：__(".data.init_task")))
union thread_union init_thread_union __attribute__((__section__(".data.init_task"))) = { INIT_THREAD_INFO(init_task) };
ENTRY(stack_start)
    .long init_thread_union+THREAD_SIZE
    .long __BOOT_DS
默认跟中断栈共享，可以通过内核配置项修改。它属于进程，即每个进程都有自己的内核栈

```

**内核栈的产生**<br>
在进程被创建的时候，fork族的系统调用中会分别为内核栈和`struct task_struct`分配空间，调用过程是：fork族的系统调用--->do_fork--->copy_process--->dup_task_struct
在`dup_task_struct`函数中:

```cpp
static struct task_struct *dup_task_struct(struct task_struct *orig)
	struct task_struct *tsk = alloc_task_struct_node(node); //使用内核的slab分配器去为所要创建的进程分配struct task_struct的空间
	struct thread_info *ti = alloc_thread_info_node(tsk, node);//使用内核的伙伴系统去为所要创建的进程分配内核栈（union thread_union ）空间
	err = arch_dup_task_struct(tsk, orig);//
	tsk->stack = ti;//关联了struct task_struct和内核栈
	|--> setup_thread_stack(tsk, orig);//void setup_thread_stack(struct task_struct *p, struct task_struct *org) 关联了内核栈和struct task_struct
		//#define task_thread_info(task)	((struct thread_info *)(task)->stack)
		//#define task_stack_page(task)	((task)->stack)
		*task_thread_info(p) = *task_thread_info(org);
		task_thread_info(p)->task = p;
	...

static inline struct thread_info *current_thread_info(void)
{
	register unsigned long sp asm ("sp");
	return (struct thread_info *)(sp & ~(THREAD_SIZE - 1));
}
//#define get_current() (current_thread_info()->task)
//#define current get_current()
从上面定义就清楚 current 指针是如何实现的了；另外，由于栈空间的限制，在编写的驱动（特别是被系统调用使用的底层函数）中要注意避免对栈空间消耗较大的代码，比如递归算法、局部自动变量定义的大小等等
```


![进程内存空间结构](pic_dir/进程内存空间结构.png)

**进程栈的动态增长实现**<br>
进程在运行的过程中，通过不断向栈区压入数据，当超出栈区容量时，就会耗尽栈所对应的内存区域，这将触发一个 缺页异常 (page fault)。通过异常陷入内核态后，异常会被内核的 expand_stack() 函数处理，进而调用 acct_stack_growth() 来检查是否还有合适的地方用于栈的增长。如果栈的大小低于 RLIMIT_STACK（通常为8MB），那么一般情况下栈会被加长，程序继续执行，感觉不到发生了什么事情，这是一种将栈扩展到所需大小的常规机制。然而，如果达到了最大栈空间的大小，就会发生 栈溢出（stack overflow），进程将会收到内核发出的 段错误（segmentation fault） 信号。动态栈增长是唯一一种访问未映射内存区域而被允许的情形，其他任何对未映射内存区域的访问都会触发页错误，从而导致段错误。一些被映射的区域是只读的，因此企图写这些区域也会导致段错误。

### 4.2 重要函数解析

 整个系统的内存由一个名为node_data 的struct pglist_data（page_data_t） 指针数组来管理。分析可以开始于此．

```cpp
unsigned long vm_brk(unsigned long addr, unsigned long len)
unsigned long do_mmap_pgoff(struct file *file, unsigned long addr,unsigned long len, unsigned long prot, unsigned long flags, unsigned long pgoff,	unsigned long *populate)

```

## 5 信号处理

```cpp
struct task_struct {
/* signal handlers */
	struct signal_struct *signal;
	struct sighand_struct *sighand;

	sigset_t blocked, real_blocked;
	sigset_t saved_sigmask;	/* restored if set_restore_sigmask() was used */
	struct sigpending pending;

	unsigned long sas_ss_sp;
	size_t sas_ss_size;
	int (*notifier)(void *priv);
	void *notifier_data;
	sigset_t *notifier_mask;
};

```


### 5.1

## 6
