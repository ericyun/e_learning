## 进程与调度管理

###  修订记录
| 修订说明 | 日期 | 作者 | 额外说明 |
| --- |
| 初版 | 2018/04/26 | 员清观 |  |

**参考索引**<br>
https://blog.csdn.net/npy_lp/article/category/1209083
**wowo**<br>
http://www.wowotech.net/sort/process_management/page/2

**进程调优**
https://blog.csdn.net/ljianhui/article/details/46718835

## 1

https://blog.csdn.net/gatieme/article/details/51872618
https://blog.csdn.net/sailor_8318/article/details/2460177

## 2 进程加载
```cpp
long do_fork(unsigned long clone_flags,　unsigned long stack_start,　unsigned long stack_size,　int __user *parent_tidptr,　int __user *child_tidptr)//好像很少用，下一步可以重点关注 copy_thread()源代码
pid_t kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)//这个函数最重要的用处就是初始化过程中rest_init()函数中创建两个内核线程： //kernel_thread(kernel_init, NULL, CLONE_FS | CLONE_SIGHAND); //pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);
  return do_fork(flags|CLONE_VM|CLONE_UNTRACED, (unsigned long)fn,(unsigned long)arg, NULL, NULL);

int load_elf_binary(struct linux_binprm *bprm)
  struct {	struct elfhdr elf_ex;	struct elfhdr interp_elf_ex; } *loc;
  loc = kmalloc(sizeof(*loc), GFP_KERNEL); loc->elf_ex = *((struct elfhdr *)bprm->buf);
  size = loc->elf_ex.e_phnum * sizeof(struct elf_phdr);   elf_phdata = kmalloc(size, GFP_KERNEL);
  retval = kernel_read(bprm->file, loc->elf_ex.e_phoff, (char *)elf_phdata, size); elf_ppnt = elf_phdata;
  //解析依赖库，全部读取到一个buffer中。
  for (i = 0; i < loc->elf_ex.e_phnum; i++) {
    if (elf_ppnt->p_type == PT_INTERP)   {
      elf_interpreter = kmalloc(elf_ppnt->p_filesz, GFP_KERNEL);
      retval = kernel_read(bprm->file, elf_ppnt->p_offset, elf_interpreter, elf_ppnt->p_filesz);
      interpreter = open_exec(elf_interpreter);  retval = kernel_read(interpreter, 0, bprm->buf, BINPRM_BUF_SIZE);
      loc->interp_elf_ex = *((struct elfhdr *)bprm->buf);
    }
    elf_ppnt++;
  }
  retval = flush_old_exec(bprm);  current->mm->def_flags = def_flags;
  SET_PERSONALITY(loc->elf_ex);


static int do_execve_common(const char *filename, struct user_arg_ptr argv, struct user_arg_ptr envp)
  file = open_exec(filename); bprm->file = file; 	bprm->filename = filename; 	bprm->interp = filename;
  retval = bprm_mm_init(bprm);//创建并且初始化mm_struct
  retval = prepare_binprm(bprm); //return kernel_read(bprm->file, 0, bprm->buf, BINPRM_BUF_SIZE);
  |--> retval = search_binary_handler(bprm); //加载二进制文件
    int (*fn)(struct linux_binprm *) = fmt->load_binary;  retval = fn(bprm);//load_binary:: load_elf_binary()
  current->fs->in_exec = 0;current->in_execve = 0; acct_update_integrals(current);  free_bprm(bprm);

int do_execve(const char *filename,	const char __user *const __user *__argv, const char __user *const __user *__envp)
  struct user_arg_ptr argv = { .ptr.native = __argv };
	struct user_arg_ptr envp = { .ptr.native = __envp };
  return do_execve_common(filename, argv, envp);

SYSCALL_DEFINE3(execve, const char __user *, filename, const char __user *const __user *, argv,	const char __user *const __user *, envp)
	struct filename *path = getname(filename);
	int error = PTR_ERR(path);
	if (!IS_ERR(path)) { 		error = do_execve(path->name, argv, envp); 		putname(path); 	}

int run_init_process(const char *init_filename)//内核态创建的用户进程
  argv_init[0] = init_filename;
  return do_execve(init_filename,(const char __user *const __user *)argv_init,(const char __user *const __user *)envp_init);

```
## 3

## 4
### 4.1 进程栈 线程栈 中断栈 内核栈
	https://blog.csdn.net/yangkuanqaz85988/article/details/52403726

```cpp
/* 虚拟内存管理的操作函数 - 对VMA做打开、关闭和
 * 取消映射操作, (需要保持文件在磁盘上的同步更新等),
 * 当一个缺页或交换页异常发生时，这些函数指针指向实际的函数调用。 */
struct vm_operations_struct {
    void (*open)(struct vm_area_struct * area);
   /* 被内核调用以实现 VMA 的子系统来初始化一个VMA.当对 VMA 产生一个新的引用时( 如fork进程时)，则调用这个方法
    * 唯一的例外是当该 VMA 第一次被 mmap 创建时;在这个情况下, 则需要调用驱动的 mmap 方法.  */

    void (*close)(struct vm_area_struct * area);
   /* 当一个VMA被销毁时, 内核调用此操作.注意：由于没有相应的 VMA使用计数; VMA只被每个使用它的进程打开和关闭一次. */

    int (*fault)(struct vm_area_struct *vma, struct vm_fault *vmf);
   /* 重要的函数调用，当一个进程试图存取使用一个有效的、但当前不在内存中 VMA 的页,自动触发的缺页异常处理程序就调用该方法。
    * 将对应的数据读取到一个映射在用户地址空间的物理内存页中（替代原有的nopage）*/


    /* 通知一个之前只读的页将要变为可写，如果返回错误，将会引发SIGBUS（总线错误） */
    int (*page_mkwrite)(struct vm_area_struct *vma, struct vm_fault *vmf);

    /* 当get_user_pages() 失败，被access_process_vm调用，一般用于特殊的VMA（可以在硬件和内存间交换的VMA）*/
    int (*access)(struct vm_area_struct *vma, unsigned long addr, void *buf, int len, int write);
		/* called by sys_remap_file_pages() to populate non-linear mapping */
		int (*remap_pages)(struct vm_area_struct *vma, unsigned long addr,
	   		 unsigned long size, pgoff_t pgoff);
};

struct vm_area_struct {
	 struct mm_struct * vm_mm;/* 所属的进程虚拟地址空间的结构体指针，就是我们上面看到的结构体 */
	 /* 被该VMA 覆盖的虚拟地址范围. 也就是在 /proc/*/maps中出现的头 2 个字段 */
   unsigned long vm_start;        /* vm_mm内的起始地址 */
   unsigned long vm_end;          /* 在vm_mm内的结束地址之后的第一个字节的地址 */
   struct vm_area_struct *vm_next, *vm_prev;		/* 用来链接进程的VMA结构体的指针, 按地址排序 */
	 struct rb_node vm_rb; 	 unsigned long rb_subtree_gap;
	 struct mm_struct *vm_mm;	/* The address space we belong to. */
	 pgprot_t vm_page_prot;		/* Access permissions of this VMA. */
	 unsigned long vm_flags;		/* Flags, see mm.h. */
	 union {
		 struct {
			 struct list_head list;
			 void *parent;
			 struct vm_area_struct *head;
		 } vm_set;
		 struct raw_prio_tree_node prio_tree_node;
	 } shared;
	 //上面union shared 则与文件映射页面使用的优先级搜索树相关；union shared 中的 prio_tree_node 结构用于表示优先级搜索树的一个节点；在某些情况下，比如不同的进程的内存区域可能映射到了同一个文件的相同部分，也就是说这些内存区域具有相同的 （radix,size,heap）值，这个时候 Linux 就会在树上相应的节点（树上原来那个具有相同 （radix,size,heap） 值的内存区域）上接一个双向链表用来存放这些内存区域，这个链表用 vm_set.list 来表示；树上那个节点指向的链表中的第一个节点是表头，用 vm_set.head 表示；vm_set.parent 用于表示是否是树结点
	 //与 匿名页面的双向链表相关的字段是 anon_vma_node 和 anon_vma；字段 anon_vma 指向 anon_vma 表；字段 anon_vma_node 将映射该页面的所有虚拟内存区域链接起来
	 struct list_head anon_vma_node;
	 struct anon_vma *anon_vma;
	 const struct vm_operations_struct *vm_ops;//ops回调函数
	 unsigned long vm_pgoff;
	 struct file * vm_file;		/* File we map to (can be NULL). */
	 void * vm_private_data;		/* was vm_pte (shared mem) */
 };

struct mm_struct {
	struct vm_area_struct *mmap; /* 内存区域链表 */
	struct rb_root mm_rb; 			 /* VMA 形成的红黑树 */
	struct vm_area_struct * mmap_cache;    /* 指向最近找到的虚拟区间 */
	unsigned long (*get_unmapped_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags);
  void (*unmap_area) (struct mm_struct *mm, unsigned long addr);
	unsigned long mmap_base;        /* mmap区域的基地址 */
  unsigned long task_size;        /* 进程虚拟地址空间的大小 */
	unsigned long cached_hole_size;     /* if non-zero, the largest hole below free_area_cache */
	unsigned long free_area_cache;        /* first hole of size cached_hole_size or larger */
	pgd_t * pgd;                   /* 指向进程的页目录 */
	atomic_t mm_users;             /* 用户空间中的有多少用户? */
	atomic_t mm_count;             /* 本数据结构的引用计数 (users count as 1) */
	int map_count;                 /* 虚拟内存区（VMA）的计数 */

	spinlock_t page_table_lock;        /* 页表和计数器的保护自旋锁 */
	struct rw_semaphore mmap_sem;
	struct list_head mmlist; 		 /* 所有 mm_struct 形成的链表 */
	...
	unsigned long total_vm; 		 /* 全部页面数目 */
	unsigned long locked_vm; 		 /* 上锁的页面数据 */
	unsigned long pinned_vm; 		 /* Refcount permanently increased */
	unsigned long shared_vm; 	 	 /* 共享页面数目 Shared pages (files) */
	unsigned long exec_vm; 			 /* 可执行页面数目 VM_EXEC & ~VM_WRITE */
	unsigned long stack_vm; 		 /* 栈区页面数目 VM_GROWSUP/DOWN */
	unsigned long def_flags;
	unsigned long start_code, end_code, start_data, end_data; /* 代码段、数据段 起始地址和结束地址 */
	unsigned long start_brk, brk, start_stack; /* 栈区 的起始地址，堆区 起始地址和结束地址 */
	unsigned long arg_start, arg_end, env_start, env_end; /* 命令行参数 和 环境变量的 起始地址和结束地址 */
	... /* Architecture-specific MM context */
	mm_context_t context; 		   /* 体系结构特殊数据 */
	/* Must use atomic bitops to access the bits */
	unsigned long flags; 				 /* 状态标志位 */
	...
	/* Coredumping and NUMA and HugePage 相关结构体 */
};

struct thread_info {
    unsigned long        flags;        /* low level flags */
    int            preempt_count;    /* 0 => preemptable, <0 => bug */
    mm_segment_t        addr_limit;    /* address limit */
    struct task_struct    *task;        /* main task structure */
    struct exec_domain    *exec_domain;    /* execution domain */
    __u32            cpu;        /* cpu */
    __u32            cpu_domain;    /* cpu domain */
    struct cpu_context_save    cpu_context;    /* cpu context */
    __u32            syscall;    /* syscall number */
    __u8            used_cp[16];    /* thread used copro */
    unsigned long        tp_value;
    struct crunch_state    crunchstate;
    union fp_state        fpstate __attribute__((aligned(8)));
    union vfp_state        vfpstate;
    unsigned long        thumbee_state;    /* ThumbEE Handler Base register */
    struct restart_block    restart_block;
};

//#define THREAD_SIZE		8192
union thread_union {
    struct thread_info thread_info;
    unsigned long stack[THREAD_SIZE/sizeof(long)];
};
//内核栈被放在特殊的段中：__(".data.init_task")))
union thread_union init_thread_union __attribute__((__section__(".data.init_task"))) = { INIT_THREAD_INFO(init_task) };
ENTRY(stack_start)
    .long init_thread_union+THREAD_SIZE
    .long __BOOT_DS
默认跟中断栈共享，可以通过内核配置项修改。它属于进程，即每个进程都有自己的内核栈

```

**内核栈的产生**<br>
在进程被创建的时候，fork族的系统调用中会分别为内核栈和struct task_struct分配空间，调用过程是：fork族的系统调用--->do_fork--->copy_process--->dup_task_struct
在dup_task_struct函数中:

```cpp
static struct task_struct *dup_task_struct(struct task_struct *orig)
	struct task_struct *tsk = alloc_task_struct_node(node); //使用内核的slab分配器去为所要创建的进程分配struct task_struct的空间
	struct thread_info *ti = alloc_thread_info_node(tsk, node);//使用内核的伙伴系统去为所要创建的进程分配内核栈（union thread_union ）空间
	err = arch_dup_task_struct(tsk, orig);//
	tsk->stack = ti;//关联了struct task_struct和内核栈
	|--> setup_thread_stack(tsk, orig);//void setup_thread_stack(struct task_struct *p, struct task_struct *org) 关联了内核栈和struct task_struct
		//#define task_thread_info(task)	((struct thread_info *)(task)->stack)
		//#define task_stack_page(task)	((task)->stack)
		*task_thread_info(p) = *task_thread_info(org);
		task_thread_info(p)->task = p;
	...

static inline struct thread_info *current_thread_info(void)
{
	register unsigned long sp asm ("sp");
	return (struct thread_info *)(sp & ~(THREAD_SIZE - 1));
}
//#define get_current() (current_thread_info()->task)
//#define current get_current()
从上面定义就清楚 current 指针是如何实现的了；另外，由于栈空间的限制，在编写的驱动（特别是被系统调用使用的底层函数）中要注意避免对栈空间消耗较大的代码，比如递归算法、局部自动变量定义的大小等等
```


![进程内存空间结构](pic_dir/进程内存空间结构.png)

**进程栈的动态增长实现**<br>
进程在运行的过程中，通过不断向栈区压入数据，当超出栈区容量时，就会耗尽栈所对应的内存区域，这将触发一个 缺页异常 (page fault)。通过异常陷入内核态后，异常会被内核的 expand_stack() 函数处理，进而调用 acct_stack_growth() 来检查是否还有合适的地方用于栈的增长。如果栈的大小低于 RLIMIT_STACK（通常为8MB），那么一般情况下栈会被加长，程序继续执行，感觉不到发生了什么事情，这是一种将栈扩展到所需大小的常规机制。然而，如果达到了最大栈空间的大小，就会发生 栈溢出（stack overflow），进程将会收到内核发出的 段错误（segmentation fault） 信号。动态栈增长是唯一一种访问未映射内存区域而被允许的情形，其他任何对未映射内存区域的访问都会触发页错误，从而导致段错误。一些被映射的区域是只读的，因此企图写这些区域也会导致段错误。

### 4.2 重要函数解析

 整个系统的内存由一个名为node_data 的struct pglist_data（page_data_t） 指针数组来管理。分析可以开始于此．

```cpp
unsigned long vm_brk(unsigned long addr, unsigned long len)
unsigned long do_mmap_pgoff(struct file *file, unsigned long addr,unsigned long len, unsigned long prot, unsigned long flags, unsigned long pgoff,	unsigned long *populate)

```

## 5
### 5.1

## 6
