# 开发中问题

### 修订记录
| 修订说明 | 日期 | 作者 | 额外说明 |
| --- |
| 初版 | 2017/09/25 | 员清观 | 常用操作索引，尽量简短方便使用 |

----
## spi和p2p待确定
1. xr871应该必须rx中断中确认dma结束，确认一下问题
2. xr871是否可以设定唤醒封包？我们p2p供应商反复提到在其他的方案中wifi芯片中可以设定唤醒封包，wifi芯片只有收到这种特定格式的封包之后才会唤醒MCU,请问xr871有这种支持么？我现在看到的是，只要xr871收到目标为自己ip的网络包，就会唤醒。
3. 交互16字节数据时候，出现0x5a接收为0x2d的情况，刚好整体偏移了一位，降低时钟到24m之后问题没有了。之前批量发送的时候没有发现这个问题。
4. 需要确认wifi长期压力测试表现，全速率和1mbps两种情况
5. 确认p2p链接到锥形NAT上测试时候，p2p是否能够正常。
6. 应该在pc/xr871/c20上定义多个发送接收的client,只需要各自指定每个部分的id就可以完成一项特别的测试。基本的spi测试，最好直接spi接口增加测试命令定义。
7. 环境问题：
  1. 快速初始化
  2. 使用nfs加载，或者其他方式直接下载当前测试程序
  3. 简化wifi启动方式
  4. usb方式启动

字帖．儿子书架．
cat /proc/pagetypeinfo
    /proc/vmallocinfo

alloc_contig_range()函数中调用了__free_pages函数,是否应该直接把CMA分配剩下的内存整块释放,而不是逐个释放
  某次申请大块内存之后,后面的小块内存,如果migrate_off,作为cma order0被管理;否则,作为moveable page被管理,两者都是不可靠的做法.后者给非moveable类型的内存申请一个可乘之机.
  migrate_off的情况下,应该彻底脱离伙伴系统的管理,而不是现在这样bitmap和伙伴系统双层管理;否则,不能 把剩余内存丢到可移动内存部分管理,这会否导致无法移动?增加测试代码确认一下,检查是否has_unmovable_pages()函数会返回true

audio_chn_fmt_t fmt;
audio_get_initial_fmt(&fmt);
int handle = audio_get_channel_ex(pcm_name, &fmt, CHANNEL_BACKGROUND);


## 07-30->...

```cpp

```
## 07-23->...
**07-24**<br>

除了足够的fr内存之外，videobox启动还需额外的内存用于程序加载和堆栈等，这个大小缺省是8M，通过ulimit -s 1024可以调整缺省堆栈为1M，那么至少仍然需要3.5M。所以如果应用在videobox之前启动并占用大量内存的情况下，videobox可能因为普通内存不足而启动失败。
//预留34M
cma -f 0 -s 4 -m 3500 -l 1 -t 1 &
//预留35M
cma -f 0 -s 4 -m 3300 -l 1 -t 1 &
sleep 1
cat /proc/meminfo > /dev/null;echo 3 > /proc/sys/vm/drop_caches;cat /proc/meminfo | grep "MemFree"
ulimit -s 1024
videoboxd &

//对比测试1： 允许迁移
//老版本允许迁移videobox终止；新版本cma测试程序终止
cma -f 0 -s 4 -m 5000 -l 1 -t 1 & 直接
sleep 1
videoboxd &

当应用程序申请过多内存时，保护videobox启动，预留足够的fr, 但是mmap内存怎么办？
保护videobox启动，

cma迁移的配置以及预留fr内存的机制，会影响到应用可用内存，测试如下：
//应用程序可用内存测试,保障videobox在3s内完成启动
  //禁止迁移，测试程序可申请4k内存3100次
  cma -f 0 -s 4 -m 3100 -l 1 -t 1 &
  //允许迁移，预留35m，测试程序可申请4k内存3300次
  cma -f 0 -s 4 -m 3300 -l 1 -t 1 &
  //允许迁移，预留34m，测试程序可申请4k内存3500次
  cma -f 0 -s 4 -m 3500 -l 1 -t 1 &
  //允许迁移，无预留fr，测试程序可申请4k内存3700次
  cma -f 0 -s 4 -m 3700 -l 1 -t 1 &
  ulimit -s 1024
  sleep 1
  videoboxd


**07-23**<br>
```cpp
//cma测试程序
//#include <stdio.h>
//#include <stdlib.h>
//#include <unistd.h>
//#include <fcntl.h>
//#include <fr/libfr.h>

int main(int argc, char *argv[])
{
	int opt;
	int blksize = -1;
	int mblknum = -1;
	int cmaflag = 0;
	int fstep = -1;
	char echar;
	int loopcnt = -1;
	int curnum = 0;
	char str[20];
	void * (ptr[1024*32]);
	int total_malloc = 0;
	int total_free = 0;
	int total_fail = 0;
	int mblknum_loc;
	int wait_time = 2000;//seconds
	struct fr_info fr;
	char fr_name[128];

	memset(ptr, 0, sizeof(void*)*4096);

	while((opt = getopt(argc, argv, "s:m:f:l:w:t:"))!=-1) {
		switch (opt) {
		case 's':
			blksize = 1024*atoi(optarg);
			break;
		case 'm':
			mblknum = atoi(optarg);
			break;
		case 'f':
			fstep = atoi(optarg);
			break;
		case 'l':
			loopcnt = atoi(optarg);
			break;
		case 'w':
			wait_time = atoi(optarg);
			break;
		case 't':
			cmaflag = atoi(optarg);
			break;
		case '?':
			echar = (char)optopt;
			printf("argument error, opt char is \' %c \'!\n", echar);
			break;
		}
	}

	if (blksize <= 0 || mblknum <=0 || fstep <0 || loopcnt<=0 || mblknum >= 1024*32) {
		printf("error para value. %d, %d, %d, %d\n", blksize, mblknum, fstep, loopcnt);
		return -1;
	}
	printf("size=%08x, mblknum=%08x, fstep=%08x, loopcnt=%d, waittime=%d cmaflag=%d\n"
		, blksize, mblknum, fstep, loopcnt, wait_time, cmaflag);

		printf("start test loop %d\n", loopcnt);
		while(loopcnt-- > 0) {
			if (cmaflag & 0x1) {
				curnum = 0;
				mblknum_loc = mblknum;
				while (mblknum_loc-- > 0) {
					ptr[curnum] = malloc(blksize);
					if(ptr[curnum])
						memset(ptr[curnum], 1, blksize);
					else {
						total_fail++;
						printf("malloc(%d) failed %d, total: malloc=%d free=%d, fail=%d\n", blksize, ptr, total_malloc, total_free, total_fail);
					}
					if (fstep!=0 && curnum%fstep==0 && ptr[curnum]>0) {
						free(ptr[curnum]);
						ptr[curnum] = 0;
					}

					total_malloc++;
					curnum++;
				}
			}

			if (cmaflag & 0x2) {
				mblknum_loc = mblknum;
				while (mblknum_loc-- > 0) {
					snprintf(fr_name, sizeof(fr_name), "pid%d_%d", getpid(), mblknum_loc);
					if (fr_alloc(&fr, fr_name, blksize, 1) != 0) {
						total_fail++;
					}else
						;//printf("fr_name: %s\n", fr_name);
					total_malloc++;
				}
			}
		}

		if (cmaflag&0x4) {
			curnum -= 1;
			while (curnum > 0) {
				if(ptr[curnum]) {
					free(ptr[curnum]);
					total_free++;
				} else
					break;
				curnum -= 1;
				printf("cmaflag: %d curnum: %d\n", cmaflag, curnum);
			}
		}

		printf("\n~~~~~~~~~~~~~~~~~~~~~~~~End test: cmaflag=%d~~~~~~~~~~~~~~~~~~~~~~~~\n", cmaflag);
		sleep(500);

	return 0;
}

```
## 07-16->...
**07-20**<br>
**07-19**<br>
**07-18**<br>

**07-17**<br>
几种修改方式:
1. 所有的驱动中,dma_alloc_coherent()和dma_free_coherent()调用替换为新的函数接口,只需要在get_dma_ops()中添加一行
2. 所有的驱动中,dma_alloc_coherent()和dma_free_coherent()中dev参数变更为新的api接口对应的dev,set_dma_ops()函数关联两者
3. 驱动和fr分开申请内存
**07-16**<br>
```cpp
mmc_test 6 &测试:
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable

```
## 07-09->...
**07-13**<br>
确定预留内存方法,测试也发现,上层应用需要借用不到1M的CMA,否则运行错误.所以,节省内存是必须的.
修改kconfig文件的过程中,编译出错,然后就再也恢复不了;两种办法解决问题:1. 代码移植到另外一个目录 2. 比较发现了主要差异, git checkout /kernel/scripts尝试

trace控制
```cpp
extern int 	dmaconti_debug;
extern int 	dmabmp_debug;

//#define dmacontigdebug(fmt, args...) ({				\
	if (unlikely(dmaconti_debug))			\
		printk(KERN_DEBUG	"dma_contig::%s " fmt, __func__, ## args);		\
})

early_param("cma", early_cma);

```
**07-12**<br>
调整分配算法的实现,发现纠结点:预留的fr大小应该设定为多少.
**07-11**<br>
整理和移植bitmap算法的打印信息
**07-10**<br>
videobox启动关闭循环失败,跟踪之后发现是上层的问题;改变测试方法
**07-09**<br>
整理完成内存管理文档,最后使用html格式分享,和md转换最不会丢失信息.讨论完成之后,开始实现.
## 07-02->...
**07-06**<br>
**07-05**<br>
fr分配内存时, flag为 : GFP_KERNEL|__GFP_NOWARN 或者 GFP_KERNEL

**07-04**<br>
为bitmap增加诊断机制,文档化
**07-03**<br>
为bitmap增加诊断机制
**07-02**<br>
整理CMA实现算法
```cpp
//解析代码,一定要确保下面判断是无效的
if (PageHighMem(page))
//解析下面函数,详细
bitmap_find_next_zero_area()

addr = __alloc_from_contiguous(dev, size, prot, &page, caller);
int dma_alloc_from_coherent(struct device *dev, ssize_t size,dma_addr_t *dma_handle, void **ret)
pageno = bitmap_find_next_zero_area(cma->bitmap, cma->count, start, count, mask);
pageno = bitmap_find_free_region(mem->bitmap, mem->size, order);
  //没有对齐的操作,所以,应该使用bitmap_find_next_zero_area的一套接口来实现.

bitmap_find_next_zero_area()

//参考下面的函数来实现,或者,感觉可以直接使用
static void *__alloc_from_pool(size_t size, struct page **ret_page)
	struct dma_pool *pool = &atomic_pool;
	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
	align_mask = (1 << get_order(size)) - 1;
	spin_lock_irqsave(&pool->lock, flags);
	pageno = bitmap_find_next_zero_area(pool->bitmap, pool->nr_pages, 0, count, align_mask);
	bitmap_set(pool->bitmap, pageno, count);
	ptr = pool->vaddr + PAGE_SIZE * pageno; 	*ret_page = pool->pages[pageno];
	spin_unlock_irqrestore(&pool->lock, flags); 	return ptr;
static int __init atomic_pool_init(void)
	int bitmap_size = BITS_TO_LONGS(nr_pages) * sizeof(long);
	bitmap = kzalloc(bitmap_size, GFP_KERNEL);
	pages = kzalloc(nr_pages * sizeof(struct page *), GFP_KERNEL);
	ptr = __alloc_from_contiguous(NULL, pool->size, prot, &page, atomic_pool_init);
	for (i = 0; i < nr_pages; i++)			pages[i] = page + i;
	spin_lock_init(&pool->lock);
  pool->vaddr = ptr;		pool->pages = pages;		pool->bitmap = bitmap;		pool->nr_pages = nr_pages;
}
//下面函数改写,增加对应的init函数,控制好所有对应的bitmap.
void *__alloc_from_contiguous(struct device *dev, size_t size, pgprot_t prot, struct page **ret_page, const void *caller)

模仿atomic_pool_init()函数,分配内存部分,好像bitmap已经初始化过
cma_create_area()函数中初始化,和atomic_pool_init()地位相同
cma初始化的时候,每个page增加下面处理:
  __dma_clear_buffer(page, size);
    void *ptr = page_address(page);
  	memset(ptr, 0, size);
  	dmac_flush_range(ptr, ptr + size);
  	outer_flush_range(__pa(ptr), __pa(ptr) + size);//eric : empty function
  __dma_remap(page, size, prot);
    apply_to_page_range(&init_mm, start, size, __dma_update_pte, &prot);
  	dsb();
  	flush_tlb_kernel_range(start, end);
  ptr = page_address(page);
```

----
## 06-25->06-29
**06-28**<br>
请假,带父亲到医院检查心功能.
**06-28**<br>
感觉,可以直接移植最新版本的coherent.c函数中内容,初始化的时候直接增加core_init,保证在普通驱动之前初始化就好.
CONFIG_CMA 估计不能禁止
不是必须用fr的struct device指针作为申请内存时的dev参数,直接使用全局的就好. 在新的驱动文件中定义,core_init函数中申请并且使用系统全局的CMA初始化.



```cpp
struct cma *dma_contiguous_default_area; //包含了

void __init arm_memblock_init(struct meminfo *mi, struct machine_desc *mdesc)
  dma_contiguous_reserve(min(arm_dma_limit, arm_lowmem_limit));

```
void dma_contiguous_early_fixup(phys_addr_t base, unsigned long size);

struct dma_coherent_mem {
	void		*virt_base;
	dma_addr_t	device_base;
	unsigned long	pfn_base;
	int		size;
	int		flags;
	unsigned long	*bitmap;
	spinlock_t	spinlock;
	bool		use_dev_dma_pfn_offset;
};

dma_declare_coherent_memory
dma_init_coherent_memory

__dma_clear_buffer(page, size);
__dma_remap(page, size, prot);
ptr = page_address(page);

如果进入buddy,那么就会有clear和remap的要求,但如果不进入,那么直接计算就可以得到相关的地址信息.

可以直接给common CMA赋予一个

struct device *GLOBAL_CMA;

//#define dma_alloc_coherent(d, s, h, f) dma_alloc_attrs(d?d:GLOBAL_CMA, s, h, f, NULL)

或者修改下面函数就好, dev为NULL的时候,不调用arm_dma_ops,直接

static inline struct dma_map_ops *get_dma_ops(struct device *dev)
{
	if (dev && dev->archdata.dma_ops)
		return dev->archdata.dma_ops;
	return &arm_dma_ops;
}

之后需要对比最新版本的情况.

用到的数据结构:
    struct dma_coherent_mem {
	    void		*virt_base;
	    dma_addr_t	device_base;
	    phys_addr_t	pfn_base;
	    int		size;
	    int		flags;
	    unsigned long	*bitmap;
    };
    struct dma_coherent_mem	*dma_mem; /* internal for coherent mem
        mem->size
        mem->bitmap
        mem->device_base
        mem->virt_base
        mem->flags
        dev的用处应该只是获取到这个指针.
    //struct cma *cma_area;		/* contiguous memory area for dma


dma_declare_coherent_memory()函数申请这个指针和对应内存,并且初始化之

**06-27**<br>
**需求**
videobox和客户应用共享使用CMA内存,内存总容量够用的前提下,videobox可能会在某些场景下分配大块连续内存失败.已知场景至少包括:
- 客户高优先级程序和videobox进程同时后台启动,竞争CMA内存,可以参考`RM#6667 videobox 启动出现几率性失败`
- videobox改变分辨率

`RM#6667`问题中david已经确认在内核配置中打开CONFIG_CMA_MIGRATE_OFF的宏,禁止用户程序对CMA内存的抢占,可以避免上述情况的出现. 本文的目标是尝试改善内存管理的方式,允许用户程序占用CMA内存的情况下,避免videobox在剩余内存足够的情况下分配连续内存失败. 客户程序恶意占用过量内存的情况不在本文考虑范围内.

**分析1 内存资源两种统计管理方式**<br>
- bitmap算法,CMA中每一个page都对应bitmap中一个bit,此bit为1代表page已经被分配,为0代表空闲.分配连续内存的时候,在bitmap中寻找第一个连续为0的bit区域,并设置为1;释放内存的时候将此bit区域清0
- 伙伴系统,这是linux内存管理基本算法,不在此介绍;videobox和客户应用共享使用CMA内存的时候,CMA内存初始化时会被释放到伙伴系统中.

**分析2 cma内存申请和释放流程**<br>
下面大概列出申请和释放cma内存的基本调用流程:
```cpp
dma_alloc_coherent(dev, ...)
  |--> dma_alloc_attrs(dev, ...)
    |--> arm_dma_alloc(dev, ...)
      //if (dma_alloc_from_coherent(dev, size, handle, &memory))  return memory;
      |--> return __dma_alloc(dev, size, handle, gfp, prot, false,__builtin_return_address(0)); //dev非空的情况
        |--> return __alloc_from_contiguous(dev, size, prot, &page, caller);
          |--> page = dma_alloc_from_contiguous(dev, count, order);
            pageno = bitmap_find_next_zero_area(cma->bitmap, cma->count,start, count, mask);//从bitmap中找到符合条件的连续内存
            pfn = cma->base_pfn + pageno;
            ret = alloc_contig_range(pfn, pfn + count, MIGRATE_CMA);//从伙伴系统中申请内存
            bitmap_set(cma->bitmap, pageno, count);//在bitmap中标注内存已被占用
            return pfn_to_page(pfn);

dma_free_coherent(dev, ...)
  |--> dma_free_attrs(dev, ...)
    |--> __arm_dma_free(dev, ...)
      if (dma_release_from_coherent(dev, get_order(size), cpu_addr))  return;//dev非空的情况
      |--> __free_from_contiguous(dev, page, cpu_addr, size);
        |--> dma_release_from_contiguous(dev, page, size >> PAGE_SHIFT);
          bitmap_clear(cma->bitmap, pfn - cma->base_pfn, count); //清除bitmap中对应位域
          free_contig_range(pfn, count);//释放内存到伙伴系统
```

`dma_alloc_coherent()`函数第一个参数`dev`确定了它的两种主要使用场景:<br>
- `dev`为`NULL`
  同时使用了bitmap和伙伴系统两种算法管理内存<br>
  申请系统公有的CMA,当前fr和驱动模块都是此种方式<br>
- `dev`为具体设备指针
  仅使用bitmap算法管理内存<br>
  设备独享自定义的私有CMA,当前系统中未使用此种方式<br>

**分析3 改进方向**<br>

videobox分配内存失败后`cat /proc/pagetypeinfo`的显示结果如下:
```
  Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10
Node    0, zone   Normal, type    Unmovable      0      1      2      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type  Reclaimable     70     92     52      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type      Movable      0      0      0      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type      Reserve      0      0      0      1      0      0      1      1      1      1      0
Node    0, zone   Normal, type          CMA   2161   2160    356      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0

Number of blocks type     Unmovable  Reclaimable      Movable      Reserve          CMA      Isolate
Node 0, zone   Normal            1            1            3            1           10            0
```

用户的应用程序大量抢占CMA的内存后产生过多CMA内存碎片,导致videobox无法申请到足够长的连续内存. 基于此,有两个疑点:
- 碎片过于琐碎,完全没有8或更多page的碎片,怀疑分配算法是否合理
- 伙伴系统有碎片整理的能力,但没有生效,怀疑碎片回收的算法有缺陷

比较系统的跟踪内核相关内存管理部分逻辑之后,我认为现有的cma机制本身如果能够解决上面两个问题,可以满足我们内存使用的需求

**CMA迁移算法bug**<br>
跟踪应用层`malloc()`函数调用流程到`__alloc_pages_nodemask()`

```cpp
__alloc_pages_nodemask()
  |--> get_page_from_freelist()
    |--> buffered_rmqueue()
      |--> __rmqueue()
        page = __rmqueue_smallest(zone, order, migratetype);
        if (unlikely(!page) && migratetype != MIGRATE_RESERVE)
          |--> page = __rmqueue_fallback(zone, order, migratetype);
            for (current_order = MAX_ORDER-1; current_order >= order; --current_order) {
  		        for (i = 0;; i++) {
                migratetype = fallbacks[start_migratetype][i];
                ...
              }
            }
```

应用层调用`__rmqueue_smallest()`申请不到通用内存时,就会调用`__rmqueue_fallback()`从CMA申请内存. 阅读代码时发现逻辑上存在严重问题,检查分配的循环每次从`current_order = MAX_ORDER-1`开始,也就是说每次优先分配最大的内存块,这种逻辑就是个内存粉碎器. 比如我们有10个4M大小的CMA块,10次调用分配之后,哪怕只是分配4k小内存,我们就只剩下10个2M大小的块和大量小碎片;反复大量调用后,最后就只会剩下4k和8k碎片.

简单尝试修改逻辑如下进行测试,不会再出现碎片:
```cpp
  ...
    for (current_order = order; current_order <= MAX_ORDER-1; current_order++) {
    		for (i = 0;; i++) {
        }
    }
```

查看最新linux4.18 kernel,这部分代码也已经被修正,系统优先分配小的CMA块

**碎片整理问题**<br>
这涉及到更复杂的流程,尚未发现问题根源,需要更多时间跟踪. 这应该是超量碎片场景下会出现的问题,修正内存分配算法中逻辑错误之后,没有再次发现

**06-26**<br>

void show_free_areas(unsigned int filter)

void refresh_cpu_vm_stats(int cpu)  计算cpu内存

void drain_zonestat(struct zone *zone, struct per_cpu_pageset *pset)

void zone_page_state_add(long x, struct zone *zone,enum zone_stat_item item)
unsigned long zone_page_state(struct zone *zone,	enum zone_stat_item item)

unsigned long global_page_state(enum zone_stat_item item)
unsigned long zone_page_state(struct zone *zone,enum zone_stat_item item)
void __inc_zone_state(struct zone *zone, enum zone_stat_item item)
__inc_zone_page_state(struct page *page,enum zone_stat_item item)
void __dec_zone_state(struct zone *zone, enum zone_stat_item item)

**06-25**<br>
----
## 06-18->06-22
**06-22**<br>
本周进展:
1.跟踪CMA机制内存alloc过程,发现可移动页不足导致从CMA迁移的时候分配算法不合理,会导致CMA内存出现大量碎片;简单尝试修改算法之后,不再出现碎片,在系统绝大部分内存都被分配出去的场景下,前者为videobox分配内存失败而后者成功;
2.跟踪CMA机制内存free过程,确认了CMA机制中包含对可移动页的碎片整理功能,只是客户的场景中碎片整理失败;暂时停止此方向的跟踪,等确定最终实现方案之后再决定是否继续分析解决;
3.经过简单尝试确定,现有机制的基础上使用dma_declare_coherent_memory()和dma_contiguous_reserve()就可以比较方便的实现fr设备独享CMA


[2018-06-25 11:15:55.966] Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10     11
[2018-06-25 11:15:55.978] Node    0, zone   Normal, type    Unmovable      0      0      0      0      0      0      0      0      0      0      0      0
[2018-06-25 11:15:55.989] Node    0, zone   Normal, type  Reclaimable      0     10     13      6      0      1      1      0      1      0      1      0
[2018-06-25 11:15:56.000] Node    0, zone   Normal, type      Movable      0      0      0      0      0      0      0      0      0      0      0      0
[2018-06-25 11:15:56.011] Node    0, zone   Normal, type      Reserve      0      0      0      0      0      0      0      0      0      0      0      1
[2018-06-25 11:15:56.023] Node    0, zone   Normal, type          CMA      0      0      0      0      1      0      3      0      1      0      1      3
[2018-06-25 11:15:56.034] Node    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0      0
[2018-06-25 11:15:56.045]
[2018-06-25 11:15:56.046] Number of blocks type     Unmovable  Reclaimable      Movable      Reserve          CMA      Isolate
[2018-06-25 11:15:56.054] Node 0, zone   Normal            0            1            2            1            4            0
[2018-06-25 11:15:56.063] ~~~~~~~~~~~~~~mes_len: 52~~~~~~~~~~~~~~~
[2018-06-25 11:15:56.080] @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@malloc failed: 3584
[2018-06-25 11:15:56.259] ~~~~~~~~~~~~~~mes_len: 52~~~~~~~~~~~~~~~
[2018-06-25 11:15:59.985] Page block order: 11
[2018-06-25 11:15:59.987] Pages per block:  2048
[2018-06-25 11:15:59.989]
[2018-06-25 11:15:59.989] Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10     11
[2018-06-25 11:16:00.000] Node    0, zone   Normal, type    Unmovable      0      0      0      0      0      0      0      0      0      0      0      0
[2018-06-25 11:16:00.012] Node    0, zone   Normal, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      0      0
[2018-06-25 11:16:00.023] Node    0, zone   Normal, type      Movable      0      1      0      0      0      0      0      0      0      0      0      0
[2018-06-25 11:16:00.034] Node    0, zone   Normal, type      Reserve      0      0      2      0      1      1      1      1      1      1      1      0
[2018-06-25 11:16:00.045] Node    0, zone   Normal, type          CMA      0      1      0      0      0      0      0      1      1      0      1      2
[2018-06-25 11:16:00.057] Node    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0      0


**06-21**<br>
设计mmc_test程序,大量分配内存,然后加载videobox的时候,可能因为没有足够的页缓存,有时候20+s才会加载成功程序,然后杀掉mmc_test程序释放内存.

__rmqueue_fallback 的借用顺序也应该调整: 应该在cma已经没有可以借用的时候,再去借用MIGRATE_RECLAIMABLE,现在的代码,是优先借用高order的,同order有限cma的,这样是有问题的.MIGRATE_RECLAIMABLE缺少会导致程序加载速度很慢.

moveable好像从开始就没分配,但显示2个,不知道怎么回事.

我们可以软件配置定义一个上限, 超过这个上限, 不能

记得,海思当时的方案,支持的通道配置变化的时候,需要先释放所有的通道,然后重新分配.
几个方案:
- 兼容之前的CMA方式,解决bug,这是尽量给客户提供更多可用内存的方式,可以考虑让可回收页面占用部分cma内存
- 使用一个cma,禁止客户fallback,使用coherent的bitmap机制管理cma;当前实际上使用的伙伴系统
- 两个cma,一个
实际执行:
- 增加接口,可以让设备申请自己的cma接口
-
**06-20**<br>
migratetype:2 4 current_order:0 a page: c033a000
migratetype:2 4 current_order:0 a page: c0332000
migratetype:2 4 current_order:0 a page: c032a000
migratetype:2 4 current_order:0 a page: c0322000
migratetype:2 4 current_order:0 a page: c031a000
migratetype:2 4 current_order:0 a page: c0312000
migratetype:2 4 current_order:0 a page: c030a000
migratetype:2 4 current_order:0 a page: c0302000
migratetype:2 4 current_order:0 a page: c02fa000
migratetype:2 4 current_order:0 9 page: c02fe000
migratetype:2 4 current_order:0 9 page: c0306000
migratetype:2 4 current_order:0 9 page: c030e000
migratetype:2 4 current_order:0 9 page: c0316000
migratetype:2 4 current_order:0 9 page: c031e000
migratetype:2 4 current_order:0 9 page: c0326000
migratetype:2 4 current_order:0 9 page: c032e000
migratetype:2 4 current_order:0 9 page: c032e000
migratetype:2 4 current_order:0 9 page: c0336000
migratetype:2 4 current_order:0 9 page: c033e000
migratetype:2 4 current_order:0 9 page: c02f6000
migratetype:2 4 current_order:0 8 page: c02f8000
migratetype:2 4 current_order:0 8 page: c0340000
migratetype:2 4 current_order:0 8 page: c0338000
migratetype:2 4 current_order:0 8 page: c0330000
migratetype:2 4 current_order:0 8 page: c0328000
migratetype:2 4 current_order:0 8 page: c0320000
migratetype:2 4 current_order:0 8 page: c0318000
migratetype:2 4 current_order:0 8 page: c0310000
migratetype:2 4 current_order:0 8 page: c0308000
migratetype:2 4 current_order:0 8 page: c0300000
migratetype:2 4 current_order:0 8 page: c02fc000
migratetype:2 4 current_order:0 8 page: c0304000
migratetype:2 4 current_order:0 8 page: c030c000
migratetype:2 4 current_order:0 8 page: c0314000
migratetype:2 4 current_order:0 8 page: c031c000
migratetype:2 4 current_order:0 8 page: c0324000
migratetype:2 4 current_order:0 8 page: c032c000
migratetype:2 4 current_order:0 8 page: c0334000
migratetype:2 4 current_order:0 8 page: c033c000
migratetype:2 4 current_order:0 8 page: c02f4000
migratetype:2 4 current_order:0 8 page: c0326000
migratetype:2 4 current_order:0 8 page: c031e000
migratetype:2 4 current_order:0 8 page: c0316000
migratetype:2 4 current_order:0 8 page: c030e000
migratetype:2 4 current_order:0 8 page: c0306000
migratetype:2 4 current_order:0 8 page: c02fe000
migratetype:2 4 current_order:0 8 page: c02fa000
migratetype:2 4 current_order:0 8 page: c0302000
migratetype:2 4 current_order:0 8 page: c030a000
migratetype:2 4 current_order:0 8 page: c0312000
migratetype:2 4 current_order:0 8 page: c031a000
migratetype:2 4 current_order:0 8 page: c0322000
migratetype:2 4 current_order:0 8 page: c032a000
migratetype:2 4 current_order:0 8 page: c0332000
migratetype:2 4 current_order:0 8 page: c033a000
migratetype:2 4 current_order:0 7 page: c033b000
migratetype:2 4 current_order:0 7 page: c0333000
migratetype:2 4 current_order:0 7 page: c032b000
migratetype:2 4 current_order:0 7 page: c0323000
migratetype:2 4 current_order:0 7 page: c031b000
migratetype:2 4 current_order:0 7 page: c0313000
migratetype:2 4 current_order:0 7 page: c030b000
migratetype:2 4 current_order:0 7 page: c0303000
migratetype:2 4 current_order:0 7 page: c02fb000
migratetype:2 4 current_order:0 7 page: c02ff000
migratetype:2 4 current_order:0 7 page: c0307000
migratetype:2 4 current_order:0 7 page: c030f000
migratetype:2 4 current_order:0 7 page: c0317000
migratetype:2 4 current_order:0 7 page: c031f000
migratetype:2 4 current_order:0 7 page: c0327000
migratetype:2 4 current_order:0 7 page: c02f5000
migratetype:2 4 current_order:0 7 page: c033d000
migratetype:2 4 current_order:0 7 page: c0335000
migratetype:2 4 current_order:0 7 page: c032d000
migratetype:2 4 current_order:0 7 page: c0325000
migratetype:2 4 current_order:0 7 page: c031d000
migratetype:2 4 current_order:0 7 page: c0315000
migratetype:2 4 current_order:0 7 page: c030d000
migratetype:2 4 current_order:0 7 page: c0305000
migratetype:2 4 current_order:0 7 page: c02fd000
migratetype:2 4 current_order:0 7 page: c0301000
migratetype:2 4 current_order:0 7 page: c0309000
migratetype:2 4 current_order:0 7 page: c0311000
migratetype:2 4 current_order:0 7 page: c0319000
migratetype:2 4 current_order:0 7 page: c0321000
migratetype:2 4 current_order:0 7 page: c0329000
migratetype:2 4 current_order:0 7 page: c0331000
migratetype:2 4 current_order:0 7 page: c0339000
migratetype:2 4 current_order:0 7 page: c0341000
migratetype:2 4 current_order:0 7 page: c02f9000
migratetype:2 4 current_order:0 7 page: c02f7000
migratetype:2 4 current_order:0 7 page: c033f000
migratetype:2 4 current_order:0 7 page: c0337000
migratetype:2 4 current_order:0 7 page: c032f000

Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10
Node    0, zone   Normal, type    Unmovable      0      0      0      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type      Movable      0      0      0      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type      Reserve      0      0      2      0      0      1      1      1      0      1      0
Node    0, zone   Normal, type          CMA   1783      0      0      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0

Free pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10
Node    0, zone   Normal, type    Unmovable      0      0      0      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type      Movable      0      0      0      0      0      0      0      0      0      0      0
Node    0, zone   Normal, type      Reserve      2      1      1      0      1      1      0      1      0      1      0
Node    0, zone   Normal, type          CMA      1      1      0      0      0      0      0      1      1      1      1
Node    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0

cat /proc/pagetypeinfo

**06-19**<br>
**06-18**<br>
----
## 06-11->06-15
**06-15**<br>
内存管理学习

qiwo_lanch_dropcaches()
{
	while [ -f "/tmp/drop" ]; do
		echo 3 > /proc/sys/vm/drop_caches
		usleep 1000
	done
	echo "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~dropceches stopped!"
}
qiwo_lanch_ceva_dsp()
{
	modprobe ceva-dsp
	touch /tmp/ceva
}
qiwo_lanch_videobox_cur()
{
	videoboxd > /dev/null 2>&1
	touch /tmp/video
}
qiwo_lanch_wifi_cur()
{
	qiwo_load_wifi_driver
	touch /tmp/wifi
}
case "$1" in
  start)
	echo "[ $VERSION ] start qiwo custum script.";

	mount -t vfat /dev/spiblock2 /config
	modprobe Felix clkRate=80000000

	eventhub &

	touch /tmp/keep_power

	echo "start eventhub ."
	#qiwo_lanch_once_wifi
	touch /tmp/drop
	touch /tmp/wifi
	qiwo_lanch_dropcaches &
	while true; do
		#echo "start ceva_dsp ."
		qiwo_lanch_ceva_dsp &
		qiwo_lanch_videobox_cur &

		while [ ! -f "/tmp/ceva" ]; do
			usleep 1000
		done
		while [ ! -f "/tmp/video" ]; do
			usleep 1000
		done

		while [ ! -f "/tmp/wifi" ]; do
			usleep 1000
		done
		modprobe -r ceva-dsp
		#modprobe -r bcmdhd
		kill -9 $(pidof videoboxd)
		rm /tmp/ceva
		rm /tmp/video
		#rm /tmp/wifi

		#dmesg > /tmp/dmesg_info
		usleep 100000
	done

**06-14**<br>
extern int 	dmaconti_debug;
//#define dmacontigdebug(fmt, args...) ({				\
	if (unlikely(dmaconti_debug))			\
		printk(KERN_DEBUG	"dma_contig::%s " fmt, __func__, ## args);		\
})

dmacontigdebug("real alloc switch : %d", real_switch, (int)test1, (int)test2);

dmamapdebug("real alloc switch : %d", real_switch, (int)test1, (int)test2);


内存管理学习
**06-13**<br>
MIGRATE_UNMOVABLE,	MIGRATE_RECLAIMABLE,	MIGRATE_MOVABLE, MIGRATE_CMA,
从只读文件系统加载的程序,申请的内存应该是MIGRATE_MOVABLE,这样应该更好.
内存管理,需要考虑MIGRATE_RECLAIMABLE到MIGRATE_CMA的迁移可能.
**06-12**<br>
内存管理学习
**06-11**<br>
内存管理学习
----
## 06-04->06-08
**06-10加班**<br>
内存管理学习
**06-08**<br>
cma内存的申请和释放，以方便的方式dump出来，包含开始地址，大小等信息，按照顺序打印，列出hole等．

**06-07**<br>
阅读内存管理代码和资料
printk(KERN_EMERG "func:%s, %d~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n", __func__, __LINE__);

printk(KERN_EMERG "func:%s, %d~~~~~~~~~~~~~~~~~\n", __func__, __LINE__);
printk(KERN_EMERG "~~~~~~~~~func:%s, %d, (%x %x)\n", __func__, __LINE__
          , (int)test1, (int)test2);
printk(KERN_EMERG "~~~~~~~~~func:%s, %d, (phys:%x addr:%x pgd:%x)\n", __func__, __LINE__
					, (int)phys, (int)addr, (int)pgd);
memblock_dbg("memblock_reserve: [%#016llx-%#016llx] %pF\n",
		     (unsigned long long)base,
		     (unsigned long long)base + size,
		     (void *)_RET_IP_);

**06-06**<br>
阅读内存管理代码和资料

CMA问题，建立测试脚本，mmc_test程序，以多种不同的大小和方式申请内存，测试多种场景下CMA以及整个内存系统的状态变化，分析解决问题．
之后门铃项目中反映50Mhz工作不稳定，uboot容易出现启动失败，这应该是spimul两个时钟非同源导致．
增加记录，每个进程占用的内存．

整体修正：
http://gerrit.in.infotm.com/#/c/15770/

**06-05**<br>
RM #6625 -- BU2: 读写jffs2分区导致下次启动无法挂载文件系统
RM #6272 -- QSDK: [Allchip][BSP] 内核环境中SPI总线时钟无法工作在50MHz
问题分析解决：
之前完全无法工作在50MH，是因为clk.c中配置ssp-clk时，ENABLE 了 NCO　模式，时钟波形质量差．

代码上传：comment #4中已经包含

make app-d318-upgrade-rebuild;make

fix(spimul,spiblock): resolve a squashfs access error problem
this problem get caused by two issues: 1. ssp_clk and spibus_clk of spimul is generated from different PLL, this may cause bus error at high speed transmission; 2.spi_block read cache buffer have a bug which casue memory access out of bound
Close 6722

尝试16kblock size，和下层保持一致； 更新squashfs版本到4.2
印象中，mmc驱动每次数据最大128k；spi接口现在定义16k --> mmc->max_blk_size = 65536;mmc->max_seg_size = 0x1000;之类的设定

**06-04**<br>
[2018-06-05 13:33:05.460] blk:dc8 cnt:24 (105053, 125148) // 8成的数据读取是32个block．
      blk_cnt = ((offset_addr[segments+1] - offset_addr[0]) >> tr->blkshift);
			blk_addr = (block + (offset_addr[0] >> tr->blkshift));
			//ktime_get_ts(&ts_write_start);
			if (tr->read_multisect(dev, blk_addr, blk_cnt, spi_blk->cache_read_buf)) {
				ret = -EIO;
				break;
			}
			//ktime_get_ts(&ts_write_end);
			//printk("infotm %x spi %d %d read %d %d \n", buf, blk_addr, blk_cnt, (ts_write_end.tv_sec - ts_write_start.tv_sec), (ts_write_end.tv_nsec - ts_write_start.tv_nsec));
			for(i=0; i<(segments+1); i++) {
				buf = (char *)buf_addr[i];
				blk_cnt = ((offset_addr[i+1] - offset_addr[i]) >> tr->blkshift);
				memcpy(buf, spi_blk->cache_read_buf+offset_addr[i], blk_cnt<<tr->blkshift);
			}
spiblock_fs_read_multisect() 函数修改，直接读取到本地的buffer中就好，或者，spi部分实现sg dma机制．

可以考虑，跟踪一个完整的squshfs文件加载过程．

需要确定，调整时钟同源之后，boot和kernel阶段192m应该分频到32M？然后就是对pll022的影响？
cd config;touch test;touch drop;sync

uboot中spi读取数据块64k切换到4k，影响8%的效率(115ms--123ms).
int32_t ssp_manager_set_flash_type(uint32_t flash_type)
  spi_manager_g.flash_sector_size = 64*1024;

pl022最大一次读取4k，这才是最大的区别．
是否应该打印所有的flash访问请求呢？或者，最近的若干个．

----
## 05-28->06-01
**06-03加班**<br>
每次dma传输前后，都增加一定的延时，看是否能够解决问题!!!!!
降低分频之前的输入时钟，也许会有影响，之前出现300M输入需要改成150才能使用的情况．而且之前都是使用60M的时钟．
不知道太低会否不好，那么就再试试看4倍频吧．
之前的测试，重新使用低频率试试看．
测试发现，使用单个总线时钟就可以驱动spi接口了．

**06-02加班**<br>

脚本中增加限制，保证videobox在ceva_dsp加载成功之后启动，不清楚两者之间是否存在有某种互斥关系．

禁止mmc0

qiwo_lanch_dropcaches()
{
	while [ -f "/config/test" ]; do
		echo 3 > /proc/sys/vm/drop_caches
		usleep 10000
	done
	echo "dropceches stopped!"
}

请不要忽略：　Bus error

**06-01**<br>
请假，上午去中山医院，下午国际象棋
**05-31**<br>

根据这几天的测试，如下操作可以保证不会出现当前问题：
1. Felix，videoboxd，qiwo_load_wifi_driver保持前台运行
2. 取消drop_caches操作
估计这个问题和内存占用有关，进一步分析需要更多时间．
感觉drop_caches操作应该是清理了cache，导致立刻需要读取填充大量数据，导致问题；总线频率太高，是否同样的情况？不断在各个进程之间颠簸．
单线spi没有这个问题，

下一步：　禁止drop_caches再次尝试
echo 4 > /proc/sys/vm/dirty_background_ratio
echo 8 > /proc/sys/vm/dirty_ratio
printk(KERN_EMERG "fragment_cache: (%d, %d)\n", SQUASHFS_CACHED_FRAGMENTS, msblk->block_size);
禁止squashfs的cache如何？
```cpp
//基本的清理过程，但实际上没有任何意义
free -m
sync
cat /proc/sys/vm/drop_caches
echo 3 > /proc/sys/vm/drop_caches
cat /proc/sys/vm/drop_caches
```
整理清楚：uboot0启动时part和其他传入kernel的参数的管理

感觉有可能是squashfs中存在的一个bug,cache相关的，cache已经被回收，但内核继续索引使用．
最新修改的脚本去掉sleep;
恢复其他所有的脚本，只去掉echo 3 > /proc/sys/vm/drop_caches看看结果如何．

**05-30**<br>
下一步，d318等程序，移动到videobox之后启动，而且应该保证videobox启动完毕．

内核加载程序时增加打印信息，记录时间:
static int do_execve_common(const char *filename,
  if((strcmp(filename, "/usr/bin/audiobox") == 0) || (strcmp(filename, "/usr/bin/videoboxd") == 0)
		|| (strcmp(filename, "/usr/bin/d318") == 0)
		|| (strcmp(filename, "/usr/bin/systemmsg") == 0)
		|| (strcmp(filename, "/usr/bin/d318") == 0))
		printk(KERN_EMERG "~~~~~start exec: %s at [%d]\n", filename, jiffies);

可以考虑同时启动包括videobox在内的多个程序，也许出现几率更高．
  就算是不重现，比较并行启动和串行启动的时间长度．

videoboxd延时
[2018-05-30 09:59:01.204] Ispostv2: ispost_open
[2018-05-30 09:59:01.207] SQUASHFS error: lzo decompression failed, data probably corrupt
时间非常接近，所以，有可能会造成影响．

ispost_open 开始和结束的时候，增加打印
调整代码，改变时钟的时候刚好在读取文件．或者，测试程序后台运行，读取几个典型的大文件．
videoboxd加载之前的900ms延时，真是有毛病．

弄清楚，
1. item文件的part部分是如何解析的
2. ftl的模块化机制
3. mtd功能

几种烧录方式流程：
1. upgrade流程
2. d318-upgrade，客户自定义流程
3. uboot1烧录

**05-29**<br>
make app-d318-upgrade-rebuild;make
mkdir /mnt/sd4
mount -t squashfs /dev/spiblock1 /mnt/sd4
mkdir /mnt/sd3
mount -t vfat /dev/mmcblk0p1 /mnt/sd3
cp -fr / /mnt/sd3
cp -fr -L /usr /mnt/sd3

**05-28**<br>
Unable to read page, block 4f5556, size 1515a
SQUASHFS error: ~~~2 lzo decompression failed: -5, out_len:0x15eb7

读取：
//１．位宽改为每次读取16bits
２．6 dummy cycles 需要确认一下，什么意思
３．试试看降低时钟，看起来好像很难出现，很奇怪，好像复现过，但现在无法重现．
４．尝试去掉 SPI_NOR_QUAD_WRITE SPI_TX_QUAD 这两项
５．sd卡启动，反复读取flash，确认每次读取内容相同．
６．尝试，单线，35Mhz，是否会出现错误．
７．后台运行的程序，尝试全部提到前台来．
８．禁止mmc0初始化，根本没用到，看是否有影响．
９．内存不够，有可能吧，alloc_contig_range test_pages_isolated(41500, 417f8) failed
１０．squashfs上层再次读取并解压
１１．spi驱动层确定读取错误原因
１２．使用高倍率分频(8)，并尝试 imapx_spi_probe()函数中禁止：
    `clk_set_rate(host->extclk, host->master_info->extclk_rate);`
１３．应该考虑调整busclk
１４．尝试polling方式4线测试
１５．尝试kernel中启动wifi和ddk驱动等，或者，kernel启动时初始化相关时钟．
１６．尝试，降低cpu整体时钟．

repo init -u ssh://eric.yun@gerrit.in.infotm.com:29418/manifest/buildroot -b qipc_qiwo_doorbell_dev
repo sync -c
repo start develop --all

**也许倍频因子也有影响，至少应该是４，２会出问题？**
如果是这样，提高原始clk，设置：
  `DEV_CLK_INFO(SSP_CLK_SRC, 0, EPLL, 0, 4, DISABLE),`
  `.extclk_rate = 120000000 /*50MHZ*/`

或者，在底层增加判断，每批数据读取两次，然后进行比较，不同的话，打印错误，以确认问题．　
Dear david,
分支：   qipc_qiwo_doorbell_dev
下载完后做修改两处代码
1.按照如下diff，后修改一个文件
mqd@mqd-OptiPlex-3020:~/2018/qiwo/qipc_qiwo_doorbell_dev_squashfserror/system$ git diff
diff --git a/d318/S22qiwo_ff b/d318/S22qiwo_ff
index 862cf68a..a0c0e2aa 100755
--- a/d318/S22qiwo_ff
+++ b/d318/S22qiwo_ff
@@ -787,8 +787,8 @@ case "$1" in

        echo "[ $VERSION ] qiwo custum script end..."
        sleep 15;
-       cd /ff && ./autotest &;
-    ./autotest_videobox &
    cd /ff && ./autotest &

2.将system/d318/ff/下的autotest用该目录下的autotest-squashfserror替换
编译：　./tools/setproduct.sh   1   doorbell  0   PS5230DVP_NEW.json  0   ps5230dvp
    使能4k block
    make app-d318-upgrade-rebuild;make
    make d318-rebuild
    cat /proc/pagetypeinfo

  	eventhub &
	modprobe ceva-dsp &
	modprobe Felix clkRate=80000000 &

	echo "start eventhub ."

	qiwo_load_wifi_driver  > /dev/null ;
	qiwo_initdir  > /dev/null ;
	qiwo_check_if_to_set_network1  > /dev/null ;
	qiwo_lanch_videobox &
	echo "[ $VERSION ] lanch doorbell ";
	d318 &
	nice -n -20 systemmsg  > /dev/null &
	echo "[ $VERSION ] let doorbell start in backgroud. ";
	qiwo_lanch_audiobox > /dev/null  &
	qiwo_initial_wifi_info > /dev/null  &
	qiwo_nptd_initial > /dev/null &
	echo "[ $VERSION ] qiwo custum script end..."
	touch /tmp/keep_power
	echo "reboot 15s later..."
	sleep 15;
	cat /proc/fr_info
	frinfo_ok=`cat /proc/fr_info | grep -c 'Total: 23.65M'`;echo $frinfo_ok
	process_ok=`ps | grep -c -e 'videoboxd$' -e 'audiobox$' -e 'd318$'`;echo $process_ok
	echo ""
	echo "Show frinfo_ok : [ $frinfo_ok ] ... process_ok : [ $process_ok ]";
	echo ""
	if [ "$frinfo_ok" == "1" ]; then
		if [ "$process_ok" == "3" ]; then
			echo "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~initiate videobox ok~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
			reboot
		fi
	fi
  

----
## 05-21->05-25
**05-27**<br>
测试：　
1. 8字节对齐，原代码，问题重现
2. 64字节对齐，问题仍然重现
3. 恢复单线spi接口－－周一检查,没有重现，所以这是4ｌｉｎｅ相关的问题．
4. 尝试polling方式4线测试

**05-25**<br>
17:04开始测试
手机上resetting wifi重新绑定，按门铃按键启动程序，绑定的时候需要保证删除/confit/test文件．绑定完毕，重启，touch /config/test触发测试流程  d318.c qiwo_write_uart 2741  send usart data: aa 15 2 b5 b9 55　//2表示开启测试过程

spi驱动，如果使用全双工协议，那么最好在pl022中完成；怀疑spi-core的机制是否还合适，因为需要经常填充和发送空的消息，这个消息不应该来自于上层，而且为了保证效率，最好避开core的thread上下文，直接在pl022中维持发送和接收链表；
pump_transfers()函数中，调用 spi_get_next_queued_message()函数判断master队列为空，就直接封装简单消息接口；这需要增加 set_up_next_null_transfer()函数；

全双工方式下，发送空消息，或者上层tx_buf中信息；接收到的数据需要判断是否有效，无效就直接丢弃，有效，放到队列中．

上层接口：模仿net,发送和接收定义buffer. 阻塞读取，阻塞发送，

spi驱动层，只需要增加标志位，表明是否填充即可，最多加上有效长度．

spi_get_next_queued_message()函数可以直接取下一消息．

评价包含：
1. 整体评价，如能力，特点，长处等等
2. 突出业绩（如印象最深的，最有价值的等等，不要超过3个）


**05-24**<br>
内存管理基本机制学习;下午4:30－6:00 spi驱动会议；
**05-23**<br>
内存管理基本机制学习
**05-22**<br>
no_scatterlist_test 分支，调试并解决pl330 scatterlist 传输问题
另外一个不对头的地方，tasklet中调用callback,callback中包含有delay,这是不大合适的，考虑工作队列替代．
struct pl330_info *pi = &pch->dmac->pif;
dev_err(pi->dev, "~~~~~~~~ %s:%d!\n", __func__, __LINE__);

**05-21**<br>

fix(spimul): resolve a jffs2 mounting problem from anni project
this was caused by 4-line spi bus working with too small rx burst length, so adjust minimum dma rx burst length to 16 bytes for 4-line spi bus, to speed up dma transfer
Close 6625

mkfs.vfat /dev/spiblock2
umount /dev/spiblock2
mkdir /mnt/sd3
mount -t vfat /dev/spiblock2 /mnt/sd3

cp /bin/busybox /mnt/sd3
cp /mnt/sd3/busybox /mnt/sd0/b2

int len = 0;
if(len > 4096)
 		 pr_err("[spimul] 1~~~~~~~~~~~~~~~~~~~~~rx err:%d %d\n", __LINE__, len);

----
## 05-14->05-18
**05-20加班**<br>
linux驱动，宋宝华版本，前面几章基本过滤
**05-19加班**<br>
pl330文档，spi调整机制的分析．
**05-18**<br>
深入了解pl330机制以及分析测试之后，估计问题可能是因为每次dma搬运的burst数据太少(4bytes)，如果spi接收数据的速率超过dma通道搬运能力，就会出错；尝试降低spi频率到5M，如预期不会出现问题；尝试提升spi频率到60M,同时加大burst长度到64,如预期也不会出现问题．
**05-17**<br>
阅读pl330代码
**05-16**<br>
16字节对齐可以解决问题，继续分析根本原因．开始阅读pl330代码
**05-15**<br>
新硬件上重现问题，尝试比较出错jffs2分区和正常分区在写入相同内容时差别，无法找到分析依据；发现出错时最后数据长度3800，尝试512字节对齐，问题解决
**05-14**<br>
anni分支调试，总是出现jffs2的访问错误，但最后发现是硬件问题，烧录kernel和system失败．kernel启动提示，版本时间是05/11的．
----
## 05-07->05-11
**05-12加班**<br>
p2p基于udp，所以，点到点的数据传输可能会丢失，
    同样，udp包记得是必须按照packet接收，不像tcp收发可以直接放在buffer中，所以，p2p自己额外定义了buffer，必须要尽快接收．
    设备到pc，pc接收非常简单，没有发现丢失数据；pc到设备，数据丢失非常明显，尤其是批量传送的时候
p2p内存耗尽问题：
    １．p2p需要限制接收buffer的大小，否则传输的burst会导致内存耗尽
    ２．及时通知，尽快消耗数据，查询方式可能太慢
创建独立的spi线程，直接从rx缓冲区中获取数据发送．
buffer大小的定义，按照packet的大小比较合适，这样可以增加响应速度．
有一个问题，如果短时间内接收到比较多的packet，xr871来不及通过spi发送到c20，p2p会malloc过多的内存，导致内存耗尽而crash．这个问题我这边无法避免．
|--> 和涂鸦讨论确定，涂鸦将移植MQTT协议相关部分到xr871，音视频封装处理部分到c20，预计5月末完成；配合涂鸦的sdk更改，我们这边需要修改spi和p2p软件，以支持多个session以及每个session支持多个channel的设计．
周五已经实现基本的spi消息机制，在c20和pc之间实现了简单的双向通信demo：c20传递一个文件到pc，同时pc传递一个文件到c20，文件验证没有出现错误．
下一步，等待涂鸦完成sdk移植之后的集成．

**05-11**<br>
anni分支相关登录:
repo init -u ssh://eric.yun@gerrit.in.infotm.com:29418/manifest/buildroot -b qipc_anni_dev
repo sync -c
git tag //显示所有版本tag
git checkout qsdk_ipc_v3.6.1
repo start develop --all

root anni2013

二. 代码编译:
./tools/setproduct.sh
//# please choose a product from list below:
0   q3520e_nopmu    1   q3520e_nopmu_isp_debug  2   qipc_38f_nopmu
//# your choice: 0
//# configuration written to /home/soyo/soyo_work/ipc/qipc_anni_dev/.config
//# product successfully set to q3520e_nopmu
//# please choose sensor0 configuration:
0   sc2235dvp     x   none
//# your choice: 0
//# please choose product json configration:
0   1080P.json  1   1080P_IQ.json 2   rc.json 3   720P.json 4   960P.json x   default
//# your choice: 0
//# choose configuration successfully to q3520e_nopmu
三. 代码烧录:
1. 编译完将output/images下所有文件拷贝到tf卡
   //cp -rf output/images /media/yuan/Ubuntu\ 16.04\ LTS\ amd64/
   cp output/images/* /media/yuan/Ubuntu\ 16.04\ LTS\ amd64/
   cp output/images/uImage /media/yuan/Ubuntu\ 16.04\ LTS\ amd64/
   sync
   sudo eject /dev/sdb
   cd /media/yuan/Ubuntu\e520_1line 16.04\ LTS\ amd64/
2. 烧录在uboot1阶段敲空格停在命令交互界面，插入TF卡，使用以下命令更新需要更新的镜像文件
vs assign mmc1;vs assign flash;vs erase 10000 10000
//uboot0.isi+items.itm
vs assign mmc1;fatload mmc 1:1 80008000 uboot0.isi;fatload mmc 1:1 80014000 items.itm;vs assign flash;vs erase 0 10000;vs write 80008000 0 10000
//uboot1.isi
fatload mmc 1:1 80008000 uboot1.isi;vs erase 20000 40000;vs write 80008000 20000 40000
//kernel
fatload mmc 1:1 80008000 uImage;vs erase 60000 200000;vs write 80008000 60000 200000
//system
fatload mmc 1:1 80008000 rootfs.squashfs;vs erase 260000 D20000;vs write 80008000 260000 D20000
//app data
vs assign flash;vs erase F80000 80000

vs assign mmc1;vs assign flash;fatload mmc 1:1 80008000 uImage;vs erase 60000 200000;vs write 80008000 60000 200000


26+d2 = F80000

ifconfig eth0 down
ifconfig eth0 192.168.21.108 netmask 255.255.255.0 broadcast 192.168.21.255
ifconfig eth0 up

inet addr:128.168.91.233  Bcast:128.168.91.255  Mask:255.255.255.0

ifconfig eno1 128.168.91.235 netmask 128.168.91.255 broadcast 255.255.255.0


ping 128.168.91.233

**05-10**<br>
下一步调整：　p2p client，发送命令配置xr871的测试参数；c20测试参数从命令行输入
数据传输方式：
１．c20轮询，查询有没有接收到数据，或者能否发送新的数据，有的话就启动过程．暂时按照单向传输实现．
２．xr871检查p2p buffer,和c20交互状态信息，执行c20数据请求

基于spi增加测试命令：数据开始，结束，下一个文件，等等．

测试项目，需要统计传输速率等信息(还需要测试，dma最小块对齐是否256.)：
1. 单元测试：相同大小数据块传输，传送/接收/全双工，参数：数据块大小，数据块个数
2. 单元测试：cmd+data数据块传输，传送/接收/全双工，参数：数据块大小，数据块个数，命令长度
3. 真实数据传输，文件或者指定数据块．

应用场景：
1. c20发送结束，发送命令到xr871，xr871xr871发送cmd到client
2. client发送结束，发送命令到xr871，xr871xr871发送cmd到c20
3. client启动，发送命令启动xr871和c20
4. client同时发送和接收数据，启动发送完毕命令，接收接收完成命令．

c20实现：
1. 读取：循环check然后读取
2.

**05-09**<br>
c20到client传输没哟发现文件，反方向总是出错．跟踪，最后发现消息头部定义不能小于128bytes，可能和xr871的dma配置有关．如果项目立项，那么后续继续跟踪．当前，先使用128的消息头长度．
**05-08**<br>
发送和接收在涂鸦应用中分开实现：
　　如果上层使用轮询方式接收，那么发送和接收，可以分开实现
　　如果采用线程+消息队列的方式，那么最好发送和接收一起，可以提高效率。
　　针对当前的应用，分开实现可行而且比较简单。
完全采用c20主控，这样无论发送还是接收，都需要xr871满足了指定的长度要求，才能传输，这样暂时可以简化代码的设计

printf("reach: <%s,%d>\n", __func__,__LINE__);

c20处理流程：
　　０．启动一个线程
　　１．查询对方收发状态
　　２．如果可以发送就从本地文件中读取内容发送
　　３．有数据就绪就读取并写入目标测试文件
xr871处理流程：
　　０．启动一个线程
　　１．接收一条命令，查询，接收，发送的操作．
　　２．如果可以发送就从本地文件中读取内容发送
　　３．有数据就绪就读取并写入目标测试文件
然后，尝试双工读写数据，明显简化
　　０．启动一个线程
　　１．全双工访问．

**05-07**<br>
上午移植涂鸦sdk，和涂鸦　力波讨论确定api接口含义
初始化：
    tuya_ipc_tranfser_init(&p2p_var);
    start_live();
启动session:
    tuya_ipc_session_start(23, TRANS_MODE_P2P);
发送视频：
    １．初始化视频通道：　ret = tuya_ipc_ring_init(VIDEO_MAIN_CHN, 512*1024);
    ２．循环发送视频帧：tuya_ipc_ring_append_data(VIDEO_MAIN_CHN, videoBuf, len, media_type, pts);
发送音频：
    １．初始化音频通道：　ret = tuya_ipc_ring_init(VIDEO_MAIN_CHN, 512*1024);
    ２．循环发送音频帧：tuya_ipc_ring_append_data(AUDIO_CHN, audioBuf, len, AUDIO_FRAME, pts);
下午和晚上基本都在会议

----
## 05-02->05-06
**05-06加班**<br>
amba bus相关代码解析； 远程桌面剪贴板功能，处理失败，所以转向确认验证了几个通用共享方式：samba/cifs/nfs/ftp

**05-05加班**<br>
今天考虑增加spi全双工传输的支持.
1. 测试，每次大的数据传输之前先额外增加４个字节的收发，看会否影响到正常的处理．
spi传输函数全双工时候，使用动态内存来分配发送buffer，出现错误，spi卡死在dma，可能是需要一定程度的对齐．
如果全部的数据都进行校验，开销太大；如果不校验，那么不安全．所以推荐采用部分校验的方式．命令需要校验，数据帧中的命令ack部分，也应该校验．
每个传输过程可以通过两种方式触发：１．两个方向的申请中断；２．轮询方式，中间可以增加msleep.　后面这种方式虽然效率稍低，但本身视频传送是非对称的，c20发送的数据不会引入延时，而且手机端过来的数据应该对延时有一定的容忍度．

应该在驱动层完成传输过程的操作．
除了数据，前面过程就算是有错，也要执行完毕几个步骤
cmd加上两次ack的方式：
１．cmd，交互信息
２．可控制数据传输 : 中断方式或者延时方式处理错误
  如果任何一方对协商结果有异议，那么就否决数据传输．这一步不方便通过传输的内容来判断，因为内容可能出错．尤其是长度信息出错将会导致失控
    c20不启动传输，或者xr871不触发ready中断．通过超时来实现．也就是说，每次出错付出的代价是一定延时．
    传送请求，启动一次全新的传输；重传请求，不发送data，直接再次重新传输cmd.
  xr871检查到错误:
    c20增加一个请求资源的接口，阻塞等待dma ready中断，重传请求中断也可以终止它，哪个中断先到就处理哪一个．xr871检查到错误就发送重传请求，否则就发送dma ready中断．
  c20检查到错误
    不启动数据传输，产生重传请求中断，xr871接收到中断之后，终止数据dma的配置．

如果协商没有数据需要发送，那么数据部分就作为ack用．增加seqnum的控制，出错重传．xr871在一次传输中，没有数据要发，那么下次轮询的时间间隔可以定义的稍长．

xr871一次基本读写流程：
１．读取当前tcp的读写buffer大小
２．如果有读的，设置好当前send_len
３．读取recv_buffer，如果网络缓冲就绪就发送；如果当前recv_buffer中空，设置recv_enable=1
４．spi读写8同步字节
５．填充send_buffer内容，协调两端数据长度，开始spi传输过程

如果同步字节完毕之后，刚好有新的frame过来，那么延后处理这个frame.

**05-04**<br>
又要开始涂鸦sdk移植，有点头疼．

全志xr871，app软件是基于freertos和lwip的，完整资料可在https://github.com/XradioTech/XR871下载
chip vendor: 全志
chip type: ARM Cortex-M4F
chip Model: xr871
Endian: Little
ToolChain Version:4_9-2015q2
ToolChain Info:　gcc-arm-none-eabi-4_9-2015q2
编译开发环境搭建参照　XR871/03_SDK/XR871_Quick_Start_Guide-CN.pdf 文档

开发可以使用project/wlan_demo工程作为基础。

接入无线路由器，比如接入"TP-LINK_5E87E6"，可以在命令行输入：
net mode sta
net sta config TP-LINK_5E87E6 12345678
net sta enable



范例command TP-LINK_5E87E6　为路由器ssid，密码12345678



chip vendor: Infotm
chip type: ARM Cortex-A5
chip Model: C20
Endian: Little
ToolChain Version:4.7.3
ToolChain Info:　arm-buildroot-linux-uclibcgnueabihf

工具链下载：
Windows:https://launchpad.net/gcc-arm-embedded/4.9/4.9-2015-q2-update/+download/gcc-arm-none-eabi-4_9-2015q2-20150609-win32.exe
Linux:https://launchpad.net/gcc-arm-embedded/4.9/4.9-2015-q2-update/+download/gcc-arm-none-eabi-4_9-2015q2-20150609-linux.tar.bz2

开发过程中，修改default config，可以提高distclean之后的工程配置工作效率
meld products/q3fevb_va_ipc/configs/qsdk_defconfig .config
meld products/q3fevb_va_ipc/configs/linux_defconfig output/build/linux-local/.config

**05-03**<br>
重新整理spi和p2p的测试代码，调试中出现一些弱智问题，浪费了３个小时时间．
可以从c20发送文件到pc，或者c20无限发送数据，这两种模式方便之后的调试．
xr871启动支持下面几种模式：
１．进入命令行之后不执行任何测试
２．链接自己缺省路由测试
３．链接pc server，通过网络获取指定测试路由，然后开始测试
４．rw程序最好可以完成更加复杂一点的测试内容，可以rw程序指定传输的数据长度或者时间

设定两种发送模式：<br>
- 指定文件发送，发送完毕为止，可以设置文件参数, 不指定文件的话就是无限发送
　mmc_test send -f /mnt/sd0/pcm_16khz_ch2_32b.wav -b 16
- 无限发送
　mmc_test send -b 16
