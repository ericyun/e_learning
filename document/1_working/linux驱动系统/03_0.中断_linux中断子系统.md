# 部门研发制度规定

## 0 修订记录1
| 修订说明 | 日期 | 作者 | 额外说明 |
| --- |
| 初版 | 2018/04/10 | 员清观 |  |

## 1 中断子系统一些基本概念

可以查看linux系统中中断统计信息：　`cat /proc/interrupts`

**一些基本概念：**
- 硬中断（外部中断）：通过外部设备接口，向CPU的中断请求引脚INT和NMI发中断请求产生
- 软中断（内部中断）：CPU内部执行中断指令，或由运算溢出，TF（Trap Falg，每执行一条指令，自动产生一个内部中断去执行一个中断服务程序）标志而产生
- 可屏蔽中断（INT）
- 不可屏蔽中断（NMI）
- 向量中断：不同的中断分配不同的中断号，有不同的入口地址，硬件提供
- 非向量中断：多个中断共享一个入口地址，再通过中断标志识别具体哪个中断，软件提供

中断处理程序是在关掉其他所有中断的情况下进行，执行于硬件相关的处理要求快，而有些驱动在中断处理程序中又需要完成大量的工作，这就矛盾了。这需要在这两者间找到一个平衡点，所以分解为两个部分。
- 顶半部 上半部（tophalf） 顶半部的功能是“登记中断”。顶半部尽可能快的完成比较急的功能，往往是时间敏感的，CPU逻辑，硬件状态处理等，简单的读取寄存器中的中断状态并清除中断标志后进行“登记中断”即中断例程的底半部挂到该设备的底半部执行队列中去。这样顶半部执行的速度很快，能服务更多的中断请求. 申请和释放中断函数request_irq() 和 free_irq();
- 底半部 下半部 (bottom half)  底半部来完成中断事件的绝大多数使命。顶半部与底半部最大的不同是，底半部是可中断的，顶半部不可中断。

### 1.1 中断的申请和释放
一个`irq_domain`对应一个GIC控制器

struct irqaction 结构体在 `include\linux\interrupt.h` 文件里面定义。用户注册的每个中断处理函数都用一个 irqaction 结构体来描述一个中断(例如共享中断)可以有多个处理函数。


```cpp
struct irq_domain_ops gic_irq_domain_ops = {
	.map = gic_irq_domain_map, 	.xlate = gic_irq_domain_xlate,
};
struct irq_chip gic_chip = { //gic_v2为硬件中断定义的方法集
	.name			= "GIC", 	.irq_mask		= gic_mask_irq, /*屏蔽一个中断*/ 	.irq_unmask		= gic_unmask_irq, /*解除一个中断源的屏蔽操作*/
	.irq_eoi		= gic_eoi_irq, //发送EOI信号给中断控制器,表示硬件中断已经处理完毕
	.irq_set_type = gic_set_type, /*设置中断触发类型*/.irq_retrigger = gic_retrigger, /*重新发送中断到CPU*/
	.irq_set_wake		= gic_set_wake, //使能/关闭该中断在电源管理中的唤醒功能
};
struct irq_domain_ops {
	int (*match)(struct irq_domain *d, struct device_node *node);　void (*unmap)(struct irq_domain *d, unsigned int virq);
	int (*map)(struct irq_domain *d, unsigned int virq, irq_hw_number_t hw);
	int (*xlate)(struct irq_domain *d, struct device_node *node, *intspec, intsize, *out_hwirq, *out_type);
};
struct irq_domain {
	struct list_head link;  //通过这个节点加入irq_domain_list链表
  unsigned int revmap_type;
  union {
		struct { unsigned int size;	unsigned int first_irq;	irq_hw_number_t first_hwirq; } legacy;
		struct { unsigned int size; unsigned int *revmap; } linear;
		struct { unsigned int max_irq; } nomap;
		struct radix_tree_root tree;
	} revmap_data;
	const struct irq_domain_ops *ops;
	void *host_data;
	irq_hw_number_t inval_irq;
  struct device_node *of_node; //对应中断控制器的device node
};

struct gic_chip_data {
	union gic_base dist_base; union gic_base cpu_base;
	u32 saved_spi_enable[DIV_ROUND_UP(1020, 32)];
	u32 saved_spi_conf[DIV_ROUND_UP(1020, 16)];
	u32 saved_spi_target[DIV_ROUND_UP(1020, 4)];
	u32 __percpu *saved_ppi_enable; u32 __percpu *saved_ppi_conf;
	struct irq_domain *domain; //和irq_domain一一对应
	unsigned int gic_irqs;
};
struct irq_data {
	unsigned int		irq; unsigned long hwirq; unsigned int	node; unsigned int state_use_accessors;
	struct irq_chip		*chip;　//回调函数集合
	struct irq_domain	*domain;
	void　*handler_data，　*chip_data;
	struct msi_desc		*msi_desc;
	cpumask_var_t		affinity;
};
struct irq_desc {
	struct irq_data		irq_data;
	unsigned int __percpu	*kstat_irqs;
	irq_flow_handler_t	handle_irq;　//这个或者是这组的中断的处理函数入口。中断时调用asm_do_IRQ函数,然后根据中断号调用相应irq_desc数组项的handle_irq
	struct irqaction	*action;	/* IRQ action list */
	unsigned int		status_use_accessors; unsigned int		core_internal_state__do_not_mess_with_it;
	unsigned int		depth, wake_depth; /* nested irq disables,  and  nested wake enables */
	unsigned int		irq_count;	/* For detecting broken IRQs */
	unsigned long		last_unhandled;	/* Aging timer for unhandled count */
	unsigned int		irqs_unhandled;
	raw_spinlock_t		lock;
	struct cpumask		*percpu_enabled;
	unsigned long		threads_oneshot;
	atomic_t		threads_active;
	wait_queue_head_t       wait_for_threads;
	struct proc_dir_entry	*dir;
	int			parent_irq;
	struct module		*owner;
	const char		*name;
} ;

struct irqaction {
	irq_handler_t		handler; //中断处理函数，注册时提供
	void *dev_id;//设备id,用来区分中断源,中断处理函数的第二个参数
	void __percpu		*percpu_dev_id;
	struct irqaction	*next; //链接共享一个中断的几个action
	irq_handler_t		thread_fn; //线程化的中断处理
	struct task_struct	*thread;
	unsigned int		irq, flags;
	unsigned long		thread_flags, thread_mask;
	const char		*name;
	struct proc_dir_entry	*dir;
};
//每个gic控制器对应一个irq_domain,所以一般这个链表只有一个节点
static LIST_HEAD(irq_domain_list);  //irq_domain的链表
static struct irq_domain *irq_default_domain;

int nr_irqs = NR_IRQS;
static DECLARE_BITMAP(allocated_irqs, IRQ_BITMAP_BITS);
struct irq_desc irq_desc[NR_IRQS] = {
	[0 ... NR_IRQS-1] = {	.handle_irq	= handle_bad_irq, .depth		= 1, .lock		= __RAW_SPIN_LOCK_UNLOCKED(irq_desc->lock),	}
};
int irq_thread(void *data) //中断处理线程
	static const struct sched_param param = { .sched_priority = MAX_USER_RT_PRIO/2, };
	struct irqaction *action = data;
	struct irq_desc *desc = irq_to_desc(action->irq);
	irqreturn_t action_ret;
	sched_setscheduler(current, SCHED_FIFO, &param);
	init_task_work(&on_exit_work, irq_thread_dtor); task_work_add(current, &on_exit_work, false);
	while (!)
		|--> ret = irq_wait_for_interrupt(action);
			set_current_state(TASK_INTERRUPTIBLE);
			while (!kthread_should_stop()) //--> test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);
				if (test_and_clear_bit(IRQTF_RUNTHREAD, &action->thread_flags))
					__set_current_state(TASK_RUNNING); return 0;
				schedule();
				set_current_state(TASK_INTERRUPTIBLE);
			__set_current_state(TASK_RUNNING);
		if (ret) break;
		|--> action_ret = irq_thread_fn(desc, action);
			action->thread_fn(action->irq, action->dev_id); irq_finalize_oneshot(desc, action);
		if (!noirqdebug) note_interrupt(action->irq, desc, action_ret);
		|--> wake_threads_waitq(desc);//
			if (atomic_dec_and_test(&desc->threads_active) && waitqueue_active(&desc->wait_for_threads)) wake_up(&desc->wait_for_threads);
	task_work_cancel(current, irq_thread_dtor);

static inline int devm_request_irq(struct device *dev, unsigned int irq, irq_handler_t handler, unsigned long irqflags, const char *devname, void *dev_id) //此函数申请的必然不是线程化处理
  |--> return devm_request_threaded_irq(dev, irq, handler, NULL, irqflags, devname, dev_id); //非线程化中断
    struct irq_devres *dr = devres_alloc(devm_irq_release, sizeof(struct irq_devres), GFP_KERNEL);
    |--> request_threaded_irq(irq, handler, thread_fn, irqflags, devname, dev_id);//irq是linux管理的虚拟中断号
      struct irq_desc *desc = irq_to_desc(irq); //--> (irq < NR_IRQS) ? irq_desc + irq : NULL; 简单的在数组中索引
      struct irqaction *action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
      action->handler = handler; action->thread_fn = thread_fn; action->flags = irqflags;
      action->name = devname; action->dev_id = dev_id;
      |--> __setup_irq(irq, desc, action);
        if (new->thread_fn && !nested)
          struct task_struct *t = kthread_create(irq_thread, new, "irq/%d-%s", irq, new->name); //为中断处理创建一个线程
          get_task_struct(t); new->thread = t; set_bit(IRQTF_AFFINITY, &new->thread_flags);
        //省略根据flags等参数配置中断控制器的操作部分
        ...; //把新的action添加到desc的action链表中
        __enable_irq(desc, irq, false);
        if (new->thread) wake_up_process(new->thread);
        register_irq_proc(irq, desc); new->dir = NULL; register_handler_proc(irq, new);//创建proc目录下中断
    dr->irq = irq;  dr->dev_id = dev_id;  devres_add(dev, dr);
```

`request_irq()`这个函数是对`request_thread_irq()`的封装，它给`request_thread_irq()`的`thread_fn`参数传进了一个NULL，也就是只申请中断处理函数，不要`thread_fn`; `devm_request_threaded_irq`这个函数增加了对申请irq的dev的管理．

```cpp
//顶半部机制
//申请和释放中断函数request_irq() 和 free_irq()
int request_irq(unsigned int irq, irq_handler_t handler, unsigned long irqflags, const char * devname, void *dev_id);
//irq是要申请的硬件中断号。handler是向系统登记的中断处理函数。这是一个回调函数，中断发生时，系统调用这个函数，传入的参数包括硬件中断号，device id，寄存器值。dev_id就是下面的request_irq时传递给系统的参数dev_id。irqflags是中断处理的一些属性。比较重要的有标明中断处理程序是快速处理程序(设置IRQF_DISABLED)还是慢速处理程序(不设置IRQF_DISABLED)。快速处理程序被调用时屏蔽所有中断。慢速处理程序不屏蔽。还有一个IRQF_SHARED属性，设置了以后运行多个设备共享中断。dev_id在中断共享时会用到。一般设置为这个设备的 device结构本身或者NULL。中断处理程序可以用dev_id找到相应的控制这个中断的设备，或者用irq2dev_map找到中断对应的设备。
void free_irq(unsigned int irq,void *dev_id);
void enable_irq(int irq)

int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id); //比request_irq()函数多了irq_handler_t thread_fn参数，为NULL的话与之相同，否则对应线程化的中断处理部分

//使能和屏蔽中断 disable_irq()和disable_irq_nosync()的区别在于，后者立即返回，而前者等待目前的中断处理完成。如果enable_irq()函数会引起系统死锁，这种情况下，只能使用disable_irq_nosync()
void disable_irq(int irq) //--> struct irq_desc *desc = irq_desc + irq; disable_irq_nosync(irq);  if (desc->action) synchronize_irq(irq);
void disable_irq_nosync(int irq)

void local_irq_save(unsigned long flags); // 在当前处理器上禁止中断递交，在保存当前中断 状态到flags.. 注意：保存的是数值，不是指针，因为flags是unsigned long类型，所以这对中断函数要在同一个函数中使用
void local_irq_restore(unsigned long flags);

void local_irq_disable(void); //关闭本地中断递交而不保存状态
void local_irq_enable(void);

```

linux kernel的中断子系统分成4个部分：
1. 硬件无关的代码，我们称之Linux kernel通用中断处理模块。无论是哪种CPU，哪种controller，其中断处理的过程都有一些相同的内容，这些相同的内容被抽象出来，和HW无关。此外，各个外设的驱动代码中，也希望能用一个统一的接口实现irq相关的管理（不和具体的中断硬件系统以及CPU体系结构相关）这些“通用”的代码组成了linux kernel interrupt subsystem的核心部分。
2. CPU architecture相关的中断处理。 和系统使用的具体的CPU architecture相关。
3. Interrupt controller驱动代码 。和系统使用的Interrupt controller相关。
4. 普通外设的驱动。这些驱动将使用Linux kernel通用中断处理模块的API来实现自己的驱动逻辑。

当外设触发一次中断后，一个大概的处理过程是：
1. 具体CPU architecture相关的模块会进行现场保护，然后调用machine driver对应的中断处理handler.--> ARM的IRQ异常,保护现场,调用中断handler
2、machine driver对应的中断处理handler中会根据硬件的信息获取HW interrupt ID，并且通过irq domain模块翻译成IRQ number.
3、调用该IRQ number对应的high level irq event handler，在这个high level的handler中，会通过和interupt controller交互，进行中断处理的flow control（处理中断的嵌套、抢占等），当然最终会遍历该中断描述符的IRQ action list，调用外设的specific handler来处理该中断
//中断控制器相关的处理.
4、具体CPU architecture相关的模块会进行现场恢复。

对于中断处理而言，linux将其分成了两个部分，一个叫做中断handler（top half），属于不那么紧急需要处理的事情被推迟执行，我们称之deferable task，或者叫做bottom half，。具体如何推迟执行分成下面几种情况：
1、推迟到top half执行完毕, 包括softirq机制和tasklet机制
2、推迟到某个指定的时间片（例如40ms）之后执行, softirq机制的一种应用场景（timer类型的softirq）
3、推迟到某个内核线程被调度的时候执行,包括threaded irq handler以及通用的workqueue机制和驱动专属kernel thread（不推荐使用）

软中断不会抢占另外一个软中断，唯一可以抢占软中断的是中断处理程序。软中断可以在不同CPU上并发执行(哪怕是同一个软中断)

### 1.2 上半部
**中断处理程序上半部的限制：**<br>
 1、不能向用户空间发送或者接收数据
 2、不能做任何导致休眠的操作
 3、不能调用schedule函数
 4、无论快速还是慢速中断处理例程，都要设计成执行时间尽可能短

### 1.3 软中断内核实现

**软中断是编译期间静态分配的**
```cpp
//定义的一个枚举类型来静态声明软中断。索引号小的软中断在索引号大的软中断之前执行。要添加新项的话根据赋予它的优先级来决定加入的位置而不是直接添加到列表末尾
//与上面的枚举值相对应，内核定义了一个softirq_action的结构数组，每种软中断对应数组中的一项：

//内核为每个cpu都管理着一个待决软中断变量（pending），它就是irq_cpustat_t; __softirq_pending字段中的每一个bit，对应着某一个软中断，某个bit被置位，说明有相应的软中断等待处理
```

**软中断的守护进程ksoftirqd**<br>
每个处理器都有一个这样的线程。所有线程的名字都叫做 ksoftirq/n ，区别在于n，它对应的是处理器的编号。在一个双CPU的机器上就有两个这样的线程，分别叫做ksoftirqd/0和ksoftirqd/1。为了保证只要有空闲的处理器，它们就会处理软中断，所以给每个处理器都分配一个这样的线程。
软中断的执行既可以守护进程中执行，也可以在中断的退出阶段执行。实际上，软中断更多的是在中断的退出阶段执行（irq_exit），以便达到更快的响应，加入守护进程机制，只是担心一旦有大量的软中断等待执行，会使得内核过长地留在中断上下文中
```cpp
//在cpu的热插拔阶段，内核为每个cpu创建了一个用于执行软件中断的守护进程ksoftirqd，同时定义了一个per_cpu变量用于保存每个守护进程的task_struct结构指针：
DEFINE_PER_CPU(struct task_struct *, ksoftirqd);
//大多数情况下，软中断都会在irq_exit阶段被执行，在irq_exit阶段没有处理完的软中断才有可能会在守护进程中执行。
typedef struct { unsigned int __softirq_pending; } irq_cpustat_t;
irq_cpustat_t irq_stat[NR_CPUS];

struct softirq_action {	void	(*action)(struct softirq_action *); };
enum {	HI_SOFTIRQ=0, 	TIMER_SOFTIRQ,	NET_TX_SOFTIRQ,	NET_RX_SOFTIRQ,	BLOCK_SOFTIRQ,	BLOCK_IOPOLL_SOFTIRQ,
	TASKLET_SOFTIRQ,	SCHED_SOFTIRQ,	HRTIMER_SOFTIRQ,	RCU_SOFTIRQ, 	NR_SOFTIRQS };
struct softirq_action softirq_vec[NR_SOFTIRQS];

-->#define __IRQ_STAT(cpu, member)	(irq_stat[cpu].member)
-->#define local_softirq_pending()	__IRQ_STAT(smp_processor_id(), __softirq_pending)
-->#define set_softirq_pending(x) (local_softirq_pending() = (x))
-->#define or_softirq_pending(x)  (local_softirq_pending() |= (x))

static void run_ksoftirqd(unsigned int cpu)
	local_irq_disable();
	if (local_softirq_pending())
		|--> __do_softirq();
			pending = local_softirq_pending();  account_irq_enter_time(current);
      __local_bh_disable((unsigned long)__builtin_return_address(0), SOFTIRQ_OFFSET);
      lockdep_softirq_enter(); cpu = smp_processor_id(); set_softirq_pending(0); local_irq_enable();
      for(h = softirq_vec; pending;h++; pending >>= 1)
          if (pending & 1) h->action(h);
		rcu_note_context_switch(cpu);	local_irq_enable(); cond_resched();
	local_irq_enable();
static struct smp_hotplug_thread softirq_threads = {
	.store			= &ksoftirqd, .thread_should_run	= ksoftirqd_should_run,
	.thread_fn		= run_ksoftirqd, .thread_comm		= "ksoftirqd/%u",
};
static __init int spawn_ksoftirqd(void)
	register_cpu_notifier(&cpu_nfb);
	|--> smpboot_register_percpu_thread(&softirq_threads);
    for_each_online_cpu(cpu) //每个cpu启动一个ksoftirqd进程
  		__smpboot_create_thread(plug_thread, cpu); smpboot_unpark_thread(plug_thread, cpu);
  	list_add(&plug_thread->list, &hotplug_threads);
early_initcall(spawn_ksoftirqd);
```

**编写自己的软中断**
(1)、分配索引，在HI_SOFTIRQ与NR_SOFTIRQS中间添加自己的索引号。
(2)、注册处理程序，处理程序：open_softirq(索引号，处理函数)。
(3)、触发你的软中断：raise_softirq(索引号)。

**软中断处理程序注意**
(1)、软中断处理程序执行的时候，允许响应中断，但自己不能休眠。
(2)、如果软中断在执行的时候再次触发，则别的处理器可以同时执行，所以加锁很关键。

**软中断的执行过程**<br>
软中断的调度时机:
1. do_irq完成I/O中断时调用irq_exit。
2. 系统使用I/O APIC,在处理完本地时钟中断时。
3. local_bh_enable，即开启本地软中断时。
4. SMP系统中，cpu处理完被CALL_FUNCTION_VECTOR处理器间中断所触发的函数时
5. ksoftirqd/n线程被唤醒时

![软终端执行流程](pic_dir/软终端执行流程.png)
下面以从中断处理返回函数irq_exit中调用软中断为例详细说明：<br>
1. 首先调用local_softirq_pending函数取得目前有哪些位存在软件中断。
2. 调用__local_bh_disable关闭软中断，其实就是设置正在处理软件中断标记，在同一个CPU上使得不能重入`__do_softirq`函数。
3. 重新设置软中断标记为0，set_softirq_pending重新设置软中断标记为0，这样在之后重新开启中断之后硬件中断中又可以设置软件中断位。
4. 调用local_irq_enable，开启硬件中断。
5. 之后在一个循环中，遍历pending标志的每一位，如果这一位设置就会调用软件中断的处理函数。在这个过程中硬件中断是开启的，随时可以打断软件中断。这样保证硬件中断不会丢失。
6. 之后关闭硬件中断(local_irq_disable)，查看是否又有软件中断处于pending状态，如果是，并且在本次调用`__do_softirq`函数过程中没有累计重复进入软件中断处理的次数超过max_restart=10次，就可以重新调用软件中断处理。如果超过了10次，就调用wakeup_softirqd()唤醒内核的一个进程来处理软件中断。设立10次的限制，也是为了避免影响系统响应时间。
7. 调用_local_bh_enable开启软中断。

## 2 中断处理过程
### 2.1 中断初始化相关
```cpp
struct gic_chip_data gic_data[MAX_GIC_NR]; //所有gic的总控制,但这里只需要看第一个.

void __init start_kernel(void)
  local_irq_disable();
  |--> setup_arch(&command_line);
    setup_processor();-->cpu_init();//初始化cpu stack
    |--> paging_init(mdesc);
      |--> devicemaps_init(mdesc); //static void __init devicemaps_init(struct machine_desc *mdesc) 加载中断向量表
        vectors = early_alloc(PAGE_SIZE);
        |--> early_trap_init(vectors); //完成中断向量表的拷贝工作
        	unsigned long vectors = (unsigned long)vectors_base; int kuser_sz = __kuser_helper_end - __kuser_helper_start;
        	vectors_page = vectors_base;
        	memcpy((void *)vectors, __vectors_start, __vectors_end - __vectors_start);
        	memcpy((void *)vectors + 0x200, __stubs_start, __stubs_end - __stubs_start);
        	memcpy((void *)vectors + 0x1000 - kuser_sz, __kuser_helper_start, kuser_sz); kuser_get_tls_init(vectors);
        	memcpy((void *)(vectors + KERN_SIGRETURN_CODE - CONFIG_VECTORS_BASE), sigreturn_codes, sizeof(sigreturn_codes));
        	flush_icache_range(vectors, vectors + PAGE_SIZE); modify_domain(DOMAIN_USER, DOMAIN_CLIENT);
        map.virtual = 0xffff0000; create_mapping(&map, false);
        fill_pmd_gaps(); local_flush_tlb_all(); flush_cache_all();
  early_irq_init(); //
  |--> init_IRQ();//-->machine_desc->init_irq();-->q3f_init_irq();-->gic_init(0, 29, IO_ADDRESS(IMAP_GIC_DIST_BASE), IO_ADDRESS(IMAP_GIC_CPU_BASE));-->gic_init_bases(nr, start, dist, cpu, 0, NULL);
    struct gic_chip_data *gic = &gic_data[gic_nr];
    gic->dist_base.common_base = dist_base; gic->cpu_base.common_base = cpu_base;
    for (i = 0; i < NR_GIC_CPU_IF; i++) gic_cpu_map[i] = 0xff;
    hwirq_base = 16; irq_start = 16; gic_irqs = readl_relaxed(gic_data_dist_base(gic) + GIC_DIST_CTR) & 0x1f;
    gic->gic_irqs = gic_irqs = 32; //得到的SPI的开始编号应该是32
    gic_irqs -= hwirq_base; //反正最后得到的是中断开始编号和中断个数
    |--> irq_base = irq_alloc_descs(irq_start, 16, gic_irqs, numa_node_id());//-->__irq_alloc_descs()
      start = bitmap_find_next_zero_area(allocated_irqs, IRQ_BITMAP_BITS, from, cnt, 0);//找到连续的0空间,其实之前没有申请过,所以从第一个开始
      bitmap_set(allocated_irqs, start, cnt);
      |--> return alloc_descs(start, cnt, node, owner); //从数组中分配指定个数的irq)desc结构体
        for (i = 0; i < cnt; i++) struct irq_desc *desc = irq_to_desc(start + i); desc->owner = owner;
    |--> gic->domain = irq_domain_add_legacy(node, gic_irqs, irq_base,hwirq_base, &gic_irq_domain_ops, gic);
      |--> domain = irq_domain_alloc(of_node, IRQ_DOMAIN_MAP_LEGACY, ops, host_data);//申请一个domain并简单初始化
        domain = kzalloc_node(sizeof(*domain), GFP_KERNEL, of_node_to_nid(of_node));
        domain->revmap_type = revmap_type;	domain->ops = ops; domain->of_node = of_node_get(of_node);
        domain->host_data = host_data; //上文的struct gic_chip_data *gic, 之后配置给desc->irq_data.chip_data, 这样可以从irq索引到irq_desc,然后可以找到gic,找到domain,找到irq_chip操作行为
      for (i = 0; i < size; i++)
        struct irq_data *irq_data = irq_get_irq_data(first_irq + i);irq_data->hwirq = first_hwirq + i; irq_data->domain = domain;
      for (i = 0; i < size; i++)
        int irq = first_irq + i; 	int hwirq = first_hwirq + i;
        |--> ops->map(domain, irq, hwirq); //-->gic_irq_domain_map(); 根据irq查到irq_desc, 配置chip和handle和irq_data参数
          |--> irq_set_chip_and_handler(irq, &gic_chip, handle_fasteoi_irq);//-->irq_set_chip_and_handler_name()
            |--> irq_set_chip(irq, chip);
              struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
              desc->irq_data.chip = chip;
            |--> __irq_set_handler(irq, handle, 0, name);
              struct irq_desc *desc = irq_get_desc_buslock(irq, &flags, 0);
              desc->handle_irq = handle; desc->name = name; irq_startup(desc, true);
		      set_irq_flags(irq, IRQF_VALID | IRQF_PROBE);
          |--> irq_set_chip_data(irq, d->host_data);
            struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0); desc->irq_data.chip_data = data;
        irq_clear_status_flags(irq, IRQ_NOREQUEST);
      irq_domain_add(domain); //-->list_add(&domain->link, &irq_domain_list);
    set_handle_irq(gic_handle_irq); //--> handle_arch_irq = handle_irq;
    gic_chip.flags |= gic_arch_extn.flags; gic_dist_init(gic); gic_cpu_init(gic); gic_pm_init(gic);
  local_irq_enable();

//kernel/arch/arm/mach-q3f.c文件中
MACHINE_START(IMAPX15, "iMAPx15")
	.nr						= 0x8f9,
	.atag_offset	= 0x100,
	.smp					= smp_ops(q3f_smp_ops),
	.init_early		= q3f_init_early,
	.init_irq			= q3f_init_irq, // 中断初始化函数指针定义
	.map_io				= q3f_map_io,
	.init_machine = q3f_machine_init,
	.init_time		= q3f_init_time,
	.init_late		= q3f_init_late,
	.restart			= q3f_restart,
	.reserve			= q3f_reserve,
MACHINE_END
```

### 2.2 中断入口汇编解析
在ARM V4及V4T以后的大部分处理器中，异常向量表的位置可以有两个位置：一个是0，另一个是0xffff0000。可以通过CP15协处理器c1寄存器中V位(bit[13])控制。V和中断向量表的对应关系如下：V=0 ～0x00000000~0x0000001C; V=1 ～ 0xffff0000~0xffff001C。Linux中选择的是设置0xffff0000为异常向量表的位置。

**当中断被触发之后，处理器行为：**
```cpp
//Cpu进入irq状态
  R14_irq = 下一条指令 + 4 的地址
  SPSR_irq = CPSR
  CPSR(4:0) = 0b10010 CPSR(5) = 0 CPSR(8) = 1  CPSR(9) = CP15_reg1_EEbit CPSR(7) = 1  //disable normal interrupt
  If VE=0
    If high vectors configured then
      PC = 0xffff0018
    Else
      PC = 0x00000018
  Else
    PC = 不可预测
```
**linux中断向量表定义：**
```cpp
.macro	svc_entry, stack_hole=0
	sub	sp, sp, #(S_FRAME_SIZE + \stack_hole - 4)
	SPFIX(	tst	sp, #4		)
	SPFIX(	subeq	sp, sp, #4	)
	stmia	sp, {r1 - r12}
	ldmia	r0, {r3 - r5}
	add	r7, sp, #S_SP - 4 //@ here for interlock avoidance
	mov	r6, #-1			@  ""  ""      ""       ""
	add	r2, sp, #(S_FRAME_SIZE + \stack_hole - 4)
	SPFIX(	addeq	r2, r2, #4	)
	str	r3, [sp, #-4]!		//@ save the "real" r0 copied@ from the exception stack
	mov	r3, lr
	stmia	r7, {r2 - r6}
	.endm

.macro	svc_exit, rpsr, irq = 0
	ldr	lr, [sp, #S_SP]			//@ top of the stack
	ldrd	r0, r1, [sp, #S_LR]		//@ calling lr and pc
	clrex					//@ clear the exclusive monitor
	stmdb	lr!, {r0, r1, \rpsr}		//@ calling lr and rfe context
	ldmia	sp, {r0 - r12}
	mov	sp, lr
	ldr	lr, [sp], #4
	rfeia	sp!
	.endm

// kernel/arch/arm/entry-armv.S文件中，定义了中断向量表
	.equ	stubs_offset, __vectors_start + 0x200 - __stubs_start
	.globl	__vectors_start
__vectors_start:
 ARM(	swi	SYS_ERROR0 )
 THUMB(	svc	#0 )
 THUMB(	nop )
	W(b)	vector_und + stubs_offset
	W(ldr)	pc, .LCvswi + stubs_offset
	W(b)	vector_pabt + stubs_offset
	W(b)	vector_dabt + stubs_offset
	W(b)	vector_addrexcptn + stubs_offset
	W(b)	vector_irq + stubs_offset
	W(b)	vector_fiq + stubs_offset

	.globl	__vectors_end
__vectors_end:
	// Vector stubs. 阅读下面宏，看看上面的 vector_irq 等，是如何从 vector_\name解析的
	.macro	vector_stub, name, mode, correction=0
	.align	5

vector_\name:
	.if \correction
	sub	lr, lr, #\correction
	.endif
	// Save r0, lr_<exception> (parent PC) and spsr_<exception> (parent CPSR)
	stmia	sp, {r0, lr}	//@ save r0, lr
	mrs	lr, spsr
	str	lr, [sp, #8]		//@ save spsr
	// Prepare for SVC32 mode.  IRQs remain disabled.
	mrs	r0, cpsr
	eor	r0, r0, #(\mode ^ SVC_MODE | PSR_ISETSTATE)
	msr	spsr_cxsf, r0
	// the branch table must immediately follow this code
	and	lr, lr, #0x0f
 THUMB(	adr	r0, 1f )
 THUMB(	ldr	lr, [r0, lr, lsl #2] )
	mov	r0, sp
 ARM(	ldr	lr, [pc, lr, lsl #2] )
	movs	pc, lr			// branch to handler in SVC mode
ENDPROC(vector_\name)

	.align	2
	// handler addresses follow this label
1:
	.endm

__irq_svc: //irq跳转过程中一环
	svc_entry // Svc_entry主要将cpu相应的寄存器保存到堆栈，并将irq状态中保存的spsr_riq lr_irq等也保存到svc状态下的栈中。
	irq_handler
				@====================================================================
				@		.macro	irq_handler // irq跳转过程中一环
				@			ldr	r1, =handle_arch_irq // 在init_IRQ()函数中设置，接着，在中断
				@			mov	r0, sp
				@			adr	lr, BSYM(9997f)
				@			ldr	pc, [r1]
				@		9997:
				@			.endm
				@====================================================================
	//开始，尝试切换到另外一个就绪线程
	get_thread_info tsk //取得thread_info结构体，增加preempt计数
				@====================================================================
				@		.macro	get_thread_info, rd
				@			mov	\rd, sp
				@			lsr	\rd, \rd, #13
				@			mov	\rd, \rd, lsl #13
				@			.endm
				@====================================================================
	ldr	r8, [tsk, #TI_PREEMPT]		// get preempt count
	ldr	r0, [tsk, #TI_FLAGS]		// get flags
	teq	r8, #0				// if preempt count != 0
	movne	r0, #0				// force flags to 0
	tst	r0, #_TIF_NEED_RESCHED
	blne	svc_preempt //检查是否能够抢占，如果是，调用 svc_preempt
				@====================================================================
				@			.ltorg
				@		svc_preempt:
				@			mov	r8, lr
				@		1:	bl	preempt_schedule_irq	@ 调用外部定义的C函数
				@			ldr	r0, [tsk, #TI_FLAGS]		@ get new tasks TI_FLAGS
				@			tst	r0, #_TIF_NEED_RESCHED
				@			moveq	pc, r8				@ go again
				@			b	1b
				@====================================================================
	svc_exit r5, irq = 1			// return from exception
 UNWIND(.fnend		)
ENDPROC(__irq_svc)

	.globl	__stubs_start
__stubs_start:
/*
 * Interrupt dispatcher
 */
	vector_stub	irq, IRQ_MODE, 4
  .long	__irq_usr			@  0  (USR_26 / USR_32)
	.long	__irq_invalid			@  1  (FIQ_26 / FIQ_32)
	.long	__irq_invalid			@  2  (IRQ_26 / IRQ_32)
	.long	__irq_svc			@  3  (SVC_26 / SVC_32)
  ... //12个 __irq_invalid 类型的

void __sched preempt_schedule_irq(void)
	struct thread_info *ti = current_thread_info();
	prev_state = exception_enter();
	do
		add_preempt_count(PREEMPT_ACTIVE);
		local_irq_enable(); //暂时关闭当前cpu上的中断，另外的cpu不受影响
		__schedule();
		local_irq_disable();
		sub_preempt_count(PREEMPT_ACTIVE);
		barrier();
	while (need_resched());
	exception_exit(prev_state);
```

### 2.3 中断处理流程
中断的处理流程如下：
1）发生中断时，CPU执行异常向量 vector_irq 的代码。
2）在vector_irq里面，最终会调用中断处理的总入口函数 `handle_arch_irq() == gic_handle_irq()`
3）`handle_arch_irq()`调用`handle_IRQ()->generic_handle_irq()->generic_handle_irq_desc()`根据中断号调用`irq_desc[]`数组项中的`handle_irq()`
4）handle_irq会使用chip成员中的函数来设置硬件，比如清楚中断，禁止中断，重新使能中断等。
5）handle_irq逐个调用用户在action链表中注册的处理函数。

```cpp
//#define preempt_count()	(current_thread_info()->preempt_count) //可以表示是否处于中断处理或者软件中断处理过程中
//对应上面 handle_arch_irq 函数指针
void gic_handle_irq(struct pt_regs *regs)
  struct gic_chip_data *gic = &gic_data[0];
  void __iomem *cpu_base = gic_data_cpu_base(gic);
  while(1) {
    u32 irqstat = readl_relaxed(cpu_base + GIC_CPU_INTACK);
    u32 irqnr = irqstat & ~0x1c00;
    irqnr = irq_find_mapping(gic->domain, irqnr);
		handle_IRQ(irqnr, regs);
  }

void wakeup_softirqd(void)
	struct task_struct *tsk = __this_cpu_read(ksoftirqd);
	if (tsk && tsk->state != TASK_RUNNING)
		wake_up_process(tsk); //--> try_to_wake_up()

void handle_IRQ(unsigned int irq, struct pt_regs *regs)
  struct pt_regs *old_regs = set_irq_regs(regs);
  irq_enter();
  if (unlikely(irq >= nr_irqs))
		if (printk_ratelimit()) printk(KERN_WARNING "Bad IRQ%u\n", irq);
		ack_bad_irq(irq);
	else
		|--> generic_handle_irq(irq);
      struct irq_desc *desc = irq_to_desc(irq);
      |--> generic_handle_irq_desc(irq, desc); // --> desc->handle_irq(irq, desc)-->handle_fasteoi_irq()-->handle_irq_event(desc);-->handle_irq_event_percpu();
				while(action)
					res = action->handler(irq, action->dev_id);//调用挂载在这个irq上的所有回调函数
					if (res == IRQ_WAKE_THREAD) irq_wake_thread(desc, action); //唤醒中断关联线程-->wake_up_process(action->thread);
	|--> irq_exit(); //void irq_exit(void) //中断处理函数退出的时候可能触发tick或者软中断
    account_irq_exit_time(current);
  	sub_preempt_count(HARDIRQ_OFFSET);
  	if (!in_interrupt() && local_softirq_pending())
  		|--> invoke_softirq();
        if (!force_irqthreads) __do_softirq();
  	    else wakeup_softirqd();
  	tick_irq_exit();
  	rcu_irq_exit();

	set_irq_regs(old_regs);
```

### 2.4 基本控制函数asm实现

```cpp
static inline void arch_local_irq_enable(void)
{
	asm volatile (
		"	cpsie i			@ arch_local_irq_enable"
		:
		:
		: "memory", "cc");
}
static inline void arch_local_irq_disable(void)
{
	unsigned long temp;
	asm volatile(
		"	mrs	%0, cpsr	@ arch_local_irq_disable\n"
		"	orr	%0, %0, #128\n"
		"	msr	cpsr_c, %0"
		: "=r" (temp)
		:
		: "memory", "cc");
}
static inline unsigned long arch_local_irq_save(void)
{
	unsigned long flags, temp;
	asm volatile (
		"	mrs	%0, cpsr	@ arch_local_irq_save\n"
		"	orr	%1, %0, #128\n"
		"	msr	cpsr_c, %1"
		: "=r" (flags), "=r" (temp)
		:
		: "memory", "cc");
	return flags;
}
static inline void arch_local_irq_restore(unsigned long flags)
{
	asm volatile(
		"	msr	cpsr_c, %0	@ local_irq_restore"
		:
		: "r" (flags)
		: "memory", "cc");
}
		#define raw_local_irq_disable()		arch_local_irq_disable()
		#define raw_local_irq_enable()		arch_local_irq_enable()
		#define raw_local_irq_save(flags)	do { typecheck(unsigned long, flags);	flags = arch_local_irq_save(); } while (0)
		#define raw_local_irq_restore(flags) do {	typecheck(unsigned long, flags); arch_local_irq_restore(flags);	} while (0)

		#define local_irq_enable()	do { raw_local_irq_enable(); } while (0)
		#define local_irq_disable()	do { raw_local_irq_disable(); } while (0)
		#define local_irq_save(flags)	do { raw_local_irq_save(flags); } while (0)
		#define local_irq_restore(flags) do { raw_local_irq_restore(flags); } while (0)
```

## 3 tasklet

![tasklet工作流程](pic_dir/tasklet工作流程.png)
tasklet整体是这么运行的：驱动应该在其硬中断处理函数的末尾调用`tasklet_schedule()`接口激活该tasklet，内核经常调用`do_softirq()`执行软中断，通过softirq执行tasket，如下图所示。图中灰色部分为禁止硬中断部分，为保护软中断pending位图和tasklet_vec链表数组，count的改变均为原子操作，count确保SMP架构下同时只有一个CPU在执行该tasklet：

tasklet是一种“可延迟执行”机制中的一种，基于软中断实现主要面向驱动程序。tasklet与软中断的区别在于每个CPU上不能同时执行相同的tasklet，tasklet函数本身也不必是可重入的。与软中断一样，为了保证tasklet和硬中断之间在同一个CPU上是串行执行的，维护其PER_CPU的链表时，需要屏蔽硬中断。
具体实现主要看两个参数，一个state，一个count
- state - 用于校验在tasklet_action()或tasklet_schedule()时，是否执行该tasklet的handler。state被tasklet_schedule()函数、tasklet_hi_schedule()函数、tasklet_action()函数以及tasklet_kill()函数所修改：
  - tasklet_schedule()函数、tasklet_hi_schedule()函数将state置位TASKLET_STATE_SCHED。
  - tasklet_action()函数将state的TASKLET_STATE_SCHED清除，并设置TASKLET_STATE_RUN。
    - tasklet_action()函数在设置TASKLET_STATE_RUN标志时，使用了tasklet_trylock()、tasklet_unlock()等接口：
  - tasklet_kill()函数将state的TASKLET_STATE_SCHED清除
- count - 用于smp同步，count不为0，则表示该tasklet正在某CPU上执行，其他CPU则不执行该tasklet，count保证某个tasklet同时只能在一个CPU上执行。count的操作都是原子操作
  - tasklet_disable()函数/tasklet_disable_nosync()函数将count原子减1。
  - tasklet_enablle()函数将count原子加1。

另外，tasklet的操作如tasklet_schedule()tasklet_action()中还所使用了local_irq_save()/local_irq_disable()等禁止本地中断的函数，用于保护tasklet_vec[]链表和软中断的pending位图的更改。因为硬中断的激发能导致二者的更改，被保护对象被修改完毕后立即使用local_irq_resore()/local_irq_enable()开启

由于软中断必须使用可重入函数，这就导致设计上的复杂度变高，作为设备驱动程序的开发者来说，增加了负担。而如果某种应用并不需要在多个CPU上并行执行，那么软中断其实是没有必要的。因此诞生了弥补以上两个要求的tasklet。它具有以下特性：
a）一种特定类型的tasklet只能运行在一个CPU上，不能并行，只能串行执行。
b）多个不同类型的tasklet可以并行在多个CPU上。
c）软中断是静态分配的，在内核编译好之后，就不能改变。但tasklet就灵活许多，可以在运行时改变（比如添加模块时）。
tasklet是在两种软中断类型的基础上实现的，因此如果不需要软中断的并行特性，tasklet就是最好的选择。也就是说tasklet是软中断的一种特殊用法，即延迟情况下的串行执行。


### 3.1 比softirq优点
tasklet对于softirq而言有哪些好处：
1. tasklet可以动态分配，也可以静态分配，数量不限。
2. 同一种tasklet在多个cpu上也不会并行执行，每次中断它只会向其中的一个CPU注册，而不是所有的CPU,这使得程序员在撰写tasklet function的时候比较方便，减少了对并发的考虑（当然损失了性能）。
3. 不同tasklet可能在不同CPU上同时运行，则需要注意共享数据的保护

linux内核为什么还要引入tasklet机制呢？主要原因是软中断的pending标志位也就32位，一般情况是不随意增加软中断处理的。而且内核也没有提供通用的增加软中断的接口。其次内，软中断处理函数要求可重入，需要考虑到竞争条件比较多，要求比较高的编程技巧。所以内核提供了tasklet这样的一种通用的机制。

因为是靠软中断实现，所以tasklet不能睡眠。这意味着不能在tasklet中使用信号量或者其他阻塞函数。tasklet运行时运行可以响应中断。但如果tasklet和中断处理程序之间共享了某些数据的话，要做好预防工作。

### 3.2 tasklet内核实现

![tasklet_vec](pic_dir/tasklet_vec.png)

```cpp
struct tasklet_struct {
  struct tasklet_struct *next; //指向链表的下一个结构
  unsigned long state; //任务状态
  atomic_t count; //计数
  void (*func)(unsigned long); //处理函数
  unsigned long data;//传递参数
};
enum { TASKLET_STATE_SCHED,  TASKLET_STATE_RUN };
enum { HI_SOFTIRQ=0, TIMER_SOFTIRQ, NET_TX_SOFTIRQ, NET_RX_SOFTIRQ, BLOCK_SOFTIRQ, BLOCK_IOPOLL_SOFTIRQ,
  TASKLET_SOFTIRQ, SCHED_SOFTIRQ,   HRTIMER_SOFTIRQ, RCU_SOFTIRQ, NR_SOFTIRQS
};
//tasklet队列
struct tasklet_head { struct tasklet_struct *head; 	struct tasklet_struct **tail; };
//为每个cpu定义两个tasklet链表头, 指向softirq_work_list[]链表数组中的对应内容
static DEFINE_PER_CPU(struct tasklet_head, tasklet_vec);
static DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec);
DEFINE_PER_CPU(struct list_head [NR_SOFTIRQS], softirq_work_list);//tasklet工作链表

void tasklet_init(struct tasklet_struct *t, void (*func)(unsigned long), unsigned long data)
  t->next = NULL; t->state = 0; atomic_set(&t->count, 0); t->func = func; t->data = data;

void tasklet_schedule(struct tasklet_struct *t) //调度tasklet
  if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state))//如果当前执行中，设置标记以再次调度；如果当前没有执行，schedule之
  |--> __tasklet_schedule(t);//通过 获取当前CPU的tasklet_vec链表，将需要调度的tasklet插入当前CPU的tasklet_vec链表头部，并执行TASKLET_SOFTIRQ软中断。
    local_irq_save(flags);
    t->next = NULL; *__this_cpu_read(tasklet_vec.tail) = t;  __this_cpu_write(tasklet_vec.tail, &(t->next));
    raise_softirq_irqoff(TASKLET_SOFTIRQ);
    local_irq_restore(flags);

```

```cpp
//tasklet核心处理函数
static void tasklet_action(struct softirq_action *a) //tasklet_hi_action()处理过程相同, 不过换了个链表而已
  struct tasklet_struct *list;
  local_irq_disable(); //关闭中断
  list = __this_cpu_read(tasklet_vec.head);    //得到tasklet链表
  __this_cpu_write(tasklet_vec.head, NULL);    //清空链表
  __this_cpu_write(tasklet_vec.tail, &__get_cpu_var(tasklet_vec).head);
  local_irq_enable();
  while (list)
    struct tasklet_struct *t = list; list = list->next; //从当前链表头获取一个节点来处理
    if (tasklet_trylock(t))    //多处理器的检查, 如果另外cpu不在处理这种tasklet过程中, 就在此处理
      if (!atomic_read(&t->count)) t->func(t->data); tasklet_unlock(t); continue;
      tasklet_unlock(t);    //以上保证了同一时间，相同类型的tasklet只能有一个执行
    local_irq_disable();    //否则将未执行的task，加入链表尾, 后续再行处理
    t->next = NULL; *__this_cpu_read(tasklet_vec.tail) = t; __this_cpu_write(tasklet_vec.tail, &(t->next));
    __raise_softirq_irqoff(TASKLET_SOFTIRQ);
    local_irq_enable();

struct softirq_action {
  void (*action)(struct softirq_action *);
  void *data;
};
void __init softirq_init(void)
  for_each_possible_cpu(cpu) //初始化每个cpu的两个tasklet链表
		per_cpu(tasklet_vec, cpu).tail = &per_cpu(tasklet_vec, cpu).head;
		per_cpu(tasklet_hi_vec, cpu).tail = &per_cpu(tasklet_hi_vec, cpu).head;
		for (i = 0; i < NR_SOFTIRQS; i++) INIT_LIST_HEAD(&per_cpu(softirq_work_list[i], cpu));
	register_hotcpu_notifier(&remote_softirq_cpu_notifier);
	open_softirq(TASKLET_SOFTIRQ, tasklet_action); //-->softirq_vec[nr].action = action;
	open_softirq(HI_SOFTIRQ, tasklet_hi_action);
```

```cpp
//编写处理函数tasklet_handler
void tasklet_handler(unsigned long data)
//因为是靠软中断实现，所以tasklet不能睡眠。这意味着不能在tasklet中使用信号量或者其他阻塞函数。tasklet运行时运行可以响应中断。但如果tasklet和中断处理程序之间共享了某些数据的话，要做好预防工作。
```

### 3.3 tasklet应用

**tasklet流程**
驱动程序在初始化时，通过函数tasklet_init建立一个tasklet，然后调用函数tasklet_schedule将这个tasklet 放在 tasklet_vec链表的头部，并唤醒后台线程ksoftirqd。当后台线程ksoftirqd运行调用__do_softirq时，会执行在中断 向量表softirq_vec里中断号TASKLET_SOFTIRQ对应的tasklet_action函数，然后tasklet_action遍历 tasklet_vec链表，调用每个tasklet的函数完成软中断操作。
其中：ksoftirqd 是一个后台运行的内核线程，它会周期的遍历软中断的向量列表。

**注意：**
1.Tasklet 可被hi-schedule和一般schedule（调度），hi-schedule一定比一般shedule早运行
2.同一个Tasklet可同时被hi-schedule和一般schedule
3.同一个Tasklet若被同时hi-schedule多次，等同于只hi-shedule一次，因为，在tasklet未 运行时，hi-shedule同一tasklet无意义，会冲掉前一个tasklet
4.不同的tasklet不按先后shedule顺序运行，而是并行运行
5.Taskelet的hi-schedule 使用softirq 0, 一般schedule用softirq 30

tasklet是作为中断下半部的一个很好的选择，它在性能和易用性之间有着很好的平衡。较之于softirq，tasklet不需要考虑SMP下的并行问题，而又比workqueues有着更好的性能。tasklet通常作为硬中断的下半部来使用，在硬中断中调用tasklet_schedule(t)。每次硬中断都会触发一次tasklet_schedule(t)，但是每次中断它只会向其中的一个CPU注册，而不是所有的CPU。
完成注册后的tasklet由tasklet_action()来执行，在SMP环境下，它保证同一时刻，同一个tasklet只有一个副本在运行，这样就避免了使用softirq所要考虑的互斥的问题。
再者，tasklet在执行tasklet->func()前，再一次允许tasklet可调度（注册），但是在该tasklet已有一个副本在其他CPU上运行的情况下，它只能退后执行。
总之，同一个硬中断引起的一个tasklet_schedule()动作只会使一个tasklet被注册，而不同中断引起的tasklet则可能在不同的时刻被注册而多次被执行。

linux kernel中，和tasklet相关的softirq有两项，`HI_SOFTIRQ`用于高优先级的tasklet，`TASKLET_SOFTIRQ`用于普通的tasklet

`state`成员表示该tasklet的状态，`TASKLET_STATE_SCHED`表示该tasklet以及被调度到某个CPU上执行，`TASKLET_STATE_RUN`表示该tasklet正在某个cpu上执行。count成员是和enable或者disable该tasklet的状态相关，如果count等于0那么该tasklet是处于enable的，如果大于0，表示该tasklet是disable的。在softirq文档中，我们知道local_bh_disable/enable函数就是用来disable/enable bottom half的，这里就包括softirq和tasklet。但是，有的时候内核同步的场景不需disable所有的softirq和tasklet，而仅仅是disable该tasklet，这时候，tasklet_disable和tasklet_enable就派上用场了。

```cpp
//eric #include<linux/interrupt.h>
void tasklet_init(struct tasklet_struct *t, void (*func)(unsigned long), unsigned long data);
//eric #define DECLARE_TASKLET(name, func, data) \ struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(0), func, data }
//eric #define DECLARE_TASKLET_DISABLED(name, func, data) \ struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(1), func, data }
//一般不会使用静态创建方式，不灵活，无法定义在别的结构中，只能作为全局
void tasklet_schedule(struct tasklet_struct *t);
	|--> if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state)) __tasklet_schedule(t);
		local_irq_save(flags); t->next = NULL; *__this_cpu_read(tasklet_vec.tail) = t;
		__this_cpu_write(tasklet_vec.tail, &(t->next));	raise_softirq_irqoff(TASKLET_SOFTIRQ);
		local_irq_restore(flags);

//调度 tasklet 执行，如果tasklet在运行中被调度, 它在完成后会再次运行; 这保证了在其他事件被处理当中发生的事件受到应有的注意. 这个做法也允许一个 tasklet 重新调度它自己。
void tasklet_hi_schedule(struct tasklet_struct *t); //--> __tasklet_hi_schedule()
//和tasklet_schedule类似，只是在更高优先级执行。当软中断处理运行时, 它处理高优先级 tasklet。在其他软中断之前，只有具有低响应周期要求的驱动才应使用这个函数, 可避免其他软件中断处理引入的附加周期。

void tasklet_disable(struct tasklet_struct *t) //禁止某个指定的tasklet，如果该tasklet正在执行，会等待它执行完毕再返回
  |--> tasklet_disable_nosync(t);
    atomic_inc(&t->count); smp_mb__after_atomic_inc();
  tasklet_unlock_wait(t);  smp_mb();
//函数暂时禁止tasklet被tasklet_schedule调度，直到这个 tasklet 再次被enable；若这个 tasklet 当前在运行, 这个函数忙等待直到这个tasklet退出
void tasklet_disable_nosync(struct tasklet_struct *t); //用来禁止指定的tasklet，不用等待tasklet执行完毕就返回，不过不安全
//和tasklet_disable类似，但是tasklet可能仍然运行在另一个 CPU。
void tasklet_enable(struct tasklet_struct *t); //激活一个tasklet。
  smp_mb__before_atomic_dec(); atomic_dec(&t->count);
//使能一个之前被disable的 tasklet。若这个 tasklet 已经被调度, 它会很快运行。 tasklet_enable和tasklet_disable必须匹配调用, 因为内核跟踪每个 tasklet 的"禁止次数"。
void tasklet_kill(struct tasklet_struct *t)
  while (test_and_set_bit(TASKLET_STATE_SCHED, &t->state))
    do { yield(); } while (test_bit(TASKLET_STATE_SCHED, &t->state));
  tasklet_unlock_wait(t); //等待tasklet执行完毕，再去移除它，能引起休眠，禁止在中断上下文中使用
  clear_bit(TASKLET_STATE_SCHED, &t->state);
//确 保了 tasklet 不会被再次调度来运行，通常当一个设备正被关闭或者模块卸载时被调用。如果 tasklet正在运行, 这个函数等待直到它执行完毕。若 tasklet 重新调度它自己，则必须阻止在调用 tasklet_kill前它重新调度它自己，如同使用 del_timer_sync。
void tasklet_kill_immediate(struct tasklet_struct *t, unsigned int cpu);

```

### 3.3 tasklet范例
```cpp
struct tasklet_struct my_tasklet;
static void dw_mci_tasklet_func(unsigned long priv) { }
//动态创建和初始化
tasklet_init(&my_tasklet, dw_mci_tasklet_func, (unsigned long)host);//或者使用 DECLARE_TASKLET(tasklet_name, do_tasklet, 0);
//中断处理顶半部
irqreturn_t xxx_interrupt(int irq,void *dev_id)
  ... /*可能通过原子bits传递一些参数*/;  tasklet_schedule(&my_tasklet);    /*调度tasklet*/;  ...

tasklet_kill(&my_tasklet);
```
---
## 4 workqueue工作队列
https://blog.csdn.net/myarrow/article/details/8090504

Linux中的Workqueue机制就是为了简化内核线程的创建。通过调用workqueue的接口就能创建内核线程。并且可以根据当前系统CPU的个数创建线程的数量，使得线程处理的事务能够并行化。workqueue是内核中实现简单而有效的机制，他显然简化了内核daemon的创建，方便了用户的编程.

```cpp
kthread应用:
kernel_thread是最基础的创建内核线程的接口, 它通过将一个函数直接传递给内核来创建一个进程, 创建的进程运行在内核空间, 并且与其他进程线程共享内核虚拟地址空间.早期的kernel_thread执行更底层的操作, 直接创建了task_struct并进行初始化,引入了kthread_create和kthreadd 2号进程后, kernel_thread的实现也由统一的_do_fork(或者早期的do_fork)托管实现.

//eric #include <linux/kthread.h>
struct mmc_queue my_queue;
static int mmc_queue_thread(void *d){
     struct mmc_queue *mq = d;
}
//创建新线程后立即唤醒它，其本质就是先用kthread_create创建一个内核线程，然后通过wake_up_process唤醒它
struct task_struct  *thread = kthread_run(mmc_queue_thread, &my_queue, "my_thread_name");
int kthread_stop(struct task_struct *k);
int kthread_should_stop(void);
```

### 4.0 工作队列基本原理

```cpp
struct work_struct {
  atomic_long_t data;
  struct list_head entry;
  work_func_t func;
}; //func的参数是work_struct指针，typedef void (*work_func_t)(struct work_struct *work)。
struct delayed_work {
  struct work_struct work;
  struct timer_list timer;
  struct workqueue_struct *wq;
  int cpu;/* target workqueue and CPU ->timer uses to queue ->work */
};

bool schedule_work(struct work_struct *work) //-->queue_work(system_wq, work);
bool queue_work(struct workqueue_struct *wq, struct work_struct *work)//-->queue_work_on(WORK_CPU_UNBOUND, wq, work);
	|--> __queue_work(cpu, wq, work);
		struct pool_workqueue *pwq = unbound_pwq_by_node(wq, cpu_to_node(cpu));
		pwq->nr_active++; worklist = &pwq->pool->worklist;
		|--> insert_work(pwq, work, worklist, work_flags);
			struct worker_pool *pool = pwq->pool;
			set_work_pwq(work, pwq, extra_flags); //-->set_work_data(work, (unsigned long)pwq, WORK_STRUCT_PENDING | WORK_STRUCT_PWQ | extra_flags);
			list_add_tail(&work->entry, head);
			get_pwq(pwq); smp_mb(); if (__need_more_worker(pool))	wake_up_worker(pool);

struct workqueue_struct* alloc_workqueue(fmt, flags, max_active, args...)//__alloc_workqueue_key()
	struct workqueue_struct *wq = kzalloc(sizeof(*wq), GFP_KERNEL);... //分配然后初始化wq的基本数据结构,链表头和锁等
	wq->unbound_attrs = alloc_workqueue_attrs(GFP_KERNEL);
	|--> alloc_and_link_pwqs(wq); //申请一个有组织管理的pool_workqueue结构
		wq->cpu_pwqs = alloc_percpu(struct pool_workqueue);
		for_each_possible_cpu(cpu)
			struct pool_workqueue *pwq = per_cpu_ptr(wq->cpu_pwqs, cpu);
			struct worker_pool *cpu_pools =	per_cpu(cpu_worker_pools, cpu);
			init_pwq(pwq, wq, &cpu_pools[highpri]);
			|--> link_pwq(pwq);
				struct workqueue_struct *wq = pwq->wq; list_add_rcu(&pwq->pwqs_node, &wq->pwqs);
	list_add(&wq->list, &workqueues);
	return wq;

int worker_thread(void *__worker) //处理完所有的work之后线程结束
	worker->task->flags |= PF_WQ_WORKER;
	worker_leave_idle(worker);
	while (keep_working(pool)) //循环处理所有的work
		struct work_struct *work = list_first_entry(&pool->worklist, struct work_struct, entry);//从工作链表中获取一个work
		|--> process_one_work(worker, work);
			struct pool_workqueue *pwq = get_work_pwq(work); struct worker_pool *pool = worker->pool;
			worker->current_work = work; worker->current_func = work->func; worker->current_pwq = pwq;
			list_del_init(&work->entry); worker->current_func(work);
			worker->current_work = NULL; worker->current_func = NULL;	worker->current_pwq = NULL;
	worker_enter_idle(worker); __set_current_state(TASK_INTERRUPTIBLE);
	schedule();
int create_and_start_worker(struct worker_pool *pool)
	|--> worker = create_worker(pool);
		id = idr_alloc(&pool->worker_idr, NULL, 0, 0, GFP_NOWAIT);
		worker = alloc_worker(); worker->pool = pool; worker->id = id;
		worker->task = kthread_create_on_node(worker_thread, worker, pool->node, "kworker/%s", id_buf);
	|--> start_worker(worker);
		worker->flags |= WORKER_STARTED; worker->pool->nr_workers++;
		|--> worker_enter_idle(worker);
  		worker->flags |= WORKER_IDLE; pool->nr_idle++; worker->last_active = jiffies;
  		list_add(&worker->entry, &pool->idle_list); //添加到pool的workerlist中
		wake_up_process(worker->task);
int __cpuinit workqueue_cpu_up_callback(struct notifier_block *nfb, unsigned long action, void *hcpu)
	int cpu = (unsigned long)hcpu; struct worker_pool *pool; struct workqueue_struct *wq;
	unsigned long act = action & ~CPU_TASKS_FROZEN;
	if (act == CPU_UP_PREPARE)
		for_each_cpu_worker_pool(pool, cpu) create_and_start_worker(pool); //创建和启动worker线程
	... //暂时不管其他的场景
int __init init_workqueues(void)
	pwq_cache = KMEM_CACHE(pool_workqueue, SLAB_PANIC); //创建一个pool_workqueue结构的slab缓存
	cpu_notifier(workqueue_cpu_up_callback, CPU_PRI_WORKQUEUE_UP); //定义cpu启动时初始化动作
	hotcpu_notifier(workqueue_cpu_down_callback, CPU_PRI_WORKQUEUE_DOWN); //定义cpu停止时动作, 暂时不考虑了.
	for_each_possible_cpu(cpu) //为每个cpu创建了两个优先级的pool
		for_each_possible_cpu(cpu)
			init_worker_pool(pool); pool->cpu = cpu; pool->attrs->nice = std_nice[i++];	pool->node = cpu_to_node(cpu);
			worker_pool_assign_id(pool) //pool->id = idr_alloc(&worker_pool_idr, pool, 0, 0, GFP_KERNEL);
	for_each_online_cpu(cpu)
		for_each_cpu_worker_pool(pool, cpu)
			pool->flags &= ~POOL_DISASSOCIATED; create_and_start_worker(pool)
	for (i = 0; i < NR_STD_WORKER_POOLS; i++)
		attrs = alloc_workqueue_attrs(GFP_KERNEL); attrs->nice = std_nice[i];	unbound_std_wq_attrs[i] = attrs;
	system_wq = alloc_workqueue("events", 0, 0);
	system_highpri_wq = alloc_workqueue("events_highpri", WQ_HIGHPRI, 0);
	system_long_wq = alloc_workqueue("events_long", 0, 0);
	system_unbound_wq = alloc_workqueue("events_unbound", WQ_UNBOUND, WQ_UNBOUND_MAX_ACTIVE);
	system_freezable_wq = alloc_workqueue("events_freezable", WQ_FREEZABLE, 0);

early_initcall(init_workqueues);
```

### 4.1 系统共享工作队列
在大多数情况下, 并不需要自己建立工作队列，而是只定义工作, 将工作结构挂接到内核预定义的事件工作队列中调度, 在kernel/workqueue.c中定义了一个静态全局量的工作队列`static struct workqueue_struct *keventd_wq;`默认的工作者线程叫做`events/n`，这里n是处理器的编号，每个处理器对应一个线程。调度工作结构, 将工作结构添加到全局的事件工作队列`keventd_wq`，调用了queue_work通用模块。对外屏蔽了`keventd_wq`的接口，用户无需知道此参数，相当于使用了默认参数。`keventd_wq`由内核自己维护，创建，销毁。这样work马上就会被调度，一旦其所在的处理器上的工作者线程被唤醒，它就会被执行

```cpp
struct work_struct my_wq;
void my_wq_func(struct work_struct *work) {}
INIT_WORK(&my_wq,(void(*)(void*))my_wq_func);//INIT_WORK可以初始化这个工作队列并将工作队列与处理函数绑定
schedule_work(&my_wq); //调度工作队列，从中断bottom half调用，或者从线程中调用目标只是延后执行

int schedule_work(struct work_struct *work);
int schedule_delayed_work(struct delayed_work *dwork,unsigned long delay);//delay的单位为jiffies
bool cancel_delayed_work(struct delayed_work *dwork)
bool cancel_delayed_work_sync(struct delayed_work *dwork)//等待结束，不可在中断上下文
```

**一个定义，同时支持多个工作的范例**
```cpp
static int sensor_index[MAX_SENSORS_NUM] = {-1};
static int sensor_masks = 0;
static int sensor_counter = 0;
struct work_struct ddk_sensor_work;

static void ddk_sensor_init_work(struct work_struct *work)
{
	for (int i = 0;i < sensor_counter;i++) {
		if (i >= MAX_SENSORS_NUM)
			break;
		if (!test_and_clear_bit(i,&sensor_masks))
			break;
    ...
	}
}
void init(int index)
{
  sensor_index[sensor_counter] = index;
	set_bit(sensor_counter, &sensor_masks);
	sensor_counter ++;
	INIT_WORK(&ddk_sensor_work, ddk_sensor_init_work);
	schedule_work(&ddk_sensor_work);
}
```

### 4.2 独立工作队列
https://blog.csdn.net/myarrow/article/details/8090504

#### 4.2.1 数据结构
```cpp
//eric #include <linux/workqueue.h>

struct workqueue_struct {
  struct cpu_workqueue_struct *cpu_wq;
  struct list_head list;
  const char *name;   /*workqueue name*/
  int singlethread;   /*是不是单线程 - 单线程我们首选第一个CPU -0表示采用默认的工作者线程event*/
  int freezeable;  /* Freeze threads during suspend */
  int rt;
};
//如果是多线程，Linux根据当前系统CPU的个数创建cpu_workqueue_struct
struct cpu_workqueue_struct {
  spinlock_t lock; //*因为工作者线程需要频繁的处理连接到其上的工作，所以需要枷锁保护*/
  struct list_head worklist;
  wait_queue_head_t more_work;
  struct work_struct *current_work; /*当前的work*/
  struct workqueue_struct *wq;   /*所属的workqueue*/
  struct task_struct *thread;    //任务的上下文
} ____cacheline_aligned;
```
#### 4.2.2 创建队列

**create_singlethread_workqueue(name)**
![create_singlethread_workqueue](pic_dir/create_singlethread_workqueue.png)
图中的cwq是一per-CPU类型的地址空间。对于create_singlethread_workqueue而言，即使是对于多CPU系统，内核也只负责创建一个worker_thread内核进程。该内核进程被创建之后，会先定义一个图中的wait节点，然后在一循环体中检查cwq中的worklist，如果该队列为空，那么就会把wait节点加入到cwq中的more_work中，然后休眠在该等待队列中。
Driver调用queue_work（struct workqueue_struct *wq, struct work_struct *work）向wq中加入工作节点。work会依次加在cwq->worklist所指向的链表中。queue_work向cwq->worklist中加入一个work节点，同时会调用wake_up来唤醒休眠在cwq->more_work上的worker_thread进程。wake_up会先调用wait节点上的autoremove_wake_function函数，然后将wait节点从cwq->more_work中移走。
worker_thread再次被调度，开始处理cwq->worklist中的所有work节点...当所有work节点处理完毕，worker_thread重新将wait节点加入到cwq->more_work，然后再次休眠在该等待队列中直到Driver调用queue_work...

**create_workqueue(name)**
![create_workqueue](pic_dir/create_workqueue.png)
相对于create_singlethread_workqueue, create_workqueue同样会分配一个wq的工作队列，但是不同之处在于，对于多CPU系统而言，对每一个CPU，都会为之创建一个per-CPU的cwq结构，对应每一个cwq，都会生成一个新的worker_thread进程。但是当用queue_work向cwq上提交work节点时，是哪个CPU调用该函数，那么便向该CPU对应的cwq上的worklist上增加work节点

**小结**
当用户调用workqueue的初始化接口create_workqueue或者create_singlethread_workqueue对workqueue队列进行初始化时，内核就开始为用户分配一个workqueue对象，并且将其链到一个全局的workqueue队列中。然后Linux根据当前CPU的情况，为workqueue对象分配与CPU个数相同的cpu_workqueue_struct对象，每个cpu_workqueue_struct对象都会存在一条任务队列。紧接着，Linux为每个cpu_workqueue_struct对象分配一个内核thread，即内核daemon去处理每个队列中的任务。至此，用户调用初始化接口将workqueue初始化完毕，返回workqueue的指针。
workqueue初始化完毕之后，将任务运行的上下文环境构建起来了，但是具体还没有可执行的任务，所以，需要定义具体的work_struct对象。然后将work_struct加入到任务队列中，Linux会唤醒daemon去处理任务
![workqueue内核实现原理数据结构](pic_dir/workqueue内核实现原理数据结构.png)

```cpp
//多种初始化模式
  DECLARE_WORK(n, f)/*n 是声明的work_struct结构名称, f是要从工作队列被调用的函数*/
  DECLARE_DELAYED_WORK(n, f)  /*n是声明的delayed_work结构名称, f是要从工作队列被调用的函数， 若在运行时需要建立 work_struct 或 delayed_work结构, 使用下面 2 个宏定义:*/
  INIT_WORK(struct work_struct *work, void (*function)(void *));
  INIT_DELAYED_WORK(struct delayed_work *work, void (*function)(void *));
  PREPARE_WORK(struct work_struct *work, void (*function)(void *)); //可忽略
  PREPARE_DELAYED_WORK(struct delayed_work *work, void (*function)(void *)); //可忽略
  /* INIT_* 做更加全面的初始化结构的工作，在第一次建立结构时使用. PREPARE_* 做几乎同样的工作, 但是它不初始化用来连接 work_struct或delayed_work 结构到工作队列的指针。如果这个结构已经被提交给一个工作队列, 且只需要修改该结构,则使用 PREPARE_* 而不是 INIT_* */

struct workqueue_struct *create_workqueue(const char *name);//linux 2.6.36 之前
struct workqueue_struct *create_singlethread_workqueue(const char *name);
//每个工作队列有一个或多个专用的进程("内核线程"), 这些进程运行提交给这个队列的函数。 若使用 create_workqueue, 就得到一个工作队列它在系统的每个处理器上有一个专用的线程。在很多情况下，过多线程对系统性能有影响，如果单个线程就足够则使用 create_singlethread_workqueue 来创建工作队列。

//工作函数不能访问用户空间，因为它在一个内核线程中运行, 完全没有对应的用户空间来访问。
int queue_work(struct workqueue_struct *wq, struct work_struct *work);
int queue_delayed_work(struct workqueue_struct *wq,struct delayed_work *dwork, unsigned long delay);
/*每个都添加work到给定的workqueue。如果使用 queue_delay_work, 则实际的工作至少要经过指定的 jiffies 才会被执行。 这些函数若返回 1 则工作被成功加入到队列; 若为0，则意味着这个 work 已经在队列中等待，不能再次加入*/
int queue_delayed_work_on(int cpu, struct workqueue_struct *wq, struct delayed_work *dwork, unsigned long delay);//指定cpu，不怎么用

```

**workqueue的取消和flush，用的不多，暂时不深究用法**
```cpp
int cancel_delayed_work(struct delayed_work *work);
int cancel_work_sync(struct work_struct *work); //取消一个挂起的工作队列入口项可以调用
//如果这个入口在它开始执行前被取消，则返回非零。内核保证给定入口的执行不会在调用 cancel_delay_work 后被初始化. 如果 cancel_delay_work 返回 0, 但是, 这个入口可能已经运行在一个不同的处理器, 并且可能仍然在调用 cancel_delayed_work 后在运行. 要绝对确保工作函数没有在 cancel_delayed_work 返回 0 后在任何地方运行, 你必须跟随这个调用来调用:
void flush_workqueue(struct workqueue_struct *wq);
//在 flush_workqueue 返回后, 没有在这个调用前提交的函数在系统中任何地方运行。而cancel_work_sync会取消相应的work，但是如果这个work已经在运行那么cancel_work_sync会阻塞，直到work完成并取消相应的work。
//flush_workqueue并不会取消任何延迟执行的工作，因此如果要取消延迟工作，应该调用cancel_delayed_work_sync()
int cancel_delayed_work_sync(struct delayed_work *dwork);
/* destroy 之前可以先flush */
void destroy_workqueue(struct workqueue_struct *queue); //释放工作队列
```

```cpp
//范例
struct my_struct_t {
    char *name;
    struct work_struct my_work;
};

void my_func(struct work_struct *work)
{
    struct my_struct_t *my_name = container_of(work, struct my_struct_t, my_work);
    ...
}

struct workqueue_struct *my_wq;    //全局变量
struct my_struct_t my_name;            //全局变量

//初始化函数中定义
my_wq = create_workqueue(“my wq”);
my_name.name = “William”;
INIT_WORK(&(my_name.my_work), my_func);
queue_work(my_wq, &(my_name.my_work));

//卸载函数中使用
destroy_workqueue(my_wq);
```
## 5 kthread_work(er)
提供统一的模板来创建和管理kthread.

![kthread_work数据结构](pic_dir/kthread_work数据结构.png)

```cpp
struct kthread_worker {
    spinlock_t        lock;//保护work_list链表的自旋锁
    struct list_head    work_list;//kthread_work链表,相当于流水线
    struct task_struct    *task;//为该kthread_worker执行任务的线程对应的task_struct结构
    struct kthread_work    *current_work;//当前正在处理的kthread_work
};

struct kthread_work {
    struct list_head    node;//kthread_work链表的链表元素
    kthread_work_func_t    func;//执行函数,该kthread_work所要做的事情
    wait_queue_head_t    done;//没有找到相关用法
    struct kthread_worker    *worker;//处理该kthread_work的kthread_worker
};
struct __wait_queue_head { // 是一个带锁的链表节点
    spinlock_t lock;
    struct list_head task_list;
};
typedef struct __wait_queue_head wait_queue_head_t;
//现在见到的基本应用模式，是添加message到queue,然后queue_kthread_work去处理。
//tasklet的方式，设置bit，触发处理。
//多个cpu的支持的问题，需要使用spinlock来同步。
spin_lock_irqsave(&master->queue_lock, flags);
spin_unlock_irqrestore(&master->queue_lock, flags);
```

**flush_kthread_worker阻塞等待worker执行完毕**
```cpp
struct kthread_flush_work {
    struct kthread_work work;
    struct completion   done;
};
static void kthread_flush_work_fn(struct kthread_work *work)
{
    struct kthread_flush_work *fwork =
        container_of(work, struct kthread_flush_work, work);
    complete(&fwork->done); // 唤醒完成量
}
void flush_kthread_worker(struct kthread_worker *worker)
{
    struct kthread_flush_work fwork = {
        KTHREAD_WORK_INIT(fwork.work, kthread_flush_work_fn),
        COMPLETION_INITIALIZER_ONSTACK(fwork.done), // ON_STACK后缀相当于加了static
    };
    queue_kthread_work(worker, &fwork.work); // 将 fwork中的work成员的node节点过接到worker_list下，并尝试唤醒线程进行kthread_flush_work_fn函数的执行
    wait_for_completion(&fwork.done); // 调用这个函数的线程睡眠等待在这里，等待执行worker中work_list下的fulsh_kthread_work完kthread_flush_work_fn函数
}
```

```cpp
//eric #include <linux/kthread.h>
struct kthread_worker worker;//声明一个kthread_worker
init_kthread_worker(&worker);//初始化kthread_worker，链表等
struct task_struct *kworker_task = kthread_run(kthread_worker_fn, &worker, "nvme%d", dev->instance);
//struct task_struct *kworker_task = kthread_run(kthread_worker_fn, &worker, dev_name(&master->dev));
//为kthread_worker创建一个内核线程来处理work.
void work_fn1(struct kthread_work *work)
{
  struct spi_master *master =	container_of(work, struct spi_master, pump_messages);
  ...
}
struct kthread_work work1;//声明一个kthread_work
init_kthread_work(&work1, work_fn1);//初始化kthread_work,设置work回调函数等
queue_kthread_work(&worker, &work1);//将kthread_work添加到kthread_worker的work_list.
struct kthread_work work2;//声明一个kthread_work
init_kthread_work(&work2, work_fn2);//初始化kthread_work,设置work回调函数等
queue_kthread_work(&worker, &work2);//将kthread_work添加到kthread_worker的work_list.

int kthread_stop(struct task_struct *k);//停止kthread,一般可以flush_kthread_worker()之后调用。
```

**基本无用的初始化声明宏**
```cpp
//eric #define DEFINE_KTHREAD_WORKER(worker) struct kthread_worker worker = KTHREAD_WORKER_INIT(worker)
//eric #define DEFINE_KTHREAD_WORK(work, fn) struct kthread_work work = KTHREAD_WORK_INIT(work, fn)
```

## 6 timer和内核延时
重要参考文件:   `/kernel/kernel/timer.c` 和 `/kernel/kernel/timers.c`

```cpp
struct timer_list {
	struct list_head entry;
	unsigned long expires;
	struct tvec_base *base;
	void (*function)(unsigned long);
	unsigned long data;
	int slack;
};
static inline int timer_pending(const struct timer_list * timer)    //timer_pending用来判断一个定时器是否已经在内核定时器链表中了。如果一个定时器已经在内核定时器链表中，然后你如果再调用add_timer重新加入，会出错。一个在内核定时器链表中的定时器，当它的超时时间到了，那么内核线程将会执行它的超时函数，并把它从定时器链表中摘除。
extern void init_timers(void); //初始化一个 timer_list 数据结构
extern void add_timer_on(struct timer_list *timer, int cpu);  //注册定时器结构来在当前 CPU 上运行.（只运行一次，运行完后，定时器要重新add，才会被再次调用。
extern int del_timer(struct timer_list * timer);   //从激活的定时器链表中去除一个定时器
extern int mod_timer(struct timer_list *timer, unsigned long expires);  //修改定时器的超时时间，并把它加入到内核定时器链表中去
extern int mod_timer_pending(struct timer_list *timer, unsigned long expires);
extern int timer_reduce(struct timer_list *timer, unsigned long expires);
extern void add_timer(struct timer_list *timer);

'''

'''cpp
void ndelay(unsigned long nsecs);
void udelay(unsigned long usecs);
void mdelay(unsigned long msecs);

void wait_some_time()
  unsigned long timeout = jiffies + msecs_to_jiffies(500);
  while(time_before(jiffies, timeout));

unsigned long msecs_to_jiffies(const unsigned int m)//ms到jiffies的转化
unsigned int jiffies_to_msecs(const unsigned long j)
void msleep(unsigned int msecs)
  unsigned long timeout = msecs_to_jiffies(msecs) + 1;
  |--> timeout = schedule_timeout_uninterruptible(timeout);//signed long __sched schedule_timeout_uninterruptible(signed long timeout)
    __set_current_state(TASK_UNINTERRUPTIBLE);
    |--> return schedule_timeout(timeout);//signed long __sched schedule_timeout(signed long timeout)
      expire = timeout + jiffies;
      setup_timer_on_stack(&timer, process_timeout, (unsigned long)current);//on timeout-->wake_up_process((struct task_struct *)__data);唤醒当前进程
      __mod_timer(&timer, expire, false, TIMER_NOT_PINNED);
      schedule();
      del_singleshot_timer_sync(&timer);
      destroy_timer_on_stack(&timer);      timeout = expire - jiffies;
      return timeout < 0 ? 0 : timeout;

unsigned long msleep_interruptible(unsigned int msecs)
  unsigned long timeout = msecs_to_jiffies(msecs) + 1;
  while (timeout && !signal_pending(current))
    timeout = schedule_timeout_interruptible(timeout);
  return jiffies_to_msecs(timeout);
void usleep_range(unsigned long min, unsigned long max)
  __set_current_state(TASK_UNINTERRUPTIBLE);  do_usleep_range(min, max);//return schedule_hrtimeout_range(&kmin, delta, HRTIMER_MODE_REL);

void __init start_kernel(void)
  |--> init_timers();//void __init init_timers(void)
    err = timer_cpu_notify(&timers_nb, (unsigned long)CPU_UP_PREPARE, ...);
    init_timer_stats();
    register_cpu_notifier(&timers_nb);
    |--> open_softirq(TIMER_SOFTIRQ, run_timer_softirq);//void run_timer_softirq(struct softirq_action *h)
      struct tvec_base *base = __this_cpu_read(tvec_bases);
      hrtimer_run_pending();
      if (time_after_eq(jiffies, base->timer_jiffies)) __run_timers(base);//处理到期的timers,call_timer_fn(timer, fn, data);
void timer_example()
  struct timer_list	timeout_timer;
  init_timer(&timeout_timer);
  timeout_timer.function = dc21285_enable_error;
  timeout_timer.data = (unsigned long)dev;
  timeout_timer.expires = jiffies + HZ;//标准应用方式，HZ代表1s
  add_timer(&timeout_timer); //void add_timer(struct timer_list *timer) //注册到内核动态定时器链表中
  mod_timer(&timeout_timer, jiffies+HZ);//int mod_timer(struct timer_list *timer, unsigned long expires)
  del_timer(&timeout_timer); // int del_timer(struct timer_list *timer)
  del_timer_sync(&timeout_timer); //int del_timer_sync(struct timer_list *timer)，等待timer被处理完，不能在中断上下文中调用．
```

## 7 中断 范例
### 7.1 gpio中断
```cpp
//#include <linux/interrupt.h>
//#include <linux/gpio.h>

static int spidev_irq_index = 21;

struct spidev_data {
  //...
  struct semaphore sem;
  int     irq;
};

static irqreturn_t spidev_irq(int irq, void *dev_id)
    struct spidev_data	*spidev = dev_id;
    disable_irq_nosync(spidev->irq);
    up(&spidev->sem);
    return IRQ_HANDLED;

static int spidev_probe(struct spi_device *spi)
  //...
  int rc = 0;
  spidev_irq_index = 21;
  if (gpio_is_valid(spidev_irq_index))
		rc = gpio_request(spidev_irq_index, "ts_int");
		if (rc) pr_err("failed request gpio for ts_int\n"); return -1;
  sem_init(&spidev->sem);
  spidev->irq = gpio_to_irq(spidev_irq_index);
  //INIT_WORK(&spidev->work, gsl_ts_xy_worker);
  rc = request_irq(spidev->irq, spidev_irq, IRQF_TRIGGER_RISING|IRQF_TRIGGER_FALLING, "test", spidev);
  //...

```

### 7.2 按键中断

```cpp
//#include <linux/module.h>
//#include <linux/kernel.h>
//#include <linux/fs.h>
//#include <linux/init.h>
//#include <linux/delay.h>
//#include <asm/irq.h>
//#include <linux/interrupt.h>
//#include <asm/uaccess.h>
//#include <asm/arch/regs-gpio.h>
//#include <asm/hardware.h>

//#define DEVICE_NAME "buttons" /* 加载模式后，执行”cat /proc/devices”命令看到的设备名称 */
//#define BUTTON_MAJOR 232 /* 主设备号 */

struct button_irq_desc {
    int irq;
    unsigned long flags;
    char *name;
};

/* 用来指定按键所用的外部中断引脚及中断触发方式, 名字 */
static struct button_irq_desc button_irqs [] = {
    {IRQ_EINT19, IRQF_TRIGGER_FALLING, "KEY1"}, /* K1 */
    {IRQ_EINT11, IRQF_TRIGGER_FALLING, "KEY2"}, /* K2 */
    {IRQ_EINT2, IRQF_TRIGGER_FALLING, "KEY3"}, /* K3 */
    {IRQ_EINT0, IRQF_TRIGGER_FALLING, "KEY4"}, /* K4 */
};

/* 按键被按下的次数(准确地说，是发生中断的次数) */
static volatile int press_cnt [] = {0, 0, 0, 0};

/* 等待队列:
 * 当没有按键被按下时，如果有进程调用s3c24xx_buttons_read函数，
 * 它将休眠
 */
static DECLARE_WAIT_QUEUE_HEAD(button_waitq);

/* 中断事件标志, 中断服务程序将它置1，s3c24xx_buttons_read将它清0 */
static volatile int ev_press = 0;


static irqreturn_t buttons_interrupt(int irq, void *dev_id)
{
    volatile int *press_cnt = (volatile int *)dev_id;

    *press_cnt = *press_cnt + 1; /* 按键计数加1 */
    ev_press = 1; /* 表示中断发生了 */
    wake_up_interruptible(&button_waitq); /* 唤醒休眠的进程 */

    return IRQ_RETVAL(IRQ_HANDLED);
}


/* 应用程序对设备文件/dev/buttons执行open(...)时，就会调用s3c24xx_buttons_open函数 */
static int s3c24xx_buttons_open(struct inode *inode, struct file *file)
    for (i = 0; i < sizeof(button_irqs)/sizeof(button_irqs[0]); i++)  // 注册中断处理函数
        err = request_irq(button_irqs[i].irq, buttons_interrupt, button_irqs[i].flags, button_irqs[i].name, (void *)&press_cnt[i]);
        if (err)  break;
    if (err) // 释放已经注册的中断
        i--;
        for (; i >= 0; i--)
            free_irq(button_irqs[i].irq, (void *)&press_cnt[i]);
        return -EBUSY;
    return 0;

/* 应用程序对设备文件/dev/buttons执行close(...)时，就会调用s3c24xx_buttons_close函数 */
static int s3c24xx_buttons_close(struct inode *inode, struct file *file)
    for (i = 0; i < sizeof(button_irqs)/sizeof(button_irqs[0]); i++)
        free_irq(button_irqs[i].irq, (void *)&press_cnt[i]);// 释放已经注册的中断
    return 0;

/* 应用程序对设备文件/dev/buttons执行read(...)时，就会调用s3c24xx_buttons_read函数 */
static int s3c24xx_buttons_read(struct file *filp, char __user *buff, size_t count, loff_t *offp)
    wait_event_interruptible(button_waitq, ev_press); /* 如果ev_press等于0，休眠 */
    err = copy_to_user(buff, (const void *)press_cnt, min(sizeof(press_cnt), count)); /* 将按键状态复制给用户，并清0 */
    memset((void *)press_cnt, 0, sizeof(press_cnt));
    return err ? -EFAULT : 0;

/* 这个结构是字符设备驱动程序的核心, 当应用程序操作设备文件时所调用的open、read、write等函数，最终会调用这个结构中的对应函数 */
static struct file_operations s3c24xx_buttons_fops = {
    .owner = THIS_MODULE, /* 这是一个宏，指向编译模块时自动创建的__this_module变量 */
    .open = s3c24xx_buttons_open,
    .release = s3c24xx_buttons_close,
    .read = s3c24xx_buttons_read,
};

static int __init s3c24xx_buttons_init(void) /* 执行“insmod s3c24xx_buttons.ko”命令时就会调用这个函数 */
    /* 注册字符设备驱动程序, 参数为主设备号、设备名字、file_operations结构；这样，主设备号就和具体的file_operations结构联系起来了，操作主设备为BUTTON_MAJOR的设备文件时，就会调用s3c24xx_buttons_fops中的相关成员函数, BUTTON_MAJOR可以设为0，表示由内核自动分配主设备号  */
    ret = register_chrdev(BUTTON_MAJOR, DEVICE_NAME, &s3c24xx_buttons_fops);
    if (ret < 0) printk(DEVICE_NAME " can't register major number\n"); return ret;

static void __exit s3c24xx_buttons_exit(void) /* 执行”rmmod s3c24xx_buttons.ko”命令时就会调用这个函数 */
    unregister_chrdev(BUTTON_MAJOR, DEVICE_NAME);/* 卸载驱动程序 */

/* 这两行指定驱动程序的初始化函数和卸载函数 */
module_init(s3c24xx_buttons_init);
module_exit(s3c24xx_buttons_exit);

/* 描述驱动程序的一些信息，不是必须的 */
MODULE_AUTHOR("http://www.100ask.net"); // 驱动程序的作者
MODULE_DESCRIPTION("S3C2410/S3C2440 BUTTON Driver"); // 一些描述信息
MODULE_LICENSE("GPL"); // 遵循的协议
```

### 7.3 设置任意位置中断向量表

```cpp
vPortInstallFreeRTOSVectorTable:
	/* Set V=0 in CP15 SCTRL register - for VBAR to point to vector */
	mrc    p15, 0, r0, c1, c0, 0	@ Read CP15 SCTRL Register
	bic    r0, r0, #0x00002000		@ V = 0
	mcr    p15, 0, r0, c1, c0, 0	@ Write CP15 SCTRL Register
	 /* Set vector address in CP15 VBAR register */
	ldr    r0, =_start
	mcr    p15, 0, r0, c12, c0, 0	 @Set VBAR
	dsb
	isb
```
