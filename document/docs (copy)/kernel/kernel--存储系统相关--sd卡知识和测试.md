SD卡知识和测试
视频文件的特点，不断的叠加而不是修改。而且有可能按照时间顺序排列。不同通道的文件时间上有关联。

完全按照时间来存储，不管多少个文件，读取无所谓，但擦除的时候必须保证按时间擦除。

Fat32优化:
优化目标：优化写入性能，提高ｓｄ卡寿命。
写入干净的已擦除块，和写入脏块，一定是不同的。
当前fat32机制下，写文件时一次分配一个簇，所以同时写多文件容易出现不同文件的簇犬牙交错，而回写好像是按照文件进行的，
     上层应用使用较大的缓冲区(64k以上)，并同步好不同线程的写操作，这样文件可以分配到连续的簇
         按道理，这样写入性能应该不错，但之前好像有不同的情况出现，测试验证一下。
     要么每次为文件分配多个连续的簇，很关键的问题是分配多少
         对于大速率的视频流，这种方式比较合适，而且生成的文件占用连续cluster,删除的时候空闲簇是有序的。
         需要测试确定一下，一次分配多少簇效率高。
         不适应同时很多个小码率视频流，但这不会出现在ipc上
         越多连续簇，文件簇号在fat表中也连续，提高fat表性能,一个扇区的fat表对应128*4k=512k的内容
         另外考虑擦除区大小的影响
     要么直接定义每个簇为32/64K
     要么分配cluster延时到回写时
     要么回写不要按照文件进行，将fat表及inode回写和文件内容的回写分开
         不同文件交叉分配簇，删除部分文件后空闲簇可能犬牙交错。
         只有对于很多小文件同时低速写入比较合适。
     fat表和inode回写延后合并执行，用fdatasync同步文件内容

本周测试验证上述内容。
一般的码率是多少？这个很重要。
可以通过ioctrl或其他方式，通过码率预测文件大小，确定连续簇分配个数，改变文件策略。尽量分配扇区对齐的整扇区空闲簇号链。
     回写策略的优化，回写文件的时候，最近的不完整的文件内容page不要回写，因为很可能会被补齐；最近修改的一个扇区的fat表也不应该回写，因为很大可能会被继续优化。
     sd卡采用不同的ＩＯ调度算法和回写算法。
     还有之前提到的日志方式呢？好像不可行啊。如果使用，那么实际只是一个延后并合并fat表的写入的机制而已，那还不如在内存中缓存。
额外需要注意的：
     格式化的时候尽量保证cluster对齐128k,这可以通过调整预留扇区和fat表的大小来做到。如果是４ｋ的cluster，保证４ｋ对齐然后前面几个簇不用
     fat表空闲簇的管理方法
     考虑客户应用场景，比如写满覆盖等
     随机写，需要考虑写的时候是否需要先擦除的情况，如果不断的在同样的位置写入，或者sd卡原来就不干净，性能一定很差。
     怀疑sd卡写入并不是整体耦合的，而是分成多个内部区块，每个区块内部小块紧密耦合，写入不连续有开销，这个开销如果是区块切换带来的话，我们可以优化。
     所有的空闲cluster,是否可以用bitmap来管理，这样，可以方便的找到连续的空闲cluster
     关闭文件时候可以考虑释放掉没有写入的簇。
     虽然sd卡有ftl层，但应该也是有开销的，ftl层应该也是有缺省值的吧，没有被修改，就是线性映射。所以，尽量按照ｓｄ的特性写入，总会有好处的。所以，跳地址写的开销，不知道触发ftl带来的，还是自身带来的。覆盖一遍之后，不知道写性能会否受大的影响。
     视频文件写，顺序无覆盖，单向，对齐。可以使用简单的映射模型。O_DIRECT，然后使用专用的调度算法。

SD测试程序
SD卡测试程序设计目标是在不同场景下读写性能测试与总结，了解sd卡特性，尝试能否有针对优化性能，同时将包含一些协助fat32调试的功能，大概包含下面内容：
     测试程序可方便组合不同场景进行测试：写fat32文件/直接写设备文件 单文件/多文件 单线程/多线程 不同连续块数 不同lseek间隔块数 随机写入不同次序选择等等
     以适当格式显示sd卡或分区指定物理扇区的内容，显示fat表指定簇号的内容，显示文件占用的簇号链表，以及其他fs信息和方便调试的信息。
     扩展功能，考虑增加sd卡分区和fat32格式化功能
     尝试不同文件系统

     sd读卡测试：多线程多文件，跳址读取测试
         多线程，sd卡读512跳512测试，和随机位置读取测试，如果性能和顺序读取差别不大，就不需要继续测试了。
         否则做额外的测试，例如：sd卡顺序读取512,1024,...,64k　跳块顺序读取 随机读取(读512,跳512)

SD卡速率等级: class 0/2/4/6/10
SD卡容量
1）标准容量卡（SDSC），容量最高高达 2GB。所有 SD 协议版本都需支持。
2）高容量卡 （SDHC），大于 2GB 又不超过 32GB， SD2.0 协议定义。
3）扩展容量卡（SDXC），大于 32GB 又不超过 2TB， SD3.0 协议定义。
SD卡寿命
目前市场上所使用的SD卡，按照使用存储技术的不同，SLC已经过时，现在主要分为两种:MLC和TLC：
MLC（Multi-Level Cell）即2bit/cell，一个存储单元可以存储2bit数据。一般可以达到约3000次左右擦写寿命；
TLC（Trinary-Level Cell）即3bit/cell，一个存储单元可以存储3bit数据。一般可以达到约500次擦写寿命

参考一下ext2/3的构建，预测文件大小来动态确定块大小，预测文件数量初始分配inode数量，连续磁盘块分组，预分配块给文件(组为单位？)，启动一致性检查
块组 block group: 超级块 组描述符 数据块位图 索引节点位图 索引节点表 数据块
位图: 每个ｂｉｔ对应一个块，是否空闲３２Ｇ，32k个４ｋ的块，需要４ｋ大小的一个块空间，那么１个块可以做３２ｋ个块的位图。
实际上文件节点是预先分配好的，我们也可以预分配足够的小文件，超过预定义的，再由文件系统自己搞定。
ｆａｔ空闲ｃｌｕｓｔｅｒ的分配策略能否改变。

ext2文件系统inode预分配，如果inode不够，有空闲空间也无法使用的。所有的块组大小结构相同。
ext2文件系统lseek产生洞

FTL相关的一些知识：
测试，写的中间延时一段时间，看是否影响写入性能。
LBA，全称为Logical Bl ock Address　　PBA全称为 Physics Block Address
NAND读写以页为单位，擦除以块（多个页组成）为单位的特性导致LBA和 PBA的关系不再是固定不变的，就需要一层叫做FTL的东西来作转换，以配合现有的文件系统
闪存页大小一般为4KB或8KB，块一般有128至256页。由于NAND闪存的特性，SSD的主控制器是使用LBA和PBA的映射表来管理闪存的
WL（Wear leveling）磨损平衡，动态和动态WL
OP（Over-provisioning）预留空间，用户不可操作的容量
Trim指令 感觉像是清空trash，避免主控额外复制。
异处更新(out-of-place Update)　和　WA（Write Amplification）写入放大: 读　修改　写回
静态/动态数据分离（Separating Static and Dynamic Data）
持续写入（Sequential writes）减少WA， 理论上来说持续写入的写入放大为1

     如果有ｆｔｌ那么其修改必然有开销，尽量避免把不同的文件存在一个擦除区块中。满擦除时带来额外的数据拷贝。
     另外，ｆｔｌ的存在，会否导致对齐的ｂｕｆｆｅｒ写入无法真正对齐到擦除块呢。
     可以使用预分配机制，这部分簇仍然是空闲簇但是记录文件索引节点号并标记为预留状态，其他文件完全没有空间的时候才会分配这部分的簇
     优先级排序：1M对齐－－６４ｋ对齐－－１６ｋ对齐－－单个簇　每个簇的大小也会对算法产生影响。
我猜测，ｓｄ卡的ｆｔｌ应该是出现原地址修改的时候才会改变映射。映射的最小单位，应该是大块，不是小页，否则，开销很高。映射单元越小，随机写入性能越好。
但是，如果加上满覆盖的问题，也断绝了定制上层应用优化的可能。
固态硬盘的ｆｔｌ应该为了提高写入性能和寿命问题，ｓｄ卡的低端玩意肯定只有寿命，记录一下每个区的擦除次数，均衡处理一下就可以了。所以建立的映射应该只是大区级别。
映射单元越小，占用的管理开销越大。

     使用预擦除命令（ACMD23）设定多个写入块的预擦除会让随后的多块写入更快完成。控制器一般会使用这个值（擦除多少块）来决定随后的多块数据写入的块数。如果控制器在写入多块数据之前使用stop命令终止数据传输，那么，余下的数据块里面的值是未知的，可能是旧的值，也可能是擦除后的空白值（全1）。如果控制器传输的数据块数多于预擦除指定的块数，，SD卡会以一次擦除一块的操作方式来擦除数据（当收到新数据的时候）。ACMD32所定义的擦除块数会在多块数据写入完成后复位为默认值（1）这表示，完整按擦除块大小写入，效率最高。完全分开的擦除了写入，效率低。这要求，写开始地址对齐擦除块。

